{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Assignment_3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "23ab1f51e6ae4d24a447cd423ca94657": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de1c68e5618549899d8eceb2ad6ad948",
              "IPY_MODEL_e5aa4a674003457a93574c7f6cc8e852"
            ],
            "layout": "IPY_MODEL_0049410da8d94aee878200cde79de9c2"
          }
        },
        "de1c68e5618549899d8eceb2ad6ad948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bce68c817b64db9986c9b9a2fc6327d",
            "placeholder": "​",
            "style": "IPY_MODEL_989c8294a983424a81091bce004ae00e",
            "value": "0.009 MB of 0.009 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "e5aa4a674003457a93574c7f6cc8e852": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aae7f2c685674caaa137a8d7f5c40634",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59dc9006c19d4bdcabd0c1b0c0037ff9",
            "value": 1
          }
        },
        "0049410da8d94aee878200cde79de9c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bce68c817b64db9986c9b9a2fc6327d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "989c8294a983424a81091bce004ae00e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aae7f2c685674caaa137a8d7f5c40634": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59dc9006c19d4bdcabd0c1b0c0037ff9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59f0e3f486304fc5b361c69bf57b0f94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fbcd904475d347d39ae16a5502c5d86c",
              "IPY_MODEL_67618043b3ad4a1898f09151d6f704ab"
            ],
            "layout": "IPY_MODEL_ce19f921b4d04630a545e8a6c3f96c5c"
          }
        },
        "fbcd904475d347d39ae16a5502c5d86c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e45dad536b04dbfa43d7a973f21e491",
            "placeholder": "​",
            "style": "IPY_MODEL_7b4e82b9d35b4759a4f9f4bba4f3af43",
            "value": "0.610 MB of 0.610 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "67618043b3ad4a1898f09151d6f704ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38672d75e40940768e52b84733a9ca1a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b6afb92558340349f3d677fff7e5a8c",
            "value": 1
          }
        },
        "ce19f921b4d04630a545e8a6c3f96c5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e45dad536b04dbfa43d7a973f21e491": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b4e82b9d35b4759a4f9f4bba4f3af43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38672d75e40940768e52b84733a9ca1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b6afb92558340349f3d677fff7e5a8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fbb84a37ba5c4b96ac6ef6c584729727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f5649727a4824efcba6ceeebb0b7ceaf",
              "IPY_MODEL_5aafbee7c74d479f9adf39da2e3ae9a1"
            ],
            "layout": "IPY_MODEL_8357d04c5da343af80d361eb3fdc5e97"
          }
        },
        "f5649727a4824efcba6ceeebb0b7ceaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_146af33a97ec4a2bbf91522b8789684c",
            "placeholder": "​",
            "style": "IPY_MODEL_f851e6a1d05a42ad8427510a5ce5df90",
            "value": "0.747 MB of 0.747 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "5aafbee7c74d479f9adf39da2e3ae9a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_297bb89a3bca42329e00ae6fcee22194",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b80d791384e481faeea98a3f3c43e60",
            "value": 1
          }
        },
        "8357d04c5da343af80d361eb3fdc5e97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "146af33a97ec4a2bbf91522b8789684c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f851e6a1d05a42ad8427510a5ce5df90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "297bb89a3bca42329e00ae6fcee22194": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b80d791384e481faeea98a3f3c43e60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b0e778d7fa084b5c9906957c2e5c83bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_551e824634754e058746f0536023e4df",
              "IPY_MODEL_493c7b3dcf6148e9927804da23732819"
            ],
            "layout": "IPY_MODEL_fda5743770014c82884d6193180e6a07"
          }
        },
        "551e824634754e058746f0536023e4df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9dae80c316eb4a9ab676442887be6401",
            "placeholder": "​",
            "style": "IPY_MODEL_ea3cb6bd96834c239f4201dcae688fb6",
            "value": "0.880 MB of 0.880 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "493c7b3dcf6148e9927804da23732819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17d9c7005ad2413bb1575f26017f14ae",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b5ec3de779b41a998330fb682630a0d",
            "value": 1
          }
        },
        "fda5743770014c82884d6193180e6a07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dae80c316eb4a9ab676442887be6401": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea3cb6bd96834c239f4201dcae688fb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17d9c7005ad2413bb1575f26017f14ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b5ec3de779b41a998330fb682630a0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59e2e1521dbd4a95b329c84ad09c1225": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1e9626b2d7145e2834016cbd20fe9b0",
              "IPY_MODEL_41baf373e261420d9e7d8c5e38d7989b"
            ],
            "layout": "IPY_MODEL_6c5b6f3ecd634129ae47ae999b0d3aae"
          }
        },
        "f1e9626b2d7145e2834016cbd20fe9b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_908972d85db240bc93bff92d3bd90dfe",
            "placeholder": "​",
            "style": "IPY_MODEL_2a5635f08072406fb8dedbd5b21726c2",
            "value": "0.571 MB of 0.571 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "41baf373e261420d9e7d8c5e38d7989b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27a478c6116e473ea55808fa266cb083",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82d2e1f0ff0c469c8e35eb03e22f9240",
            "value": 1
          }
        },
        "6c5b6f3ecd634129ae47ae999b0d3aae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "908972d85db240bc93bff92d3bd90dfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a5635f08072406fb8dedbd5b21726c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27a478c6116e473ea55808fa266cb083": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82d2e1f0ff0c469c8e35eb03e22f9240": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.callbacks import History"
      ],
      "metadata": {
        "id": "v8grmhdOGcQW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar --output daksh.tar\n",
        "!tar -xvf  'daksh.tar' "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGA8GCP1GY0r",
        "outputId": "3961d62d-a19e-4843-d3c4-05fdc8f0c1c2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1915M  100 1915M    0     0   213M      0  0:00:08  0:00:08 --:--:--  219M\n",
            "dakshina_dataset_v1.0/bn/\n",
            "dakshina_dataset_v1.0/bn/lexicons/\n",
            "dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/bn/native_script_wikipedia/bn.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/bn/romanized/\n",
            "dakshina_dataset_v1.0/bn/romanized/bn.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/bn/romanized/bn.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/bn/romanized/bn.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/bn/romanized/bn.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/bn/romanized/bn.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/bn/romanized/bn.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/bn/romanized/bn.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/bn/romanized/bn.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/bn/romanized/bn.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/bn/romanized/bn.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/gu/\n",
            "dakshina_dataset_v1.0/gu/lexicons/\n",
            "dakshina_dataset_v1.0/gu/lexicons/gu.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/gu/lexicons/gu.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/gu/lexicons/gu.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/gu/native_script_wikipedia/gu.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/gu/romanized/\n",
            "dakshina_dataset_v1.0/gu/romanized/gu.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/gu/romanized/gu.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/gu/romanized/gu.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/gu/romanized/gu.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/gu/romanized/gu.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/gu/romanized/gu.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/gu/romanized/gu.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/gu/romanized/gu.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/gu/romanized/gu.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/gu/romanized/gu.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/hi/\n",
            "dakshina_dataset_v1.0/hi/lexicons/\n",
            "dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/hi/native_script_wikipedia/hi.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/hi/romanized/\n",
            "dakshina_dataset_v1.0/hi/romanized/hi.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/hi/romanized/hi.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/hi/romanized/hi.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/hi/romanized/hi.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/hi/romanized/hi.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/hi/romanized/hi.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/hi/romanized/hi.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/hi/romanized/hi.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/hi/romanized/hi.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/hi/romanized/hi.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/kn/\n",
            "dakshina_dataset_v1.0/kn/lexicons/\n",
            "dakshina_dataset_v1.0/kn/lexicons/kn.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/kn/lexicons/kn.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/kn/lexicons/kn.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/kn/native_script_wikipedia/kn.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/kn/romanized/\n",
            "dakshina_dataset_v1.0/kn/romanized/kn.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/kn/romanized/kn.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/kn/romanized/kn.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/kn/romanized/kn.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/kn/romanized/kn.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/kn/romanized/kn.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/kn/romanized/kn.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/kn/romanized/kn.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/kn/romanized/kn.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/kn/romanized/kn.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/ml/\n",
            "dakshina_dataset_v1.0/ml/lexicons/\n",
            "dakshina_dataset_v1.0/ml/lexicons/ml.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/ml/lexicons/tmp.rom.txt\n",
            "dakshina_dataset_v1.0/ml/lexicons/tmp.tsv\n",
            "dakshina_dataset_v1.0/ml/lexicons/ml.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/ml/lexicons/ml.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/ml/native_script_wikipedia/ml.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ml/romanized/\n",
            "dakshina_dataset_v1.0/ml/romanized/ml.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/ml/romanized/ml.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/ml/romanized/ml.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/ml/romanized/ml.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/ml/romanized/ml.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/ml/romanized/ml.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/ml/romanized/ml.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/ml/romanized/ml.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/ml/romanized/ml.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/ml/romanized/ml.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/mr/\n",
            "dakshina_dataset_v1.0/mr/lexicons/\n",
            "dakshina_dataset_v1.0/mr/lexicons/mr.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/mr/lexicons/mr.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/mr/lexicons/mr.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/mr/native_script_wikipedia/mr.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/mr/romanized/\n",
            "dakshina_dataset_v1.0/mr/romanized/mr.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/mr/romanized/mr.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/mr/romanized/mr.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/mr/romanized/mr.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/mr/romanized/mr.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/mr/romanized/mr.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/mr/romanized/mr.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/mr/romanized/mr.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/mr/romanized/mr.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/mr/romanized/mr.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/pa/\n",
            "dakshina_dataset_v1.0/pa/lexicons/\n",
            "dakshina_dataset_v1.0/pa/lexicons/pa.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/pa/lexicons/pa.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/pa/lexicons/pa.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/pa/native_script_wikipedia/pa.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/pa/romanized/\n",
            "dakshina_dataset_v1.0/pa/romanized/pa.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/pa/romanized/pa.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/pa/romanized/pa.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/pa/romanized/pa.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/pa/romanized/pa.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/pa/romanized/pa.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/pa/romanized/pa.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/pa/romanized/pa.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/pa/romanized/pa.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/pa/romanized/pa.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/sd/\n",
            "dakshina_dataset_v1.0/sd/lexicons/\n",
            "dakshina_dataset_v1.0/sd/lexicons/sd.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/sd/lexicons/sd.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/sd/lexicons/sd.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/sd/native_script_wikipedia/sd.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/sd/romanized/\n",
            "dakshina_dataset_v1.0/sd/romanized/sd.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/sd/romanized/sd.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/sd/romanized/sd.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/sd/romanized/sd.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/sd/romanized/sd.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/sd/romanized/sd.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/sd/romanized/sd.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/sd/romanized/sd.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/sd/romanized/sd.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/sd/romanized/sd.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/si/\n",
            "dakshina_dataset_v1.0/si/lexicons/\n",
            "dakshina_dataset_v1.0/si/lexicons/si.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/si/lexicons/si.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/si/lexicons/si.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/si/native_script_wikipedia/si.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/si/romanized/\n",
            "dakshina_dataset_v1.0/si/romanized/si.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/si/romanized/si.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/si/romanized/si.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/si/romanized/si.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/si/romanized/si.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/si/romanized/si.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/si/romanized/si.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/si/romanized/si.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/si/romanized/si.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/si/romanized/si.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/ta/\n",
            "dakshina_dataset_v1.0/ta/lexicons/\n",
            "dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/ta/native_script_wikipedia/ta.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ta/romanized/\n",
            "dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/ta/romanized/ta.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/ta/romanized/ta.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/ta/romanized/ta.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/ta/romanized/ta.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/te/\n",
            "dakshina_dataset_v1.0/te/lexicons/\n",
            "dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/te/lexicons/te.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/te/native_script_wikipedia/te.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/te/romanized/\n",
            "dakshina_dataset_v1.0/te/romanized/te.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/te/romanized/te.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/te/romanized/te.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/te/romanized/te.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/te/romanized/te.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/te/romanized/te.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/te/romanized/te.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/te/romanized/te.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/te/romanized/te.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/te/romanized/te.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/ur/\n",
            "dakshina_dataset_v1.0/ur/lexicons/\n",
            "dakshina_dataset_v1.0/ur/lexicons/ur.translit.sampled.train.tsv\n",
            "dakshina_dataset_v1.0/ur/lexicons/ur.translit.sampled.test.tsv\n",
            "dakshina_dataset_v1.0/ur/lexicons/ur.translit.sampled.dev.tsv\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-filt.valid.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-full.nonblock.sections.tsv.gz\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-full.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-full.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-full.omit_pages.txt.gz\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-filt.train.text.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-full.urls.tsv.gz\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-filt.train.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-full.nonblock.sections.list.txt.gz\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-filt.valid.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-filt.valid.text.shuf.txt.gz\n",
            "dakshina_dataset_v1.0/ur/native_script_wikipedia/ur.wiki-filt.train.info.sorted.tsv.gz\n",
            "dakshina_dataset_v1.0/ur/romanized/\n",
            "dakshina_dataset_v1.0/ur/romanized/ur.romanized.rejoined.tsv\n",
            "dakshina_dataset_v1.0/ur/romanized/ur.romanized.rejoined.dev.roman.txt\n",
            "dakshina_dataset_v1.0/ur/romanized/ur.romanized.split.validation.native.txt\n",
            "dakshina_dataset_v1.0/ur/romanized/ur.romanized.rejoined.aligned.cased_nopunct.tsv\n",
            "dakshina_dataset_v1.0/ur/romanized/ur.romanized.rejoined.dev.native.txt\n",
            "dakshina_dataset_v1.0/ur/romanized/ur.romanized.rejoined.test.native.txt\n",
            "dakshina_dataset_v1.0/ur/romanized/ur.romanized.split.validation.edits.txt\n",
            "dakshina_dataset_v1.0/ur/romanized/ur.romanized.rejoined.aligned.tsv\n",
            "dakshina_dataset_v1.0/ur/romanized/ur.romanized.split.tsv\n",
            "dakshina_dataset_v1.0/ur/romanized/ur.romanized.rejoined.test.roman.txt\n",
            "dakshina_dataset_v1.0/README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "!wandb login\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ],
      "metadata": {
        "id": "qck0iG7IyN60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42512b29-8b43-4aed-a3e4-8ed0983323ae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.15)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.5.10)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.27)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb) (1.2.3)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.8)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33makshaygrao\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"DeepLearningAssignment-3\", entity='cs21s002-ee21s113-dlassignment-1')"
      ],
      "metadata": {
        "id": "SFfsHST6z4y4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "e3021ff0-1f7a-4bc9-cf84-3d9a820c3138"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33makshaygrao\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.15"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220423_123610-1b6smi8q</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3/runs/1b6smi8q\" target=\"_blank\">smooth-oath-91</a></strong> to <a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3/runs/1b6smi8q?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f29dacbb690>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb.init(project=\"DeepLearningAssignment-3\", entity='akshaygrao')"
      ],
      "metadata": {
        "id": "lxSP8Ba92LEB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def obtain_input_target_data_from_path(path,tokenizer_obj):\n",
        "  input_texts = []\n",
        "  target_texts = []\n",
        "  \n",
        "  df = pd.read_csv(path,sep=\"\\t\",names=[\"1\", \"2\",\"3\"]).astype(str)\n",
        "  if tokenizer_obj is None:\n",
        "    # Shuffle rows in random order with a fixed seed(for reproducability)\n",
        "    df=df.sample(frac=1,random_state=1)\n",
        "  # Add all the  input and target texts with start sequence and end sequence added to target \n",
        "  for index, row in df.iterrows():\n",
        "      input_text=row['2']\n",
        "      target_text= row['1']\n",
        "      # Skip empty lines/words\n",
        "      if target_text =='</s>' or input_text=='</s>':\n",
        "        continue\n",
        "      \n",
        "      target_text = \"\\t\" + target_text + \"\\n\"\n",
        "      input_texts.append(input_text)\n",
        "      target_texts.append(target_text)\n",
        "  \n",
        "  return input_texts, target_texts"
      ],
      "metadata": {
        "id": "mzR1_lcKgW5O"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_text_to_sequences(tokenizer_obj,inp_texts):\n",
        "  if tokenizer_obj is None:\n",
        "    tokenizer_obj = tf.keras.preprocessing.text.Tokenizer(filters='', char_level=True)\n",
        "    tokenizer_obj.fit_on_texts(inp_texts)\n",
        "  ret_tensor = tokenizer_obj.texts_to_sequences(inp_texts)\n",
        "  ret_tensor = tf.keras.preprocessing.sequence.pad_sequences(ret_tensor,padding='post')\n",
        "\n",
        "  return ret_tensor,tokenizer_obj"
      ],
      "metadata": {
        "id": "1pov4thdppKt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This method converts a dataset(from path) to input and target sequences\n",
        "def pre_process_data(path,input_tokenizer=None,target_tokenizer=None,input_length=None,target_length=None):\n",
        "  \n",
        "  input_texts, target_texts = obtain_input_target_data_from_path(path,input_tokenizer)\n",
        "  \n",
        "  input_tensor,input_tokenizer = convert_text_to_sequences(input_tokenizer,input_texts)\n",
        "  \n",
        "  target_tensor,target_tokenizer = convert_text_to_sequences(target_tokenizer,target_texts)\n",
        "  \n",
        "  # Above functions return padded version wrt longest sequence in the given list of sequence\n",
        "  # The below function, pads more zeros wrt input_length and target_length\n",
        "  if input_length is not None and target_length is not None:\n",
        "      input_tensor=tf.concat([input_tensor,tf.zeros((input_tensor.shape[0],input_length-input_tensor.shape[1]))],axis=1)\n",
        "      target_tensor=tf.concat([target_tensor,tf.zeros((target_tensor.shape[0],target_length-target_tensor.shape[1]))],axis=1)\n",
        "  return input_texts,input_tensor,input_tokenizer,target_texts,target_tensor,target_tokenizer"
      ],
      "metadata": {
        "id": "s-fHBjgNHJNY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transliteration_target_language = 'kn'"
      ],
      "metadata": {
        "id": "KL3-IxpstPlS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_texts,train_input_tensor,input_tokenizer,train_target_texts,train_target_tensor,target_tokenizer = pre_process_data(\"/content/dakshina_dataset_v1.0/\"+transliteration_target_language+\"/lexicons/\"+transliteration_target_language+\".translit.sampled.train.tsv\")\n",
        "# Only training dataset is used to fit the tokenizer on text. Other datasets just use this vocab for pre-processing\n",
        "# The length for padding is also set from training datasets\n",
        "val_input_texts,val_input_tensor,val_input_tokenizer,val_target_texts,val_target_tensor,val_target_tokenizer = pre_process_data(\"/content/dakshina_dataset_v1.0/\"+transliteration_target_language+\"/lexicons/\"+transliteration_target_language+\".translit.sampled.dev.tsv\",input_tokenizer,target_tokenizer,train_input_tensor.shape[1],train_target_tensor.shape[1])\n",
        "test_input_texts,test_input_tensor,test_input_tokenizer,test_target_texts,test_target_tensor,test_target_tokenizer = pre_process_data(\"/content/dakshina_dataset_v1.0/\"+transliteration_target_language+\"/lexicons/\"+transliteration_target_language+\".translit.sampled.test.tsv\",input_tokenizer,target_tokenizer,train_input_tensor.shape[1],train_target_tensor.shape[1])"
      ],
      "metadata": {
        "id": "FWLwIxUwISEb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(train_input_texts[:2])\n",
        "# print(train_input_tensor[:2])\n",
        "# print(val_input_texts[:2])\n",
        "# print(val_input_tensor[:2])\n",
        "print(train_target_texts[15])\n",
        "print(train_target_tensor[15])\n",
        "for each_ele in train_target_texts[15]:\n",
        "  print(each_ele)\n",
        "print(len(train_input_texts))\n",
        "print(train_input_tensor.shape)\n",
        "# print(len(train_target_texts))\n",
        "# print(train_target_tensor.shape)"
      ],
      "metadata": {
        "id": "7x__RcWFtDlt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9752e053-6f69-4943-88a7-97101519b2b5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tಘಟನೆಗಳಿಗೆ\n",
            "\n",
            "[ 1 51 24 10 15 12 21  4 12 15  2  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0]\n",
            "\t\n",
            "ಘ\n",
            "ಟ\n",
            "ನ\n",
            "ೆ\n",
            "ಗ\n",
            "ಳ\n",
            "ಿ\n",
            "ಗ\n",
            "ೆ\n",
            "\n",
            "\n",
            "50624\n",
            "(50624, 26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_encoder_tokens = len(input_tokenizer.word_index)+1\n",
        "num_decoder_tokens = len(target_tokenizer.word_index)+1\n",
        "max_encoder_seq_length =  train_input_tensor.shape[1]\n",
        "max_decoder_seq_length = train_target_tensor.shape[1]"
      ],
      "metadata": {
        "id": "pi_oWsEotJq8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(num_encoder_tokens)\n",
        "print(num_decoder_tokens)\n",
        "print(max_encoder_seq_length)\n",
        "print(max_decoder_seq_length)"
      ],
      "metadata": {
        "id": "ASxKQYeZ7knF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aa84e1d-26fe-43e3-bc97-a22d71c746e6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27\n",
            "64\n",
            "26\n",
            "26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_layered_RNN_model(rnn_type,embedding_in_dim,embedding_out_dim,layers,dropout,inp_length,model_out_dim,initial_state = None):\n",
        "   #input layer ; takes in tokenize input\n",
        "  model_inputs = keras.Input(shape=( inp_length))\n",
        "  #embedding layer\n",
        "  embed = keras.layers.Embedding(embedding_in_dim, embedding_out_dim)(model_inputs)\n",
        "  \n",
        "  last_layer_model = None\n",
        "  if rnn_type == 'LSTM':\n",
        "    #adding everything except the last LSTM layer, because in last layer return state=True\n",
        "    for i in range(layers):\n",
        "      layered_model = keras.layers.LSTM(model_out_dim, return_sequences=True,return_state=True,dropout=dropout)\n",
        "      if i==0:\n",
        "        inp_layer = embed\n",
        "      else:\n",
        "        inp_layer = last_layer_model\n",
        "      \n",
        "      model_layer_out,state_h, state_c = layered_model(inp_layer,initial_state)\n",
        "      \n",
        "      last_layer_model = model_layer_out\n",
        "    \n",
        "    model_states = [state_h, state_c]\n",
        "    \n",
        "  elif rnn_type=='GRU':\n",
        "    #adding everything except the last GRU layer, because in last layer return state=True    \n",
        "    for i in range(layers):\n",
        "      layered_model = keras.layers.GRU(model_out_dim, return_sequences=True,return_state=True,dropout=dropout)\n",
        "      if i==0:\n",
        "        inp_layer = embed\n",
        "      else:\n",
        "        inp_layer = last_layer_model\n",
        "      \n",
        "      model_layer_out,state = layered_model(inp_layer,initial_state)\n",
        "      \n",
        "      last_layer_model = model_layer_out\n",
        "\n",
        "    model_states = [state]\n",
        "  elif rnn_type=='RNN':\n",
        "    #adding everything except the last RNN layer, because in last layer return state=True\n",
        "    for i in range(layers):      \n",
        "      layered_model = keras.layers.SimpleRNN(model_out_dim, return_sequences=True,return_state=True,dropout=dropout)\n",
        "      if i==0:\n",
        "        inp_layer = embed\n",
        "      else:\n",
        "        inp_layer = last_layer_model\n",
        "        \n",
        "      model_layer_out,state = layered_model(inp_layer,initial_state)\n",
        "      \n",
        "      last_layer_model = model_layer_out\n",
        "\n",
        "    model_states = [state]\n",
        "    \n",
        "  return model_states,last_layer_model,model_inputs\n"
      ],
      "metadata": {
        "id": "mF1p5Vjl6gGZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Build the model\n",
        "def build_model(rnn_type,embedding_dim,encoder_layers,decoder_layers,dropout,latent_dim):\n",
        "  \n",
        "  encoder_states,encoder_outputs,encoder_inputs = build_layered_RNN_model(rnn_type=rnn_type,embedding_in_dim = num_encoder_tokens,embedding_out_dim = embedding_dim,layers = encoder_layers,dropout = dropout,inp_length = max_encoder_seq_length,model_out_dim = latent_dim)\n",
        "\n",
        "  _,decoder_outputs,decoder_inputs = build_layered_RNN_model(rnn_type=rnn_type,embedding_in_dim = num_decoder_tokens,embedding_out_dim = embedding_dim,layers = decoder_layers,dropout = dropout,inp_length = max_decoder_seq_length,model_out_dim = latent_dim,initial_state = encoder_states)\n",
        "  \n",
        "  decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\",name='final')\n",
        "  decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "  model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "  \n",
        "  return model"
      ],
      "metadata": {
        "id": "Br2JpV-7xET_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_inference_encoder_model(model,encoder_layers):\n",
        "  encoder_inputs = model.input[0]  \n",
        "  if isinstance(model.layers[encoder_layers+3], keras.layers.LSTM):\n",
        "    encoder_outputs, state_h_enc, state_c_enc = model.layers[encoder_layers+3].output  \n",
        "    encoder_states = [state_h_enc, state_c_enc]\n",
        "  elif (isinstance(model.layers[encoder_layers+3], keras.layers.GRU) or isinstance(model.layers[encoder_layers+3], keras.layers.RNN)):\n",
        "    encoder_outputs, state = model.layers[encoder_layers+3].output  \n",
        "    encoder_states = [state]\n",
        "\n",
        "  encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
        "  return encoder_model"
      ],
      "metadata": {
        "id": "iUuV-IQ8ltes"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_inference_decoder_model(model,encoder_layers,decoder_layers,latent_dim):\n",
        "  # Decoder during inference takes just one character(i.e vector rep of a character). This is either from previous timestep or start of sequence(\"\\t\")\n",
        "  decoder_inputs =  keras.Input(shape=( 1))\n",
        "  # Contains input to each decoder layer\n",
        "  decoder_states_inputs=[]\n",
        "  # Contains state output from each decoder layer\n",
        "  decoder_states=[]\n",
        "  previous_decoder_output = None\n",
        "\n",
        "  emdedded_rep_of_decoder_input = model.layers[encoder_layers+2](decoder_inputs)\n",
        "  # \"encoder_layer + 4\" because inp,embedding of encoder + inp,embedding of decoder\n",
        "  if isinstance(model.layers[encoder_layers+4], keras.layers.LSTM):\n",
        "    for i in range(decoder_layers):\n",
        "      #every layer must have an input through which we can supply it's hidden state\n",
        "      decoder_state_input_h = keras.Input(shape=(latent_dim,),name='inp3_'+str(i))\n",
        "      decoder_state_input_c = keras.Input(shape=(latent_dim,),name='inp4_'+str(i))\n",
        "      init_state = [decoder_state_input_h, decoder_state_input_c]\n",
        "      decoder_lstm = model.layers[i+encoder_layers+4]\n",
        "      if i==0:\n",
        "        decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(emdedded_rep_of_decoder_input, initial_state=init_state)\n",
        "      else:\n",
        "        decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(previous_decoder_output, initial_state=init_state )\n",
        "      \n",
        "      previous_decoder_output = decoder_outputs\n",
        "      decoder_states_inputs.append (decoder_state_input_h)\n",
        "      decoder_states_inputs.append (decoder_state_input_c)\n",
        "      decoder_states.append (state_h_dec)\n",
        "      decoder_states.append (state_c_dec)\n",
        "  elif isinstance(model.layers[encoder_layers + 4], keras.layers.GRU):\n",
        "    for i in range(decoder_layers):\n",
        "      decoder_state_input = keras.Input(shape=(latent_dim,),name='inp3_'+str(i))\n",
        "      init_state = [decoder_state_input]\n",
        "      decoder_lstm = model.layers[i+encoder_layers+4]\n",
        "      if i==0:\n",
        "        decoder_outputs, state = decoder_lstm(emdedded_rep_of_decoder_input, initial_state=init_state)\n",
        "      else:\n",
        "        decoder_outputs, state = decoder_lstm(previous_decoder_output, initial_state=init_state )\n",
        "      \n",
        "      previous_decoder_output = decoder_outputs\n",
        "      decoder_states_inputs.append (decoder_state_input)\n",
        "      decoder_states.append (state)\n",
        "  elif isinstance(model.layers[encoder_layers + 4], keras.layers.RNN):\n",
        "    for i in range(decoder_layers):\n",
        "      decoder_state_input = keras.Input(shape=(latent_dim,),name='inp3_'+str(i))\n",
        "      init_state = [decoder_state_input]\n",
        "      decoder_lstm = model.layers[i+encoder_layers+4]\n",
        "      if i==0:\n",
        "        decoder_outputs, state = decoder_lstm(emdedded_rep_of_decoder_input, initial_state=init_state)\n",
        "      else:\n",
        "        decoder_outputs, state = decoder_lstm(previous_decoder_output, initial_state=init_state )\n",
        "      \n",
        "      previous_decoder_output = decoder_outputs\n",
        "      decoder_states_inputs.append (decoder_state_input)\n",
        "      decoder_states.append (state)      \n",
        "  decoder_dense = model.get_layer('final')\n",
        "  decoder_outputs = decoder_dense(previous_decoder_output)\n",
        "  decoder_model = keras.Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
        "\n",
        "  return decoder_model"
      ],
      "metadata": {
        "id": "WhC8eYW4mPv-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_inference_model(model,encoder_layers,decoder_layers,latent_dim):\n",
        "    encoder_model = get_inference_encoder_model(model,encoder_layers)\n",
        "    \n",
        "    decoder_model = get_inference_decoder_model(model,encoder_layers,decoder_layers,latent_dim)\n",
        "\n",
        "    return encoder_model,decoder_model"
      ],
      "metadata": {
        "id": "NDJJuJM8koKB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_char_target = dict((target_tokenizer.word_index[key], key) for key in target_tokenizer.word_index.keys())"
      ],
      "metadata": {
        "id": "Y0gUSgh26w03"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_batch_of_sequences(rnn_type,input_seq,encoder_model,decoder_model,batch_size,encoder_layers,decoder_layers):\n",
        "    # Get encoder output\n",
        "    encoder_output_state_values = encoder_model.predict(input_seq)\n",
        "    if rnn_type=='GRU' or 'RNN':\n",
        "      decoder_input_state_values=[encoder_output_state_values]\n",
        "    \n",
        "    # This is needed because encoder state is fed to all decoder layers\n",
        "    decoder_input_state_values = decoder_input_state_values * decoder_layers\n",
        "    \n",
        "    # This is contain previously predicted character's index for every words in batch.\n",
        "    prev_char_index = np.zeros((batch_size, 1))\n",
        "    # We start with \\t for every word in batch\n",
        "    prev_char_index[:, 0] = target_tokenizer.word_index['\\t']\n",
        "    \n",
        "    predicted_words = [ \"\" for i in range(batch_size)]\n",
        "    done=[False for i in range(batch_size)]\n",
        "    for i in range(max_decoder_seq_length):\n",
        "        decoder_out = decoder_model.predict(tuple([prev_char_index] + decoder_input_state_values))\n",
        "        # Decoder output has both output of all timesteps followed by hidden states\n",
        "        output_probability = decoder_out[0]\n",
        "        # Decoder state input is previous layer state output\n",
        "        decoder_input_state_values = decoder_out[1:]\n",
        "        for j in range(batch_size):\n",
        "          if done[j]:\n",
        "            continue          \n",
        "          sampled_token_index = np.argmax(output_probability[j, -1, :])\n",
        "          if sampled_token_index == 0:\n",
        "            sampled_char='\\n'\n",
        "          else:\n",
        "            sampled_char = index_to_char_target[sampled_token_index]\n",
        "          if sampled_char == '\\n':\n",
        "            done[j]=True\n",
        "            continue            \n",
        "          predicted_words[j] += sampled_char\n",
        "          #update the previously predicted characters        \n",
        "          prev_char_index[j,0]=target_tokenizer.word_index[sampled_char]\n",
        "    return predicted_words"
      ],
      "metadata": {
        "id": "Qojx7JC35S5y"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_batch_of_sequences_for_bigger_beam_width(rnn_type,input_seq,encoder_model,decoder_model,batch_size,encoder_layers,decoder_layers,beam_search_width):\n",
        "    print(\"input_seq:\"+str(input_seq.shape))\n",
        "    next_list_of_beam_record_objects = []\n",
        "    predicted_words = [ \"\" for i in range(batch_size)]\n",
        "    list_of_beam_record_objects = []\n",
        "    for j in range(batch_size):\n",
        "      print(\"Batch number:\"+str(j))\n",
        "      current_seq = input_seq[j]\n",
        "      current_seq = tf.expand_dims(current_seq, 0)\n",
        "      # Get encoder output\n",
        "      decoder_input_state_values = encoder_model.predict(current_seq)\n",
        "      if rnn_type=='GRU' or 'RNN':\n",
        "        decoder_input_state_values=[decoder_input_state_values]\n",
        "    \n",
        "      # This is needed because encoder state is fed to all decoder layers\n",
        "      decoder_input_state_values = decoder_input_state_values[0] * decoder_layers\n",
        "    \n",
        "      prev_char_index = np.zeros((1, 1))\n",
        "      # We start with \\t for every word in batch\n",
        "      prev_char_index[:, 0] = target_tokenizer.word_index['\\t']\n",
        "      done  = False\n",
        "      for _ in range(beam_search_width):\n",
        "        current_beam_search_obj = BeamRecordKeeping(decoder_input_state_values,prev_char_index,0,\"\")\n",
        "        list_of_beam_record_objects.append(current_beam_search_obj)\n",
        "\n",
        "      for i in range(max_decoder_seq_length):\n",
        "        if( i!= 0 and len(next_list_of_beam_record_objects) == 0):\n",
        "          predicted_words[j] = get_predicted_word_from_beam(list_of_beam_record_objects)\n",
        "          break\n",
        "        elif( i != 0 and len(next_list_of_beam_record_objects) < beam_search_width):\n",
        "          predicted_words[j] = get_predicted_word_from_beam(next_list_of_beam_record_objects)\n",
        "          break\n",
        "        if(i != 0):\n",
        "          list_of_beam_record_objects = next_list_of_beam_record_objects\n",
        "        next_list_of_beam_record_objects = []\n",
        "        for beam_index in range(beam_search_width):\n",
        "          # print(\"prev_char_index\"+str(list_of_beam_record_objects[beam_index].prev_char_index.shape))\n",
        "          # print(\"decoder_input_state_values\"+str(len(list_of_beam_record_objects[beam_index].decoder_input_state_values)))\n",
        "          # print(\"decoder_input_state_values\"+str(list_of_beam_record_objects[beam_index].decoder_input_state_values[0].shape))\n",
        "\n",
        "          decoder_out = decoder_model.predict(tuple([list_of_beam_record_objects[beam_index].prev_char_index] + list_of_beam_record_objects[beam_index].decoder_input_state_values))\n",
        "          # Decoder output has both output of all timesteps followed by hidden states\n",
        "          output_probability = decoder_out[0]\n",
        "          # Decoder state input is previous layer state output\n",
        "          decoder_input_state_values = decoder_out[1:]\n",
        "          sampled_token_index = np.argsort(output_probability[0][-1, :])[-beam_search_width:]\n",
        "          sampled_probability_values = output_probability[0][-1, :][sampled_token_index]\n",
        "\n",
        "          for each_candidate in range(1,len(sampled_probability_values)+1):\n",
        "            new_joint_probability = list_of_beam_record_objects[beam_index].joint_probability * math.log(sampled_probability_values[-each_candidate])\n",
        "            if(len(next_list_of_beam_record_objects) < beam_search_width):\n",
        "              sampled_char = get_sampled_char(sampled_token_index[-each_candidate])\n",
        "              if sampled_char == '\\n':\n",
        "                continue\n",
        "              accumulated_previous_chars = list_of_beam_record_objects[beam_index].accumulated_previous_chars + sampled_char\n",
        "              prev_char_index[:, 0]=target_tokenizer.word_index[sampled_char]\n",
        "              next_beam_record_keeping_obj = BeamRecordKeeping(decoder_input_state_values,prev_char_index,new_joint_probability,accumulated_previous_chars)\n",
        "              next_list_of_beam_record_objects.append(next_beam_record_keeping_obj)\n",
        "            else:\n",
        "              replace_indx = -1\n",
        "              for (current_indx,each_obj) in enumerate(next_list_of_beam_record_objects):\n",
        "                if(each_obj.joint_probability < new_joint_probability):\n",
        "                  replace_indx = current_indx\n",
        "                  break\n",
        "              if(replace_indx != -1):\n",
        "                sampled_char = get_sampled_char(sampled_token_index[-each_candidate])\n",
        "                if sampled_char == '\\n':\n",
        "                  continue\n",
        "                accumulated_previous_chars = list_of_beam_record_objects[beam_index].accumulated_previous_chars + sampled_char\n",
        "                prev_char_index[:, 0]=target_tokenizer.word_index[sampled_char]\n",
        "                next_beam_record_keeping_obj = BeamRecordKeeping(decoder_input_state_values,prev_char_index,new_joint_probability,accumulated_previous_chars)\n",
        "                next_list_of_beam_record_objects[replace_indx] = next_beam_record_keeping_obj\n",
        "        \n",
        "    return predicted_words"
      ],
      "metadata": {
        "id": "Mwfd_Mx3WQmP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_accuracy(rnn_type,encoder_model,decoder_model,encoder_layers,decoder_layers,beam_search_width=1):\n",
        "  success=0\n",
        "  success_char = 0\n",
        "  total_chars = 0\n",
        "  #Get all the predicted words\n",
        "  if(beam_search_width == 0 or beam_search_width == 1):\n",
        "    pred=decode_batch_of_sequences(rnn_type,test_input_tensor,encoder_model,decoder_model,test_input_tensor.shape[0],encoder_layers,decoder_layers)\n",
        "  else:\n",
        "    pred=decode_batch_of_sequences_for_bigger_beam_width(rnn_type,test_input_tensor,encoder_model,decoder_model,test_input_tensor.shape[0],encoder_layers,decoder_layers,beam_search_width)\n",
        "  for seq_index in range(test_input_tensor.shape[0]):\n",
        "      predicted_word = pred[seq_index]\n",
        "      target_word=test_target_texts[seq_index][1:-1]\n",
        "      for (indx,each_ele) in enumerate(target_word):\n",
        "        total_chars += 1\n",
        "        if(indx < len(predicted_word)):\n",
        "          if(target_word[indx] == predicted_word[indx]):\n",
        "            success_char += 1\n",
        "\n",
        "      #test the word one by one and write to files\n",
        "      if target_word == predicted_word:\n",
        "        success+=1\n",
        "        f = open(\"success.txt\", \"a\")\n",
        "        f.write(test_input_texts[seq_index]+' '+target_word+' '+predicted_word+'\\n')\n",
        "        f.close()\n",
        "      else:\n",
        "        f = open(\"failure.txt\", \"a\")\n",
        "        f.write(test_input_texts[seq_index]+' '+target_word+' '+predicted_word+'\\n')\n",
        "        f.close()\n",
        "  \n",
        "  print(\"success:\"+str(success))\n",
        "  print(\"success_char:\"+str(success_char))\n",
        "  return float(success)/float(test_input_tensor.shape[0]),float(success_char)/float(total_chars)"
      ],
      "metadata": {
        "id": "kbTznqNEx4sR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_validate(rnn_type,encoder_model,decoder_model,encoder_layers,decoder_layers,beam_search_width=1):\n",
        "  success = 0\n",
        "  success_char = 0\n",
        "  total_chars = 0\n",
        "  #get all the predicted words\n",
        "  if(beam_search_width == 0 or beam_search_width == 1):\n",
        "    pred=decode_batch_of_sequences(rnn_type,val_input_tensor,encoder_model,decoder_model,val_input_tensor.shape[0],encoder_layers,decoder_layers)\n",
        "  else:\n",
        "    pred=decode_batch_of_sequences_for_bigger_beam_width(rnn_type,val_input_tensor,encoder_model,decoder_model,val_input_tensor.shape[0],encoder_layers,decoder_layers,beam_search_width)\n",
        "\n",
        "  for seq_index in range(val_input_tensor.shape[0]):\n",
        "    predicted_word = pred[seq_index]\n",
        "    target_word = val_target_texts[seq_index][1:-1]\n",
        "    #test the words one by one\n",
        "    if predicted_word == target_word:\n",
        "      # print(\"pred:\"+str(pred[seq_index]))\n",
        "      # print(\"Target: \"+str(val_target_texts[seq_index][1:-1]))\n",
        "      success+=1\n",
        "      \n",
        "    for (indx,each_ele) in enumerate(target_word):\n",
        "      total_chars += 1\n",
        "      if(indx < len(predicted_word)):\n",
        "        if(target_word[indx] == predicted_word[indx]):\n",
        "          # print(\"pred:\"+str(pred[seq_index]))\n",
        "          # print(\"Target: \"+str(target_word))\n",
        "          success_char += 1\n",
        "  \n",
        "  print(\"success:\"+str(success))\n",
        "  print(\"success_char:\"+str(success_char))\n",
        "  # print(\"val_input_tensor.shape[0]:\"+str(val_input_tensor.shape[0]))\n",
        "  return float(success)/float(val_input_tensor.shape[0]),float(success_char)/float(total_chars)"
      ],
      "metadata": {
        "id": "jcWesBWKm2hn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default_config = {\n",
        "        \"rnn_type\": \"LSTM\",\n",
        "        \"dropout\": 0.5,\n",
        "        \"encoder_layers\":3,\n",
        "        \"decoder_layers\":4,\n",
        "        \"latent_dim\": 64,\n",
        "        \"epochs\": 10,\n",
        "        \"lr\": 0.0001,\n",
        "        \"embedding_out_dim\": 64,\n",
        "        \"beam_search\":False,\n",
        "        \"batch_size\":64\n",
        "    }\n",
        "\n",
        "#Keras callback    \n",
        "history = History()"
      ],
      "metadata": {
        "id": "VX5pjUqzDVr-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def HP_tuning_run():\n",
        "    # Create a MirroredStrategy.\n",
        "    if tf.config.list_physical_devices('GPU'):\n",
        "        strategy = tf.distribute.MirroredStrategy()\n",
        "    else:  # use default strategy\n",
        "        strategy = tf.distribute.get_strategy()\n",
        "    print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
        "\n",
        "    wandb.init(config=default_config, magic=True,project=\"DeepLearningAssignment-3\", entity='cs21s002-ee21s113-dlassignment-1')\n",
        "    # wandb.init(config=default_config, magic=True,project=\"DeepLearningAssignment-3\", entity='akshaygrao')\n",
        "    config = wandb.config\n",
        "    print(\"Config: \"+str(config))\n",
        "    run_name = str(config).replace(\"{\", \"\").replace(\"}\",\"\").replace(\":\",\"-\")\n",
        "    wandb.run.name = run_name\n",
        "\n",
        "    # Open a strategy scope and create the model\n",
        "    with strategy.scope():\n",
        "      model = build_model(config.rnn_type,config.embedding_out_dim,config.encoder_layers,config.decoder_layers,config.dropout,config.latent_dim)\n",
        "\n",
        "    plot_model(model, to_file='model.png', show_shapes=True, show_dtype=True,show_layer_names=True)\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(config.lr), loss=keras.losses.SparseCategoricalCrossentropy(reduction='none'), metrics=[\"accuracy\"])\n",
        "\n",
        "    hist=model.fit([train_input_tensor, train_target_tensor],tf.concat([train_target_tensor[:,1:],tf.zeros((train_target_tensor[:,:].shape[0],1))], axis=1),batch_size=config.batch_size,epochs=config.epochs,shuffle=True,callbacks=[WandbCallback(), history])\n",
        "\n",
        "    model.save(f'{run_name.replace(\",\",\"-\")}.h5')  # creates a HDF5 file 'my_model.h5'\n",
        "    inf = keras.models.load_model(f'{run_name.replace(\",\",\"-\")}.h5')\n",
        "    encoder_inference_model,decoder_inference_model=build_inference_model(inf,encoder_layers=config.encoder_layers,decoder_layers=config.decoder_layers,latent_dim=config.latent_dim)\n",
        "    plot_model(encoder_inference_model, to_file='encoder_model.png', show_shapes=True)\n",
        "    plot_model(decoder_inference_model, to_file='decoder_model.png', show_shapes=True)\n",
        "    \n",
        "    word_val_acc,char_val_acc=batch_validate(config.rnn_type,encoder_inference_model,decoder_inference_model,config.encoder_layers,config.decoder_layers,config.beam_search)\n",
        "    print(\"word_val_acc\"+str(word_val_acc))\n",
        "    print(\"char_val_acc\"+str(char_val_acc))\n",
        "    wandb.log({\"word_val_acc\":str(round(word_val_acc,5))})\n",
        "    wandb.log({\"char_val_acc\":str(round(char_val_acc,5))})\n",
        "    wandb.log({\"language\":str(transliteration_target_language)})\n",
        "    \n"
      ],
      "metadata": {
        "id": "PvOMovPZyGqj"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_best_model():\n",
        "    encoder_layers = 3\n",
        "    decoder_layers = 3\n",
        "    epochs = 20\n",
        "    lr = 0.0001\n",
        "    latent_dim = 2048\n",
        "    rnn_type = 'GRU'\n",
        "    embedding_dim = 128\n",
        "    dropout = 0.3\n",
        "    bs = 64\n",
        "    beam_width = 0\n",
        "      # Create a MirroredStrategy.\n",
        "    if tf.config.list_physical_devices('GPU'):\n",
        "        strategy = tf.distribute.MirroredStrategy()\n",
        "    else:  # use default strategy\n",
        "        strategy = tf.distribute.get_strategy()\n",
        "    print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
        "        # Open a strategy scope and create the model\n",
        "    with strategy.scope():\n",
        "      model = build_model(rnn_type,embedding_dim,encoder_layers,encoder_layers,dropout,latent_dim)\n",
        "\n",
        "    plot_model(model, to_file='best_model.png', show_shapes=True, show_dtype=True,show_layer_names=True)\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(lr), loss=keras.losses.SparseCategoricalCrossentropy(reduction='none'), metrics=[\"accuracy\"])\n",
        "\n",
        "    hist=model.fit([train_input_tensor, train_target_tensor],tf.concat([train_target_tensor[:,1:],tf.zeros((train_target_tensor[:,:].shape[0],1))], axis=1),batch_size=bs,epochs=epochs,shuffle=True,callbacks=[WandbCallback(), history])\n",
        "\n",
        "    encoder_inference_model,decoder_inference_model=build_inference_model(model,encoder_layers=encoder_layers,decoder_layers=decoder_layers,latent_dim=latent_dim)\n",
        "    plot_model(encoder_inference_model, to_file='best_encoder_model.png', show_shapes=True)\n",
        "    plot_model(decoder_inference_model, to_file='best_decoder_model.png', show_shapes=True)\n",
        "    \n",
        "    word_val_acc,char_val_acc=test_accuracy(rnn_type,encoder_inference_model,decoder_inference_model,encoder_layers,decoder_layers,beam_width)\n",
        "    print(\"Test word_val_acc\"+str(word_val_acc))\n",
        "    print(\"Test char_val_acc\"+str(char_val_acc))\n",
        "\n",
        "    return model,encoder_inference_model,decoder_inference_model"
      ],
      "metadata": {
        "id": "P_psbbJxVblX"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model,encoder_inference_model,decoder_inference_model = run_best_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOTnrvm2ZAKW",
        "outputId": "4688a74a-fe1c-46a2-b354-072a996e8f16"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "Number of devices: 1\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 26)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 26, 128)      3456        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " gru (GRU)                      [(None, 26, 2048),   13381632    ['embedding[0][0]']              \n",
            "                                 (None, 2048)]                                                    \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 26)]         0           []                               \n",
            "                                                                                                  \n",
            " gru_1 (GRU)                    [(None, 26, 2048),   25178112    ['gru[0][0]']                    \n",
            "                                 (None, 2048)]                                                    \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 26, 128)      8192        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " gru_2 (GRU)                    [(None, 26, 2048),   25178112    ['gru_1[0][0]']                  \n",
            "                                 (None, 2048)]                                                    \n",
            "                                                                                                  \n",
            " gru_3 (GRU)                    [(None, 26, 2048),   13381632    ['embedding_1[0][0]',            \n",
            "                                 (None, 2048)]                    'gru_2[0][1]']                  \n",
            "                                                                                                  \n",
            " gru_4 (GRU)                    [(None, 26, 2048),   25178112    ['gru_3[0][0]',                  \n",
            "                                 (None, 2048)]                    'gru_2[0][1]']                  \n",
            "                                                                                                  \n",
            " gru_5 (GRU)                    [(None, 26, 2048),   25178112    ['gru_4[0][0]',                  \n",
            "                                 (None, 2048)]                    'gru_2[0][1]']                  \n",
            "                                                                                                  \n",
            " final (Dense)                  (None, 26, 64)       131136      ['gru_5[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 127,618,496\n",
            "Trainable params: 127,618,496\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "Epoch 1/20\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "791/791 [==============================] - 328s 403ms/step - loss: 1.0473 - accuracy: 0.7183 - _timestamp: 1650717747.0000 - _runtime: 376.0000\n",
            "Epoch 2/20\n",
            "791/791 [==============================] - 328s 415ms/step - loss: 0.7772 - accuracy: 0.7780 - _timestamp: 1650718076.0000 - _runtime: 705.0000\n",
            "Epoch 3/20\n",
            "791/791 [==============================] - 329s 416ms/step - loss: 0.5256 - accuracy: 0.8467 - _timestamp: 1650718405.0000 - _runtime: 1034.0000\n",
            "Epoch 4/20\n",
            "791/791 [==============================] - 329s 416ms/step - loss: 0.3118 - accuracy: 0.9080 - _timestamp: 1650718734.0000 - _runtime: 1363.0000\n",
            "Epoch 5/20\n",
            "791/791 [==============================] - 329s 416ms/step - loss: 0.1947 - accuracy: 0.9427 - _timestamp: 1650719064.0000 - _runtime: 1693.0000\n",
            "Epoch 6/20\n",
            "791/791 [==============================] - 330s 417ms/step - loss: 0.1280 - accuracy: 0.9627 - _timestamp: 1650719393.0000 - _runtime: 2022.0000\n",
            "Epoch 7/20\n",
            "791/791 [==============================] - 330s 417ms/step - loss: 0.0892 - accuracy: 0.9742 - _timestamp: 1650719723.0000 - _runtime: 2352.0000\n",
            "Epoch 8/20\n",
            "791/791 [==============================] - 330s 417ms/step - loss: 0.0648 - accuracy: 0.9814 - _timestamp: 1650720053.0000 - _runtime: 2682.0000\n",
            "Epoch 9/20\n",
            "791/791 [==============================] - 330s 417ms/step - loss: 0.0489 - accuracy: 0.9861 - _timestamp: 1650720382.0000 - _runtime: 3011.0000\n",
            "Epoch 10/20\n",
            "791/791 [==============================] - 330s 417ms/step - loss: 0.0376 - accuracy: 0.9894 - _timestamp: 1650720712.0000 - _runtime: 3341.0000\n",
            "Epoch 11/20\n",
            "791/791 [==============================] - 330s 417ms/step - loss: 0.0292 - accuracy: 0.9918 - _timestamp: 1650721042.0000 - _runtime: 3671.0000\n",
            "Epoch 12/20\n",
            "791/791 [==============================] - 329s 416ms/step - loss: 0.0242 - accuracy: 0.9932 - _timestamp: 1650721371.0000 - _runtime: 4000.0000\n",
            "Epoch 13/20\n",
            "791/791 [==============================] - 329s 417ms/step - loss: 0.0201 - accuracy: 0.9944 - _timestamp: 1650721701.0000 - _runtime: 4330.0000\n",
            "Epoch 14/20\n",
            "791/791 [==============================] - 330s 417ms/step - loss: 0.0176 - accuracy: 0.9951 - _timestamp: 1650722030.0000 - _runtime: 4659.0000\n",
            "Epoch 15/20\n",
            "791/791 [==============================] - 330s 417ms/step - loss: 0.0155 - accuracy: 0.9957 - _timestamp: 1650722360.0000 - _runtime: 4989.0000\n",
            "Epoch 16/20\n",
            "791/791 [==============================] - 330s 417ms/step - loss: 0.0144 - accuracy: 0.9960 - _timestamp: 1650722690.0000 - _runtime: 5319.0000\n",
            "Epoch 17/20\n",
            "791/791 [==============================] - 329s 416ms/step - loss: 0.0129 - accuracy: 0.9965 - _timestamp: 1650723019.0000 - _runtime: 5648.0000\n",
            "Epoch 18/20\n",
            "791/791 [==============================] - 330s 417ms/step - loss: 0.0122 - accuracy: 0.9966 - _timestamp: 1650723349.0000 - _runtime: 5978.0000\n",
            "Epoch 19/20\n",
            "791/791 [==============================] - 330s 417ms/step - loss: 0.0117 - accuracy: 0.9968 - _timestamp: 1650723679.0000 - _runtime: 6308.0000\n",
            "Epoch 20/20\n",
            "791/791 [==============================] - 330s 417ms/step - loss: 0.0114 - accuracy: 0.9969 - _timestamp: 1650724008.0000 - _runtime: 6637.0000\n",
            "success:2037\n",
            "success_char:30552\n",
            "Test word_val_acc0.40360610263522884\n",
            "Test char_val_acc0.7368497214383909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('best_model.h5')\n",
        "encoder_inference_model.save('best_encoder_inference_model.h5')\n",
        "decoder_inference_model.save('best_decoder_inference_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJvR3B6-2O-i",
        "outputId": "5bfa5190-5a5b-4cfd-d5ba-584248f37536"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    \"name\": \"Assignment 3 - deeper\",\n",
        "    \"method\": \"bayes\",\n",
        "    \"metric\":{\n",
        "      \"goal\": \"maximize\",\n",
        "      \"name\": \"word_val_acc\"\n",
        "    },\n",
        "    \"early_terminate\":{\n",
        "      \"type\": \"hyperband\",\n",
        "      \"min_iter\": 2,\n",
        "      \"eta\":2\n",
        "    },\n",
        "    \"project\": 'DeepLearningAssignment-3',\n",
        "    \"parameters\": {\n",
        "        \"rnn_type\": {\n",
        "            \"values\": [\"LSTM\",\"GRU\"]\n",
        "        },\n",
        "        \"dropout\": {\n",
        "            \"values\": [0.2,0.3,0.5]\n",
        "        },\n",
        "        \"encoder_layers\": {\n",
        "            \"values\": [2,3]\n",
        "        },\n",
        "        \"decoder_layers\": {\n",
        "            \"values\": [2,3]\n",
        "        },\n",
        "        \"latent_dim\": {\n",
        "            \"values\": [512,1024,2048]\n",
        "        },\n",
        "        \"epochs\": {\n",
        "            \"values\": [15,20]\n",
        "        },\n",
        "        \"lr\": {\n",
        "            \"values\": [0.0001]\n",
        "        },\n",
        "        \"embedding_out_dim\": {\n",
        "            \"values\":[64,128]\n",
        "        },\n",
        "        \"beam_search\":{\n",
        "            \"values\":[0]\n",
        "        },\n",
        "        \"batch_size\":{\n",
        "            \"values\":[64]\n",
        "        }\n",
        "        \n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "w5KOeeV13mvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sweep_id = wandb.sweep(sweep_config,  project='DeepLearningAssignment-3', entity='akshaygrao')\n",
        "# sweep_id = wandb.sweep(sweep_config,  project='DeepLearningAssignment-3', entity='cs21s002-ee21s113-dlassignment-1')\n",
        "sweep_id=\"ohk45oaz\""
      ],
      "metadata": {
        "id": "fag3IotW5Qu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb.agent(sweep_id, function=HP_tuning_run, project='DeepLearningAssignment-3', entity='akshaygrao')\n",
        "wandb.agent(sweep_id, function=HP_tuning_run, project='DeepLearningAssignment-3', entity='cs21s002-ee21s113-dlassignment-1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "23ab1f51e6ae4d24a447cd423ca94657",
            "de1c68e5618549899d8eceb2ad6ad948",
            "e5aa4a674003457a93574c7f6cc8e852",
            "0049410da8d94aee878200cde79de9c2",
            "2bce68c817b64db9986c9b9a2fc6327d",
            "989c8294a983424a81091bce004ae00e",
            "aae7f2c685674caaa137a8d7f5c40634",
            "59dc9006c19d4bdcabd0c1b0c0037ff9",
            "59f0e3f486304fc5b361c69bf57b0f94",
            "fbcd904475d347d39ae16a5502c5d86c",
            "67618043b3ad4a1898f09151d6f704ab",
            "ce19f921b4d04630a545e8a6c3f96c5c",
            "4e45dad536b04dbfa43d7a973f21e491",
            "7b4e82b9d35b4759a4f9f4bba4f3af43",
            "38672d75e40940768e52b84733a9ca1a",
            "1b6afb92558340349f3d677fff7e5a8c",
            "fbb84a37ba5c4b96ac6ef6c584729727",
            "f5649727a4824efcba6ceeebb0b7ceaf",
            "5aafbee7c74d479f9adf39da2e3ae9a1",
            "8357d04c5da343af80d361eb3fdc5e97",
            "146af33a97ec4a2bbf91522b8789684c",
            "f851e6a1d05a42ad8427510a5ce5df90",
            "297bb89a3bca42329e00ae6fcee22194",
            "8b80d791384e481faeea98a3f3c43e60",
            "b0e778d7fa084b5c9906957c2e5c83bb",
            "551e824634754e058746f0536023e4df",
            "493c7b3dcf6148e9927804da23732819",
            "fda5743770014c82884d6193180e6a07",
            "9dae80c316eb4a9ab676442887be6401",
            "ea3cb6bd96834c239f4201dcae688fb6",
            "17d9c7005ad2413bb1575f26017f14ae",
            "4b5ec3de779b41a998330fb682630a0d",
            "59e2e1521dbd4a95b329c84ad09c1225",
            "f1e9626b2d7145e2834016cbd20fe9b0",
            "41baf373e261420d9e7d8c5e38d7989b",
            "6c5b6f3ecd634129ae47ae999b0d3aae",
            "908972d85db240bc93bff92d3bd90dfe",
            "2a5635f08072406fb8dedbd5b21726c2",
            "27a478c6116e473ea55808fa266cb083",
            "82d2e1f0ff0c469c8e35eb03e22f9240"
          ]
        },
        "id": "itgfsYWC5oCn",
        "outputId": "2db425fe-c34f-452a-a4f0-d3cd3155cffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ly8xpgof with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_search: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_out_dim: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatent_dim: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trnn_type: LSTM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "Number of devices: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.14"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220421_102537-ly8xpgof</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3/runs/ly8xpgof\" target=\"_blank\">super-sweep-5</a></strong> to <a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3/sweeps/ohk45oaz\" target=\"_blank\">https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3/sweeps/ohk45oaz</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:ly8xpgof) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23ab1f51e6ae4d24a447cd423ca94657"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">super-sweep-5</strong>: <a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3/runs/ly8xpgof\" target=\"_blank\">https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3/runs/ly8xpgof</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220421_102537-ly8xpgof/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:ly8xpgof). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.14"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220421_102543-ly8xpgof</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3/runs/ly8xpgof\" target=\"_blank\">super-sweep-5</a></strong> to <a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3/sweeps/ohk45oaz\" target=\"_blank\">https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3/sweeps/ohk45oaz</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config: {'batch_size': 64, 'beam_search': 0, 'decoder_layers': 2, 'dropout': 0.2, 'embedding_out_dim': 128, 'encoder_layers': 2, 'epochs': 20, 'latent_dim': 512, 'lr': 0.0001, 'rnn_type': 'LSTM'}\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 26)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 26, 128)      3456        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 26)]         0           []                               \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 26, 512),    1312768     ['embedding[0][0]']              \n",
            "                                 (None, 512),                                                     \n",
            "                                 (None, 512)]                                                     \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 26, 128)      8192        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, 26, 512),    2099200     ['lstm[0][0]']                   \n",
            "                                 (None, 512),                                                     \n",
            "                                 (None, 512)]                                                     \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, 26, 512),    1312768     ['embedding_1[0][0]',            \n",
            "                                 (None, 512),                     'lstm_1[0][1]',                 \n",
            "                                 (None, 512)]                     'lstm_1[0][2]']                 \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, 26, 512),    2099200     ['lstm_2[0][0]',                 \n",
            "                                 (None, 512),                     'lstm_1[0][1]',                 \n",
            "                                 (None, 512)]                     'lstm_1[0][2]']                 \n",
            "                                                                                                  \n",
            " final (Dense)                  (None, 26, 64)       32832       ['lstm_3[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 6,868,416\n",
            "Trainable params: 6,868,416\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "Epoch 1/20\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "791/791 [==============================] - 80s 84ms/step - loss: 1.2223 - accuracy: 0.6873 - _timestamp: 1650536836.0000 - _runtime: 89.0000\n",
            "Epoch 2/20\n",
            "791/791 [==============================] - 67s 84ms/step - loss: 0.9488 - accuracy: 0.7362 - _timestamp: 1650536903.0000 - _runtime: 156.0000\n",
            "Epoch 3/20\n",
            "791/791 [==============================] - 66s 84ms/step - loss: 0.8593 - accuracy: 0.7543 - _timestamp: 1650536969.0000 - _runtime: 222.0000\n",
            "Epoch 4/20\n",
            "791/791 [==============================] - 66s 83ms/step - loss: 0.7850 - accuracy: 0.7755 - _timestamp: 1650537035.0000 - _runtime: 288.0000\n",
            "Epoch 5/20\n",
            "791/791 [==============================] - 66s 84ms/step - loss: 0.6897 - accuracy: 0.8014 - _timestamp: 1650537101.0000 - _runtime: 354.0000\n",
            "Epoch 6/20\n",
            "791/791 [==============================] - 66s 84ms/step - loss: 0.6069 - accuracy: 0.8253 - _timestamp: 1650537167.0000 - _runtime: 420.0000\n",
            "Epoch 7/20\n",
            "791/791 [==============================] - 66s 84ms/step - loss: 0.5218 - accuracy: 0.8490 - _timestamp: 1650537233.0000 - _runtime: 486.0000\n",
            "Epoch 8/20\n",
            "791/791 [==============================] - 66s 84ms/step - loss: 0.4515 - accuracy: 0.8684 - _timestamp: 1650537300.0000 - _runtime: 553.0000\n",
            "Epoch 9/20\n",
            "791/791 [==============================] - 66s 84ms/step - loss: 0.3916 - accuracy: 0.8854 - _timestamp: 1650537366.0000 - _runtime: 619.0000\n",
            "Epoch 10/20\n",
            "791/791 [==============================] - 66s 83ms/step - loss: 0.3413 - accuracy: 0.8997 - _timestamp: 1650537432.0000 - _runtime: 685.0000\n",
            "Epoch 11/20\n",
            "791/791 [==============================] - 66s 83ms/step - loss: 0.2986 - accuracy: 0.9119 - _timestamp: 1650537498.0000 - _runtime: 751.0000\n",
            "Epoch 12/20\n",
            "791/791 [==============================] - 66s 83ms/step - loss: 0.2625 - accuracy: 0.9223 - _timestamp: 1650537563.0000 - _runtime: 816.0000\n",
            "Epoch 13/20\n",
            "791/791 [==============================] - 66s 83ms/step - loss: 0.2327 - accuracy: 0.9311 - _timestamp: 1650537629.0000 - _runtime: 882.0000\n",
            "Epoch 14/20\n",
            "791/791 [==============================] - 66s 83ms/step - loss: 0.2084 - accuracy: 0.9382 - _timestamp: 1650537695.0000 - _runtime: 948.0000\n",
            "Epoch 15/20\n",
            "791/791 [==============================] - 66s 83ms/step - loss: 0.1867 - accuracy: 0.9448 - _timestamp: 1650537761.0000 - _runtime: 1014.0000\n",
            "Epoch 16/20\n",
            "791/791 [==============================] - 66s 84ms/step - loss: 0.1684 - accuracy: 0.9501 - _timestamp: 1650537827.0000 - _runtime: 1080.0000\n",
            "Epoch 17/20\n",
            "791/791 [==============================] - 66s 83ms/step - loss: 0.1525 - accuracy: 0.9549 - _timestamp: 1650537893.0000 - _runtime: 1146.0000\n",
            "Epoch 18/20\n",
            "791/791 [==============================] - 67s 84ms/step - loss: 0.1390 - accuracy: 0.9589 - _timestamp: 1650537960.0000 - _runtime: 1213.0000\n",
            "Epoch 19/20\n",
            "791/791 [==============================] - 66s 84ms/step - loss: 0.1264 - accuracy: 0.9626 - _timestamp: 1650538026.0000 - _runtime: 1279.0000\n",
            "Epoch 20/20\n",
            "791/791 [==============================] - 66s 84ms/step - loss: 0.1153 - accuracy: 0.9660 - _timestamp: 1650538092.0000 - _runtime: 1345.0000\n",
            "success:1390\n",
            "success_char:25819\n",
            "word_val_acc0.27650686294012333\n",
            "char_val_acc0.635685444159937\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.590 MB of 0.590 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59f0e3f486304fc5b361c69bf57b0f94"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▂▃▃▄▄▅▆▆▆▇▇▇▇▇█████</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▆▆▅▅▄▄▃▃▂▂▂▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.96602</td></tr><tr><td>char_val_acc</td><td>0.63569</td></tr><tr><td>epoch</td><td>19</td></tr><tr><td>language</td><td>kn</td></tr><tr><td>loss</td><td>0.1153</td></tr><tr><td>word_val_acc</td><td>0.27651</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">super-sweep-5</strong>: <a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3/runs/ly8xpgof\" target=\"_blank\">https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3/runs/ly8xpgof</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220421_102543-ly8xpgof/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: psqw09bp with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_search: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_out_dim: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatent_dim: 2048\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trnn_type: LSTM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "Number of devices: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.14"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220421_104909-psqw09bp</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3/runs/psqw09bp\" target=\"_blank\">light-sweep-8</a></strong> to <a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3/sweeps/ohk45oaz\" target=\"_blank\">https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3/sweeps/ohk45oaz</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config: {'batch_size': 64, 'beam_search': 0, 'decoder_layers': 2, 'dropout': 0.5, 'embedding_out_dim': 64, 'encoder_layers': 3, 'epochs': 15, 'latent_dim': 2048, 'lr': 0.0001, 'rnn_type': 'LSTM'}\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 26)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 26, 64)       1728        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 26, 2048),   17309696    ['embedding[0][0]']              \n",
            "                                 (None, 2048),                                                    \n",
            "                                 (None, 2048)]                                                    \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 26)]         0           []                               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, 26, 2048),   33562624    ['lstm[0][0]']                   \n",
            "                                 (None, 2048),                                                    \n",
            "                                 (None, 2048)]                                                    \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 26, 64)       4096        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, 26, 2048),   33562624    ['lstm_1[0][0]']                 \n",
            "                                 (None, 2048),                                                    \n",
            "                                 (None, 2048)]                                                    \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, 26, 2048),   17309696    ['embedding_1[0][0]',            \n",
            "                                 (None, 2048),                    'lstm_2[0][1]',                 \n",
            "                                 (None, 2048)]                    'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " lstm_4 (LSTM)                  [(None, 26, 2048),   33562624    ['lstm_3[0][0]',                 \n",
            "                                 (None, 2048),                    'lstm_2[0][1]',                 \n",
            "                                 (None, 2048)]                    'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " final (Dense)                  (None, 26, 64)       131136      ['lstm_4[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 135,444,224\n",
            "Trainable params: 135,444,224\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/15\n",
            "791/791 [==============================] - 705s 879ms/step - loss: 1.1700 - accuracy: 0.6892 - _timestamp: 1650538893.0000 - _runtime: 744.0000\n",
            "Epoch 2/15\n",
            "791/791 [==============================] - 697s 882ms/step - loss: 0.8438 - accuracy: 0.7567 - _timestamp: 1650539591.0000 - _runtime: 1442.0000\n",
            "Epoch 3/15\n",
            "791/791 [==============================] - 696s 880ms/step - loss: 0.6465 - accuracy: 0.8079 - _timestamp: 1650540287.0000 - _runtime: 2138.0000\n",
            "Epoch 4/15\n",
            "791/791 [==============================] - 698s 882ms/step - loss: 0.4794 - accuracy: 0.8557 - _timestamp: 1650540984.0000 - _runtime: 2835.0000\n",
            "Epoch 5/15\n",
            "791/791 [==============================] - 695s 879ms/step - loss: 0.3644 - accuracy: 0.8894 - _timestamp: 1650541679.0000 - _runtime: 3530.0000\n",
            "Epoch 6/15\n",
            "791/791 [==============================] - 696s 880ms/step - loss: 0.2838 - accuracy: 0.9137 - _timestamp: 1650542376.0000 - _runtime: 4227.0000\n",
            "Epoch 7/15\n",
            "791/791 [==============================] - 694s 877ms/step - loss: 0.2224 - accuracy: 0.9325 - _timestamp: 1650543070.0000 - _runtime: 4921.0000\n",
            "Epoch 8/15\n",
            "791/791 [==============================] - 694s 877ms/step - loss: 0.1774 - accuracy: 0.9461 - _timestamp: 1650543763.0000 - _runtime: 5614.0000\n",
            "Epoch 9/15\n",
            "791/791 [==============================] - 693s 876ms/step - loss: 0.1420 - accuracy: 0.9569 - _timestamp: 1650544457.0000 - _runtime: 6308.0000\n",
            "Epoch 10/15\n",
            "791/791 [==============================] - 694s 877ms/step - loss: 0.1155 - accuracy: 0.9649 - _timestamp: 1650545150.0000 - _runtime: 7001.0000\n",
            "Epoch 11/15\n",
            "791/791 [==============================] - 694s 878ms/step - loss: 0.0938 - accuracy: 0.9716 - _timestamp: 1650545845.0000 - _runtime: 7696.0000\n",
            "Epoch 12/15\n",
            "791/791 [==============================] - 695s 878ms/step - loss: 0.0771 - accuracy: 0.9766 - _timestamp: 1650546539.0000 - _runtime: 8390.0000\n",
            "Epoch 13/15\n",
            "791/791 [==============================] - 694s 877ms/step - loss: 0.0640 - accuracy: 0.9806 - _timestamp: 1650547233.0000 - _runtime: 9084.0000\n",
            "Epoch 14/15\n",
            "749/791 [===========================>..] - ETA: 36s - loss: 0.0529 - accuracy: 0.9840"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Error while calling W&B API: context deadline exceeded (<Response [500]>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "791/791 [==============================] - 695s 878ms/step - loss: 0.0530 - accuracy: 0.9840 - _timestamp: 1650547927.0000 - _runtime: 9778.0000\n",
            "Epoch 15/15\n",
            "791/791 [==============================] - 695s 878ms/step - loss: 0.0455 - accuracy: 0.9862 - _timestamp: 1650548622.0000 - _runtime: 10473.0000\n",
            "success:1397\n",
            "success_char:26590\n",
            "word_val_acc0.2778993435448578\n",
            "char_val_acc0.654668111089226\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.726 MB of 0.726 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbb84a37ba5c4b96ac6ef6c584729727"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▃▄▅▆▆▇▇▇▇█████</td></tr><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>loss</td><td>█▆▅▄▃▂▂▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.98625</td></tr><tr><td>char_val_acc</td><td>0.65467</td></tr><tr><td>epoch</td><td>14</td></tr><tr><td>language</td><td>kn</td></tr><tr><td>loss</td><td>0.04547</td></tr><tr><td>word_val_acc</td><td>0.2779</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">light-sweep-8</strong>: <a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3/runs/psqw09bp\" target=\"_blank\">https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3/runs/psqw09bp</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220421_104909-psqw09bp/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dsi6b3bf with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_search: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_out_dim: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatent_dim: 1024\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trnn_type: LSTM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "Number of devices: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.14"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220421_134702-dsi6b3bf</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3/runs/dsi6b3bf\" target=\"_blank\">ruby-sweep-13</a></strong> to <a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3/sweeps/ohk45oaz\" target=\"_blank\">https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3/sweeps/ohk45oaz</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config: {'batch_size': 64, 'beam_search': 0, 'decoder_layers': 3, 'dropout': 0.2, 'embedding_out_dim': 64, 'encoder_layers': 3, 'epochs': 20, 'latent_dim': 1024, 'lr': 0.0001, 'rnn_type': 'LSTM'}\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 26)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 26, 64)       1728        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 26, 1024),   4460544     ['embedding[0][0]']              \n",
            "                                 (None, 1024),                                                    \n",
            "                                 (None, 1024)]                                                    \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 26)]         0           []                               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, 26, 1024),   8392704     ['lstm[0][0]']                   \n",
            "                                 (None, 1024),                                                    \n",
            "                                 (None, 1024)]                                                    \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 26, 64)       4096        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, 26, 1024),   8392704     ['lstm_1[0][0]']                 \n",
            "                                 (None, 1024),                                                    \n",
            "                                 (None, 1024)]                                                    \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, 26, 1024),   4460544     ['embedding_1[0][0]',            \n",
            "                                 (None, 1024),                    'lstm_2[0][1]',                 \n",
            "                                 (None, 1024)]                    'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " lstm_4 (LSTM)                  [(None, 26, 1024),   8392704     ['lstm_3[0][0]',                 \n",
            "                                 (None, 1024),                    'lstm_2[0][1]',                 \n",
            "                                 (None, 1024)]                    'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " lstm_5 (LSTM)                  [(None, 26, 1024),   8392704     ['lstm_4[0][0]',                 \n",
            "                                 (None, 1024),                    'lstm_2[0][1]',                 \n",
            "                                 (None, 1024)]                    'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " final (Dense)                  (None, 26, 64)       65600       ['lstm_5[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 42,563,328\n",
            "Trainable params: 42,563,328\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "791/791 [==============================] - 262s 318ms/step - loss: 1.2074 - accuracy: 0.6787 - _timestamp: 1650549100.0000 - _runtime: 278.0000\n",
            "Epoch 2/20\n",
            "791/791 [==============================] - 252s 318ms/step - loss: 0.8917 - accuracy: 0.7476 - _timestamp: 1650549351.0000 - _runtime: 529.0000\n",
            "Epoch 3/20\n",
            "791/791 [==============================] - 252s 318ms/step - loss: 0.7089 - accuracy: 0.7936 - _timestamp: 1650549603.0000 - _runtime: 781.0000\n",
            "Epoch 4/20\n",
            "791/791 [==============================] - 252s 318ms/step - loss: 0.5638 - accuracy: 0.8347 - _timestamp: 1650549855.0000 - _runtime: 1033.0000\n",
            "Epoch 5/20\n",
            "791/791 [==============================] - 252s 318ms/step - loss: 0.4504 - accuracy: 0.8669 - _timestamp: 1650550106.0000 - _runtime: 1284.0000\n",
            "Epoch 6/20\n",
            "791/791 [==============================] - 251s 317ms/step - loss: 0.3614 - accuracy: 0.8932 - _timestamp: 1650550357.0000 - _runtime: 1535.0000\n",
            "Epoch 7/20\n",
            "791/791 [==============================] - 252s 319ms/step - loss: 0.2921 - accuracy: 0.9138 - _timestamp: 1650550609.0000 - _runtime: 1787.0000\n",
            "Epoch 8/20\n",
            "791/791 [==============================] - 251s 318ms/step - loss: 0.2383 - accuracy: 0.9298 - _timestamp: 1650550860.0000 - _runtime: 2038.0000\n",
            "Epoch 9/20\n",
            "791/791 [==============================] - 251s 318ms/step - loss: 0.1964 - accuracy: 0.9422 - _timestamp: 1650551112.0000 - _runtime: 2290.0000\n",
            "Epoch 10/20\n",
            "791/791 [==============================] - 252s 318ms/step - loss: 0.1630 - accuracy: 0.9520 - _timestamp: 1650551363.0000 - _runtime: 2541.0000\n",
            "Epoch 11/20\n",
            "791/791 [==============================] - 251s 318ms/step - loss: 0.1362 - accuracy: 0.9599 - _timestamp: 1650551615.0000 - _runtime: 2793.0000\n",
            "Epoch 12/20\n",
            "791/791 [==============================] - 251s 318ms/step - loss: 0.1143 - accuracy: 0.9663 - _timestamp: 1650551866.0000 - _runtime: 3044.0000\n",
            "Epoch 13/20\n",
            "791/791 [==============================] - 251s 318ms/step - loss: 0.0962 - accuracy: 0.9718 - _timestamp: 1650552117.0000 - _runtime: 3295.0000\n",
            "Epoch 14/20\n",
            "791/791 [==============================] - 252s 318ms/step - loss: 0.0813 - accuracy: 0.9764 - _timestamp: 1650552369.0000 - _runtime: 3547.0000\n",
            "Epoch 15/20\n",
            "791/791 [==============================] - 251s 318ms/step - loss: 0.0695 - accuracy: 0.9798 - _timestamp: 1650552620.0000 - _runtime: 3798.0000\n",
            "Epoch 16/20\n",
            "791/791 [==============================] - 251s 317ms/step - loss: 0.0596 - accuracy: 0.9827 - _timestamp: 1650552871.0000 - _runtime: 4049.0000\n",
            "Epoch 17/20\n",
            "791/791 [==============================] - 251s 317ms/step - loss: 0.0515 - accuracy: 0.9850 - _timestamp: 1650553122.0000 - _runtime: 4300.0000\n",
            "Epoch 18/20\n",
            "791/791 [==============================] - 251s 317ms/step - loss: 0.0451 - accuracy: 0.9870 - _timestamp: 1650553373.0000 - _runtime: 4551.0000\n",
            "Epoch 19/20\n",
            "791/791 [==============================] - 251s 317ms/step - loss: 0.0397 - accuracy: 0.9886 - _timestamp: 1650553623.0000 - _runtime: 4801.0000\n",
            "Epoch 20/20\n",
            "791/791 [==============================] - 251s 317ms/step - loss: 0.0351 - accuracy: 0.9899 - _timestamp: 1650553874.0000 - _runtime: 5052.0000\n",
            "success:1341\n",
            "success_char:26348\n",
            "word_val_acc0.2667594987069823\n",
            "char_val_acc0.6487098680323026\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.859 MB of 0.859 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0e778d7fa084b5c9906957c2e5c83bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▃▄▅▅▆▆▇▇▇▇▇████████</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.98985</td></tr><tr><td>char_val_acc</td><td>0.64871</td></tr><tr><td>epoch</td><td>19</td></tr><tr><td>language</td><td>kn</td></tr><tr><td>loss</td><td>0.03512</td></tr><tr><td>word_val_acc</td><td>0.26676</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">ruby-sweep-13</strong>: <a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3/runs/dsi6b3bf\" target=\"_blank\">https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3/runs/dsi6b3bf</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220421_134702-dsi6b3bf/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 59n4lex2 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_search: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_out_dim: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatent_dim: 2048\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trnn_type: GRU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "Number of devices: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.14"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220421_151322-59n4lex2</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3/runs/59n4lex2\" target=\"_blank\">glorious-sweep-14</a></strong> to <a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3/sweeps/ohk45oaz\" target=\"_blank\">https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3/sweeps/ohk45oaz</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config: {'batch_size': 64, 'beam_search': 0, 'decoder_layers': 2, 'dropout': 0.5, 'embedding_out_dim': 64, 'encoder_layers': 2, 'epochs': 15, 'latent_dim': 2048, 'lr': 0.0001, 'rnn_type': 'GRU'}\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 26)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 26, 64)       1728        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 26)]         0           []                               \n",
            "                                                                                                  \n",
            " gru (GRU)                      [(None, 26, 2048),   12988416    ['embedding[0][0]']              \n",
            "                                 (None, 2048)]                                                    \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 26, 64)       4096        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " gru_1 (GRU)                    [(None, 26, 2048),   25178112    ['gru[0][0]']                    \n",
            "                                 (None, 2048)]                                                    \n",
            "                                                                                                  \n",
            " gru_2 (GRU)                    [(None, 26, 2048),   12988416    ['embedding_1[0][0]',            \n",
            "                                 (None, 2048)]                    'gru_1[0][1]']                  \n",
            "                                                                                                  \n",
            " gru_3 (GRU)                    [(None, 26, 2048),   25178112    ['gru_2[0][0]',                  \n",
            "                                 (None, 2048)]                    'gru_1[0][1]']                  \n",
            "                                                                                                  \n",
            " final (Dense)                  (None, 26, 64)       131136      ['gru_3[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 76,470,016\n",
            "Trainable params: 76,470,016\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/15\n",
            "791/791 [==============================] - 413s 512ms/step - loss: 1.1368 - accuracy: 0.7017 - _timestamp: 1650554439.0000 - _runtime: 437.0000\n",
            "Epoch 2/15\n",
            "791/791 [==============================] - 408s 516ms/step - loss: 0.8849 - accuracy: 0.7494 - _timestamp: 1650554847.0000 - _runtime: 845.0000\n",
            "Epoch 3/15\n",
            "791/791 [==============================] - 407s 515ms/step - loss: 0.7612 - accuracy: 0.7815 - _timestamp: 1650555254.0000 - _runtime: 1252.0000\n",
            "Epoch 4/15\n",
            "791/791 [==============================] - 408s 515ms/step - loss: 0.6118 - accuracy: 0.8210 - _timestamp: 1650555662.0000 - _runtime: 1660.0000\n",
            "Epoch 5/15\n",
            "791/791 [==============================] - 408s 515ms/step - loss: 0.4660 - accuracy: 0.8611 - _timestamp: 1650556069.0000 - _runtime: 2067.0000\n",
            "Epoch 6/15\n",
            "791/791 [==============================] - 406s 514ms/step - loss: 0.3634 - accuracy: 0.8912 - _timestamp: 1650556476.0000 - _runtime: 2474.0000\n",
            "Epoch 7/15\n",
            "791/791 [==============================] - 405s 513ms/step - loss: 0.2876 - accuracy: 0.9136 - _timestamp: 1650556881.0000 - _runtime: 2879.0000\n",
            "Epoch 8/15\n",
            "791/791 [==============================] - 405s 512ms/step - loss: 0.2295 - accuracy: 0.9310 - _timestamp: 1650557286.0000 - _runtime: 3284.0000\n",
            "Epoch 9/15\n",
            "791/791 [==============================] - 405s 512ms/step - loss: 0.1836 - accuracy: 0.9450 - _timestamp: 1650557691.0000 - _runtime: 3689.0000\n",
            "Epoch 10/15\n",
            "791/791 [==============================] - 405s 512ms/step - loss: 0.1453 - accuracy: 0.9567 - _timestamp: 1650558096.0000 - _runtime: 4094.0000\n",
            "Epoch 11/15\n",
            "791/791 [==============================] - 403s 510ms/step - loss: 0.1151 - accuracy: 0.9658 - _timestamp: 1650558499.0000 - _runtime: 4497.0000\n",
            "Epoch 12/15\n",
            "791/791 [==============================] - 403s 510ms/step - loss: 0.0914 - accuracy: 0.9730 - _timestamp: 1650558902.0000 - _runtime: 4900.0000\n",
            "Epoch 13/15\n",
            "791/791 [==============================] - 404s 511ms/step - loss: 0.0722 - accuracy: 0.9788 - _timestamp: 1650559306.0000 - _runtime: 5304.0000\n",
            "Epoch 14/15\n",
            "791/791 [==============================] - 405s 513ms/step - loss: 0.0577 - accuracy: 0.9833 - _timestamp: 1650559712.0000 - _runtime: 5710.0000\n",
            "Epoch 15/15\n",
            "791/791 [==============================] - 405s 512ms/step - loss: 0.0466 - accuracy: 0.9866 - _timestamp: 1650560117.0000 - _runtime: 6115.0000\n",
            "success:1591\n",
            "success_char:27698\n",
            "word_val_acc0.3164909488760692\n",
            "char_val_acc0.6819480007878669\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.552 MB of 0.552 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59e2e1521dbd4a95b329c84ad09c1225"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▂▃▄▅▆▆▇▇▇▇████</td></tr><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>loss</td><td>█▆▆▅▄▃▃▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.9866</td></tr><tr><td>char_val_acc</td><td>0.68195</td></tr><tr><td>epoch</td><td>14</td></tr><tr><td>language</td><td>kn</td></tr><tr><td>loss</td><td>0.04659</td></tr><tr><td>word_val_acc</td><td>0.31649</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">glorious-sweep-14</strong>: <a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3/runs/59n4lex2\" target=\"_blank\">https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3/runs/59n4lex2</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220421_151322-59n4lex2/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bgd4n6as with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_search: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_out_dim: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatent_dim: 1024\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trnn_type: LSTM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "Number of devices: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "wandb version 0.12.15 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.14"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220421_165708-bgd4n6as</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3/runs/bgd4n6as\" target=\"_blank\">effortless-sweep-17</a></strong> to <a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3/sweeps/ohk45oaz\" target=\"_blank\">https://wandb.ai/cs21s002-ee21s113-dlassignment-1/DeepLearningAssignment-3/sweeps/ohk45oaz</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config: {'batch_size': 64, 'beam_search': 0, 'decoder_layers': 2, 'dropout': 0.2, 'embedding_out_dim': 64, 'encoder_layers': 3, 'epochs': 20, 'latent_dim': 1024, 'lr': 0.0001, 'rnn_type': 'LSTM'}\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 26)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 26, 64)       1728        ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 26, 1024),   4460544     ['embedding[0][0]']              \n",
            "                                 (None, 1024),                                                    \n",
            "                                 (None, 1024)]                                                    \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 26)]         0           []                               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, 26, 1024),   8392704     ['lstm[0][0]']                   \n",
            "                                 (None, 1024),                                                    \n",
            "                                 (None, 1024)]                                                    \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 26, 64)       4096        ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, 26, 1024),   8392704     ['lstm_1[0][0]']                 \n",
            "                                 (None, 1024),                                                    \n",
            "                                 (None, 1024)]                                                    \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, 26, 1024),   4460544     ['embedding_1[0][0]',            \n",
            "                                 (None, 1024),                    'lstm_2[0][1]',                 \n",
            "                                 (None, 1024)]                    'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " lstm_4 (LSTM)                  [(None, 26, 1024),   8392704     ['lstm_3[0][0]',                 \n",
            "                                 (None, 1024),                    'lstm_2[0][1]',                 \n",
            "                                 (None, 1024)]                    'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " final (Dense)                  (None, 26, 64)       65600       ['lstm_4[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 34,170,624\n",
            "Trainable params: 34,170,624\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/20\n",
            "791/791 [==============================] - 217s 261ms/step - loss: 1.1840 - accuracy: 0.6877 - _timestamp: 1650560459.0000 - _runtime: 231.0000\n",
            "Epoch 2/20\n",
            "791/791 [==============================] - 207s 262ms/step - loss: 0.9068 - accuracy: 0.7442 - _timestamp: 1650560666.0000 - _runtime: 438.0000\n",
            "Epoch 3/20\n",
            "791/791 [==============================] - 208s 263ms/step - loss: 0.7511 - accuracy: 0.7816 - _timestamp: 1650560874.0000 - _runtime: 646.0000\n",
            "Epoch 4/20\n",
            "791/791 [==============================] - 208s 263ms/step - loss: 0.6005 - accuracy: 0.8233 - _timestamp: 1650561082.0000 - _runtime: 854.0000\n",
            "Epoch 5/20\n",
            "791/791 [==============================] - 208s 262ms/step - loss: 0.4707 - accuracy: 0.8607 - _timestamp: 1650561289.0000 - _runtime: 1061.0000\n",
            "Epoch 6/20\n",
            "791/791 [==============================] - 208s 262ms/step - loss: 0.3759 - accuracy: 0.8891 - _timestamp: 1650561497.0000 - _runtime: 1269.0000\n",
            "Epoch 7/20\n",
            "594/791 [=====================>........] - ETA: 51s - loss: 0.3075 - accuracy: 0.9095"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model('LSTM',32,2,3,0.3,64)"
      ],
      "metadata": {
        "id": "ogRAn6HcdRL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\", loss=keras.losses.SparseCategoricalCrossentropy(reduction='none'), metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "TzZNiKxOGs61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist=model.fit([train_input_tensor, train_target_tensor],tf.concat([train_target_tensor[:,1:],tf.zeros((train_target_tensor[:,:].shape[0],1))], axis=1),batch_size=32,epochs=5,shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GxbPO6Yf6Fx",
        "outputId": "8df71187-b08d-46eb-d9dd-cb7c6a0e42ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1582/1582 [==============================] - 128s 75ms/step - loss: 1.1101 - accuracy: 0.7040\n",
            "Epoch 2/5\n",
            "1582/1582 [==============================] - 99s 63ms/step - loss: 0.8731 - accuracy: 0.7526\n",
            "Epoch 3/5\n",
            "1582/1582 [==============================] - 98s 62ms/step - loss: 0.7464 - accuracy: 0.7873\n",
            "Epoch 4/5\n",
            "1582/1582 [==============================] - 99s 63ms/step - loss: 0.6210 - accuracy: 0.8208\n",
            "Epoch 5/5\n",
            "1582/1582 [==============================] - 97s 62ms/step - loss: 0.5348 - accuracy: 0.8442\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "model.save(\"s2s.keras\")\n",
        "# Run inferencing\n",
        "# Restore the model and construct the encoder and decoder.\n",
        "inf = keras.models.load_model(\"/content/s2s.keras\")\n",
        "encoder_model,decoder_model=build_inference_model(inf,encoder_layers=2,decoder_layers=3,latent_dim=64)"
      ],
      "metadata": {
        "id": "_4PpsZv6mahJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_acc,char_val_acc = batch_validate('LSTM',encoder_model,decoder_model,2,3)\n",
        "print(\"val_acc:\"+str(val_acc))\n",
        "print(\"char_val_acc:\"+str(char_val_acc))"
      ],
      "metadata": {
        "id": "6tA98ue0meqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-hBu8EDUmm-f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}