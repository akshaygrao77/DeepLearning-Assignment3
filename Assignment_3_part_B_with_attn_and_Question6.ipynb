{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_3_part_B_with_attn_and_Question6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshaygrao77/DeepLearning-Assignment3/blob/main/Assignment_3_part_B_with_attn_and_Question6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2vkvje2XA3r"
      },
      "source": [
        "# CS6910 Assignment 3 -part-B-with attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0qCvgqBxzLo",
        "outputId": "0f02665b-ba53-4f41-a14c-24346572cef1"
      },
      "source": [
        "!pip install wandb\n",
        "!pip install wordcloud\n",
        "!pip install colour"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.12.16-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[?25l\r\u001b[K     |▏                               | 10 kB 18.3 MB/s eta 0:00:01\r\u001b[K     |▍                               | 20 kB 22.8 MB/s eta 0:00:01\r\u001b[K     |▌                               | 30 kB 12.1 MB/s eta 0:00:01\r\u001b[K     |▊                               | 40 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |█                               | 51 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█                               | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 81 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 92 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██                              | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███                             | 163 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 174 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 184 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 194 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 204 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 215 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████                            | 225 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 235 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 245 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 256 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 266 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████                           | 276 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 286 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 296 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 307 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 317 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 327 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████                          | 337 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 348 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 358 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 368 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 378 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████                         | 389 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 399 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 409 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 419 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 430 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 440 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████                        | 450 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 460 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 471 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 481 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 491 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 501 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 512 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 522 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 532 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 542 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 552 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 563 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 573 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 583 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 593 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 604 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 614 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 624 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 634 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 645 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 655 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 665 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 675 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 686 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 696 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 706 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 716 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 727 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 737 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 747 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 757 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 768 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 778 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 788 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 798 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 808 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 819 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 829 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 839 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 849 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 860 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 870 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 880 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 890 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 901 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 911 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 921 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 931 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 942 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 952 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 962 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 972 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 983 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 993 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.0 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.0 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.0 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.0 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.0 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.2 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.2 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.2 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.2 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.2 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.2 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.2 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.2 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.2 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.2 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.3 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.3 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.3 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.3 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.3 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.3 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.3 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.3 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.3 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.4 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.4 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.4 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.4 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.4 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.4 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.4 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.4 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.4 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.4 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.5 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.5 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.5 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.5 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.5 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.5 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.5 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.5 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.5 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.5 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.6 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.6 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.6 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.6 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.6 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.6 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.6 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.6 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.6 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.6 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.7 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.7 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.7 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.7 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.7 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.7 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.7 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.7 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.7 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.8 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.8 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.8 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.8 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.8 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.11-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 50.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 50.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.2.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=42545e37aad64d1b5ab16f3a261cbe7bb557810764b5c16f87a18e176a3fa7a6\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.11 setproctitle-1.2.3 shortuuid-1.0.8 smmap-5.0.0 wandb-0.12.16\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (1.5.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from wordcloud) (7.1.2)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from wordcloud) (1.21.6)\n",
            "Collecting colour\n",
            "  Downloading colour-0.1.5-py2.py3-none-any.whl (23 kB)\n",
            "Installing collected packages: colour\n",
            "Successfully installed colour-0.1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VffbVoa3r-Lq",
        "outputId": "fe156e8a-62a4-42a4-adc4-14de8ecbeaca"
      },
      "source": [
        "## Installing font for kannada for matplotlib ##\n",
        "!apt-get install -y fonts-lohit-deva\n",
        "!fc-list : family \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  libnvidia-common-460 nsight-compute-2020.2.0\n",
            "Use 'apt autoremove' to remove them.\n",
            "The following NEW packages will be installed:\n",
            "  fonts-lohit-deva\n",
            "0 upgraded, 1 newly installed, 0 to remove and 42 not upgraded.\n",
            "Need to get 78.2 kB of archives.\n",
            "After this operation, 196 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-lohit-deva all 2.95.4-2 [78.2 kB]\n",
            "Fetched 78.2 kB in 0s (252 kB/s)\n",
            "Selecting previously unselected package fonts-lohit-deva.\n",
            "(Reading database ... 155203 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-lohit-deva_2.95.4-2_all.deb ...\n",
            "Unpacking fonts-lohit-deva (2.95.4-2) ...\n",
            "Setting up fonts-lohit-deva (2.95.4-2) ...\n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "Liberation Sans Narrow\n",
            "Liberation Mono\n",
            "Liberation Serif\n",
            "Humor Sans\n",
            "Liberation Sans\n",
            "Lohit Devanagari\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6xB0KDuy95e"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "import wandb\n",
        "import re, string\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.font_manager import FontProperties\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from collections import Counter\n",
        "from colour import Color\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from google.colab import files\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()\n",
        "config_defaults = {\"embedding_dim\": 64, \n",
        "                       \"enc_dec_layers\": 1,\n",
        "                       \"layer_type\": \"lstm\",\n",
        "                       \"units\": 128,\n",
        "                       \"dropout\": 0,\n",
        "                       \"attention\": False,\n",
        "                       \"beam_width\": 3,\n",
        "                       \"teacher_forcing_ratio\": 1.0\n",
        "                       }\n",
        "wandb.init(config=config_defaults, project='Assignment3-partB_attn', entity='cs21s002-ee21s113-dlassignment-1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "shdPhW00cLKY",
        "outputId": "277bff68-da6e-46ff-b05e-25dc2e44154d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmanu_data_analyst\u001b[0m (\u001b[33mcs21s002-ee21s113-dlassignment-1\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220504_201800-1yl4j0xb</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/Assignment3-partB_attn/runs/1yl4j0xb\" target=\"_blank\">imperial-bothan-25</a></strong> to <a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/Assignment3-partB_attn\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/Assignment3-partB_attn/runs/1yl4j0xb?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f99bbfdd150>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVMyzAmMzE1a",
        "outputId": "5f64cabe-e63d-4b8f-8422-5543bdbda388"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9t1O6AgVjPYm"
      },
      "source": [
        "# Loading the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w96THw2KjYFJ"
      },
      "source": [
        "## Download the dataset ##\n",
        "import requests\n",
        "import tarfile\n",
        "\n",
        "def download_data(save_path):\n",
        "\n",
        "    data_url = r\"https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\"\n",
        "\n",
        "    r = requests.get(data_url, allow_redirects=True)\n",
        "    tar_path = \"data_assignment3.tar\"\n",
        "\n",
        "    if r.status_code == 200:\n",
        "        with open(tar_path, 'wb') as f:\n",
        "            f.write(r.content)\n",
        "\n",
        "    tar_file = tarfile.open(tar_path)\n",
        "    tar_file.extractall(save_path)\n",
        "    tar_file.close()\n",
        "\n",
        "\n",
        "# downloading and extracting the data to drive \n",
        "# uncomment the line below if downloading data for the 1st time\n",
        "download_data(\"/content/drive/MyDrive/DakshinaDataset\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlbXxZXZjpEq"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC_zHEatTLsT"
      },
      "source": [
        "# Files with English to Devanagari (Hindi) translation word by word \n",
        "# Punctutations have already been cleaned from this file \n",
        "\n",
        "def get_data_files(language):\n",
        "    \"\"\" Function fo read data \n",
        "    \"\"\"\n",
        "\n",
        "    ## REPLACE THIS PATH UPTO dakshina_dataset_v1.0 with your own dataset path ##\n",
        "    template = \"/content/drive/MyDrive/DakshinaDataset/dakshina_dataset_v1.0/{}/lexicons/{}.translit.sampled.{}.tsv\"\n",
        "\n",
        "    train_tsv = template.format(language, language, \"train\")\n",
        "    val_tsv = template.format(language, language, \"dev\")\n",
        "    test_tsv = template.format(language, language, \"test\")\n",
        "\n",
        "    return train_tsv, val_tsv, test_tsv\n",
        "\n",
        "## Utility functions for preprocessing data ##\n",
        "\n",
        "def add_start_end_tokens(df, cols, sos=\"\\t\", eos=\"\\n\"):\n",
        "    \"\"\" Adds EOS and SOS tokens to data \n",
        "    \"\"\"\n",
        "    def add_tokens(s):  \n",
        "        # \\t = starting token\n",
        "        # \\n = ending token\n",
        "        return sos + str(s) + eos\n",
        "\n",
        "    for col in cols:\n",
        "        df[col] = df[col].apply(add_tokens) \n",
        "    \n",
        "def tokenize(lang, tokenizer=None):\n",
        "    \"\"\" Uses tf.keras tokenizer to tokenize the data/words into characters\n",
        "    \"\"\"\n",
        "\n",
        "    if tokenizer is None:\n",
        "        tokenizer = Tokenizer(char_level=True)\n",
        "        tokenizer.fit_on_texts(lang)\n",
        "\n",
        "        lang_tensor = tokenizer.texts_to_sequences(lang)\n",
        "        lang_tensor = tf.keras.preprocessing.sequence.pad_sequences(lang_tensor,\n",
        "                                                            padding='post')\n",
        "\n",
        "    else: \n",
        "        lang_tensor = tokenizer.texts_to_sequences(lang)\n",
        "        lang_tensor = tf.keras.preprocessing.sequence.pad_sequences(lang_tensor,\n",
        "                                                            padding='post')\n",
        "\n",
        "    return lang_tensor, tokenizer\n",
        "\n",
        "def preprocess_data(fpath, input_lang_tokenizer=None, targ_lang_tokenizer=None):\n",
        "    \"\"\" Reads, tokenizes and adds SOS/EOS tokens to data based on above functions\n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.read_csv(fpath, sep=\"\\t\", header=None)\n",
        "\n",
        "    # adding start and end tokens to know when to stop predicting \n",
        "    add_start_end_tokens(df, [0,1])\n",
        "    \n",
        "    input_lang_tensor, input_tokenizer = tokenize(df[1].astype(str).tolist(), \n",
        "                                                    tokenizer=input_lang_tokenizer)\n",
        "    \n",
        "    targ_lang_tensor, targ_tokenizer = tokenize(df[0].astype(str).tolist(),\n",
        "                                                    tokenizer=targ_lang_tokenizer) \n",
        "    \n",
        "    dataset = tf.data.Dataset.from_tensor_slices((input_lang_tensor, targ_lang_tensor))\n",
        "    dataset = dataset.shuffle(len(dataset))\n",
        "    \n",
        "    return dataset, input_tokenizer, targ_tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjGJ1sFE-eon"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLLikr1QN4kE"
      },
      "source": [
        "## Utility functions ##\n",
        "def get_layer(name, units, dropout, return_state=False, return_sequences=False):\n",
        "\n",
        "    if name==\"rnn\":\n",
        "        return layers.SimpleRNN(units=units, dropout=dropout, \n",
        "                                return_state=return_state,\n",
        "                                return_sequences=return_sequences)\n",
        "\n",
        "    if name==\"gru\":\n",
        "        return layers.GRU(units=units, dropout=dropout, \n",
        "                          return_state=return_state,\n",
        "                          return_sequences=return_sequences)\n",
        "\n",
        "    if name==\"lstm\":\n",
        "        return layers.LSTM(units=units, dropout=dropout, \n",
        "                           return_state=return_state,\n",
        "                           return_sequences=return_sequences)\n",
        "\n",
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, enc_state, enc_out):\n",
        "    \n",
        "    enc_state = tf.concat(enc_state, 1)\n",
        "    enc_state = tf.expand_dims(enc_state, 1)\n",
        "\n",
        "    score = self.V(tf.nn.tanh(self.W1(enc_state) + self.W2(enc_out)))\n",
        "\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    context_vector = attention_weights * enc_out\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights\n",
        "\n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, layer_type, n_layers, units, encoder_vocab_size, embedding_dim, dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.layer_type = layer_type\n",
        "        self.n_layers = n_layers\n",
        "        self.units = units\n",
        "        self.dropout = dropout\n",
        "        self.embedding = tf.keras.layers.Embedding(encoder_vocab_size, embedding_dim)\n",
        "        self.create_rnn_layers()\n",
        "\n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        x = self.rnn_layers[0](x, initial_state=hidden)\n",
        "\n",
        "        for layer in self.rnn_layers[1:]:\n",
        "            x = layer(x)\n",
        "\n",
        "        output, state = x[0], x[1:]\n",
        "\n",
        "        return output, state\n",
        "    \n",
        "    def create_rnn_layers(self):\n",
        "        self.rnn_layers = []\n",
        "\n",
        "        for i in range(self.n_layers):\n",
        "            self.rnn_layers.append(get_layer(self.layer_type, self.units, self.dropout,\n",
        "                                                return_sequences=True,\n",
        "                                                return_state=True))\n",
        "\n",
        "\n",
        "    def initialize_hidden_state(self, batch_size):\n",
        "\n",
        "        if self.layer_type != \"lstm\":\n",
        "            return [tf.zeros((batch_size, self.units))]\n",
        "        else:\n",
        "            return [tf.zeros((batch_size, self.units))]*2\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, layer_type, n_layers, units, decoder_vocab_size, embedding_dim, dropout, attention=False):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.layer_type = layer_type\n",
        "        self.n_layers = n_layers\n",
        "        self.units = units\n",
        "        self.dropout = dropout\n",
        "        self.attention = attention\n",
        "        self.embedding_layer = layers.Embedding(input_dim=decoder_vocab_size, \n",
        "                                                output_dim=embedding_dim)\n",
        "        \n",
        "        self.dense = layers.Dense(decoder_vocab_size, activation=\"softmax\")\n",
        "        self.flatten = layers.Flatten()\n",
        "        if self.attention:\n",
        "            self.attention_layer = BahdanauAttention(self.units)\n",
        "        self.create_rnn_layers()\n",
        "\n",
        "    def call(self, x, hidden, enc_out=None):\n",
        "        \n",
        "        x = self.embedding_layer(x)\n",
        "\n",
        "        if self.attention:\n",
        "            context_vector, attention_weights = self.attention_layer(hidden, enc_out)\n",
        "            x = tf.concat([tf.expand_dims(context_vector, 1), x], -1)\n",
        "        else:\n",
        "            attention_weights = None\n",
        "\n",
        "        x = self.rnn_layers[0](x, initial_state=hidden)\n",
        "\n",
        "        for layer in self.rnn_layers[1:]:\n",
        "            x = layer(x)\n",
        "\n",
        "        output, state = x[0], x[1:]\n",
        "\n",
        "        output = self.dense(self.flatten(output))\n",
        "        \n",
        "        return output, state, attention_weights\n",
        "\n",
        "    def create_rnn_layers(self):\n",
        "        self.rnn_layers = []    \n",
        "\n",
        "        for i in range(self.n_layers - 1):\n",
        "            self.rnn_layers.append(get_layer(self.layer_type, self.units, self.dropout,\n",
        "                                                return_sequences=True,\n",
        "                                                return_state=True))\n",
        "        \n",
        "        self.rnn_layers.append(get_layer(self.layer_type, self.units, self.dropout,\n",
        "                                            return_sequences=False,\n",
        "                                            return_state=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lks31eDH0KKc"
      },
      "source": [
        "class BeamSearch():\n",
        "    def __init__(self, model, k):\n",
        "        self.k = k \n",
        "        self.model = model\n",
        "        self.acc = tf.keras.metrics.Accuracy()\n",
        "\n",
        "    def sample_beam_search(self, probs):\n",
        "\n",
        "        m, n = probs.shape\n",
        "        output_sequences = [[[], 0.0]]\n",
        "\n",
        "        for row in probs:\n",
        "            beams = []\n",
        "\n",
        "            for tup in output_sequences:\n",
        "                seq, score = tup\n",
        "                for j in range(n):\n",
        "                    new_beam = [seq + [j], score - tf.math.log(row[j])]\n",
        "                    beams.append(new_beam)\n",
        "\n",
        "            output_sequences = sorted(beams, key=lambda x: x[1])[:self.k]\n",
        "\n",
        "        tensors, scores = list(zip(*output_sequences))\n",
        "        tensors = list(map(lambda x: tf.expand_dims(tf.constant(x),0), tensors))\n",
        "\n",
        "        return tf.concat(tensors, 0), scores\n",
        "\n",
        "    def beam_accuracy(self, input, target):\n",
        "        accs = []\n",
        "\n",
        "        for i in range(self.k):\n",
        "            self.acc.reset_states()\n",
        "            self.acc.update_state(target, input[i, :])  \n",
        "            accs.append(self.acc.result())\n",
        "\n",
        "        return max(accs)\n",
        "    \n",
        "    def step(self, input, target, enc_state):\n",
        "\n",
        "        batch_acc = 0\n",
        "        sequences = []\n",
        "\n",
        "        enc_out, enc_state = self.model.encoder(input, enc_state)\n",
        "\n",
        "        dec_state = enc_state\n",
        "        dec_input = tf.expand_dims([self.model.targ_tokenizer.word_index[\"\\t\"]]*self.model.batch_size ,1)\n",
        "\n",
        "        for t in range(1, target.shape[1]):\n",
        "\n",
        "            preds, dec_state, _ = self.model.decoder(dec_input, dec_state, enc_out)\n",
        "\n",
        "            sequences.append(preds)\n",
        "            preds = tf.argmax(preds, 1)\n",
        "            dec_input = tf.expand_dims(preds, 1)\n",
        "\n",
        "        sequences = tf.concat(list(map(lambda x: tf.expand_dims(x, 1), sequences)), axis=1)\n",
        "\n",
        "        for i in range(target.shape[0]):\n",
        "\n",
        "            possibilities, scores = self.sample_beam_search(sequences[i, :, :])\n",
        "            batch_acc += self.beam_accuracy(possibilities, target[i, 1:])\n",
        "\n",
        "        batch_acc = batch_acc / target.shape[0]\n",
        "\n",
        "        return 0, batch_acc\n",
        "\n",
        "    def evaluate(self, test_dataset, batch_size=None, upto=5, use_wandb=True):\n",
        "        \n",
        "        if batch_size is not None:\n",
        "            self.model.batch_size = batch_size\n",
        "            test_dataset = test_dataset.batch(batch_size)\n",
        "        else:\n",
        "            self.model.batch_size = 1\n",
        "\n",
        "        test_acc = 0\n",
        "        enc_state = self.model.encoder.initialize_hidden_state(self.model.batch_size)\n",
        "\n",
        "        for batch, (input, target) in enumerate(test_dataset.take(upto)):\n",
        "           \n",
        "           _, acc = self.step(input, target, enc_state)\n",
        "           test_acc += acc\n",
        "\n",
        "        if use_wandb:\n",
        "            wandb.log({\"test acc (beam search)\": test_acc / upto})\n",
        "\n",
        "        print(f\"Test Accuracy on {upto*batch_size} samples: {test_acc / upto:.4f}\\n\")\n",
        "\n",
        "    def translate(self, word):\n",
        "\n",
        "        word = \"\\t\" + word + \"\\n\"\n",
        "        sequences = []\n",
        "        result = []\n",
        "\n",
        "        inputs = self.model.input_tokenizer.texts_to_sequences([word])\n",
        "        inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
        "                                                               maxlen=self.model.max_input_len,\n",
        "                                                               padding=\"post\")\n",
        "\n",
        "\n",
        "        enc_state = self.model.encoder.initialize_hidden_state(1)\n",
        "        enc_out, enc_state = self.model.encoder(inputs, enc_state)\n",
        "\n",
        "        dec_state = enc_state\n",
        "        dec_input = tf.expand_dims([self.model.targ_tokenizer.word_index[\"\\t\"]]*1, 1)\n",
        "\n",
        "        for t in range(1, self.model.max_target_len):\n",
        "\n",
        "            preds, dec_state, _ = self.model.decoder(dec_input, dec_state, enc_out)\n",
        "\n",
        "            sequences.append(preds)\n",
        "            preds = tf.argmax(preds, 1)\n",
        "            dec_input = tf.expand_dims(preds, 1)\n",
        "\n",
        "        sequences = tf.concat(list(map(lambda x: tf.expand_dims(x, 1), sequences)), axis=1)\n",
        "\n",
        "        possibilities, scores = self.sample_beam_search(tf.squeeze(sequences, 0))\n",
        "        output_words = self.model.targ_tokenizer.sequences_to_texts(possibilities.numpy())\n",
        "        \n",
        "        def post_process(word):\n",
        "            word = word.split(\" \")[:-1]\n",
        "            return \"\".join([x for x in word])\n",
        "\n",
        "        output_words = list(map(post_process, output_words))\n",
        "\n",
        "        return output_words, scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwR1miyeRrIG"
      },
      "source": [
        "class Seq2SeqModel():\n",
        "    def __init__(self, embedding_dim, encoder_layers, decoder_layers, layer_type, units, dropout, attention=False):\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.encoder_layers = encoder_layers\n",
        "        self.decoder_layers = decoder_layers\n",
        "        self.layer_type = layer_type\n",
        "        self.units = units\n",
        "        self.dropout = dropout\n",
        "        self.attention = attention\n",
        "        self.stats = []\n",
        "        self.batch_size = 128\n",
        "        self.use_beam_search = False\n",
        "\n",
        "    def build(self, loss, optimizer, metric):\n",
        "        self.loss = loss\n",
        "        self.optimizer = optimizer\n",
        "        self.metric = metric\n",
        "\n",
        "    def set_vocabulary(self, input_tokenizer, targ_tokenizer):\n",
        "        self.input_tokenizer = input_tokenizer\n",
        "        self.targ_tokenizer = targ_tokenizer\n",
        "        self.create_model()\n",
        "    \n",
        "    def create_model(self):\n",
        "\n",
        "        encoder_vocab_size = len(self.input_tokenizer.word_index) + 1\n",
        "        decoder_vocab_size = len(self.targ_tokenizer.word_index) + 1\n",
        "\n",
        "        self.encoder = Encoder(self.layer_type, self.encoder_layers, self.units, encoder_vocab_size,\n",
        "                               self.embedding_dim, self.dropout)\n",
        "\n",
        "        self.decoder = Decoder(self.layer_type, self.decoder_layers, self.units, decoder_vocab_size,\n",
        "                               self.embedding_dim,  self.dropout, self.attention)\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(self, input, target, enc_state):\n",
        "\n",
        "        loss = 0 \n",
        "\n",
        "        with tf.GradientTape() as tape: \n",
        "\n",
        "            enc_out, enc_state = self.encoder(input, enc_state)\n",
        "\n",
        "            dec_state = enc_state\n",
        "            dec_input = tf.expand_dims([self.targ_tokenizer.word_index[\"\\t\"]]*self.batch_size ,1)\n",
        "\n",
        "            ## We use Teacher forcing to train the network\n",
        "            ## Each target at timestep t is passed as input for timestep t + 1\n",
        "\n",
        "            if random.random() < self.teacher_forcing_ratio:\n",
        "\n",
        "                for t in range(1, target.shape[1]):\n",
        "\n",
        "                    preds, dec_state, _ = self.decoder(dec_input, dec_state, enc_out)\n",
        "                    loss += self.loss(target[:,t], preds)\n",
        "                    self.metric.update_state(target[:,t], preds)\n",
        "                    \n",
        "                    dec_input = tf.expand_dims(target[:,t], 1)\n",
        "            \n",
        "            else:\n",
        "\n",
        "                for t in range(1, target.shape[1]):\n",
        "\n",
        "                    preds, dec_state, _ = self.decoder(dec_input, dec_state, enc_out)\n",
        "                    loss += self.loss(target[:,t], preds)\n",
        "                    self.metric.update_state(target[:,t], preds)\n",
        "\n",
        "                    preds = tf.argmax(preds, 1)\n",
        "                    dec_input = tf.expand_dims(preds, 1)\n",
        "\n",
        "\n",
        "            batch_loss = loss / target.shape[1]\n",
        "\n",
        "            variables = self.encoder.variables + self.decoder.variables\n",
        "            gradients = tape.gradient(loss, variables)\n",
        "\n",
        "            self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "        return batch_loss, self.metric.result()\n",
        "\n",
        "    @tf.function\n",
        "    def validation_step(self, input, target, enc_state):\n",
        "\n",
        "        loss = 0\n",
        "        \n",
        "        enc_out, enc_state = self.encoder(input, enc_state)\n",
        "\n",
        "        dec_state = enc_state\n",
        "        dec_input = tf.expand_dims([self.targ_tokenizer.word_index[\"\\t\"]]*self.batch_size ,1)\n",
        "\n",
        "        for t in range(1, target.shape[1]):\n",
        "\n",
        "            preds, dec_state, _ = self.decoder(dec_input, dec_state, enc_out)\n",
        "            loss += self.loss(target[:,t], preds)\n",
        "            self.metric.update_state(target[:,t], preds)\n",
        "\n",
        "            preds = tf.argmax(preds, 1)\n",
        "            dec_input = tf.expand_dims(preds, 1)\n",
        "\n",
        "        batch_loss = loss / target.shape[1]\n",
        "        \n",
        "        return batch_loss, self.metric.result()\n",
        "\n",
        "\n",
        "    def fit(self, dataset, val_dataset, batch_size=128, epochs=10, use_wandb=False, teacher_forcing_ratio=1.0):\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
        "\n",
        "        steps_per_epoch = len(dataset) // self.batch_size\n",
        "        steps_per_epoch_val = len(val_dataset) // self.batch_size\n",
        "        \n",
        "        dataset = dataset.batch(self.batch_size, drop_remainder=True)\n",
        "        val_dataset = val_dataset.batch(self.batch_size, drop_remainder=True)\n",
        "\n",
        "        # useful when we need to translate the sentence\n",
        "        sample_inp, sample_targ = next(iter(dataset))\n",
        "        self.max_target_len = sample_targ.shape[1]\n",
        "        self.max_input_len = sample_inp.shape[1]\n",
        "\n",
        "        template = \"\\nTrain Loss: {0:.4f} Train Accuracy: {1:.4f} Validation Loss: {2:.4f} Validation Accuracy: {3:.4f}\"\n",
        "\n",
        "        print(\"-\"*100)\n",
        "        for epoch in range(1, epochs+1):\n",
        "            print(f\"EPOCH {epoch}\\n\")\n",
        "\n",
        "            ## Training loop ##\n",
        "            total_loss = 0\n",
        "            total_acc = 0\n",
        "            self.metric.reset_states()\n",
        "\n",
        "            starting_time = time.time()\n",
        "            enc_state = self.encoder.initialize_hidden_state(self.batch_size)\n",
        "\n",
        "            print(\"Training ...\\n\")\n",
        "            for batch, (input, target) in enumerate(dataset.take(steps_per_epoch)):\n",
        "                batch_loss, acc = self.train_step(input, target, enc_state)\n",
        "                total_loss += batch_loss\n",
        "                total_acc += acc\n",
        "\n",
        "\n",
        "                if batch==0 or ((batch + 1) % 100 == 0):\n",
        "                    print(f\"Batch {batch+1} Loss {batch_loss:.4f}\")\n",
        "\n",
        "            avg_acc = total_acc / steps_per_epoch\n",
        "            avg_loss = total_loss / steps_per_epoch\n",
        "\n",
        "            # Validation loop ##\n",
        "            total_val_loss = 0\n",
        "            total_val_acc = 0\n",
        "            self.metric.reset_states()\n",
        "\n",
        "            enc_state = self.encoder.initialize_hidden_state(self.batch_size)\n",
        "\n",
        "            print(\"\\nValidating ...\")\n",
        "            for batch, (input, target) in enumerate(val_dataset.take(steps_per_epoch_val)):\n",
        "                batch_loss, acc = self.validation_step(input, target, enc_state)\n",
        "                total_val_loss += batch_loss\n",
        "                total_val_acc += acc\n",
        "\n",
        "            avg_val_acc = total_val_acc / steps_per_epoch_val\n",
        "            avg_val_loss = total_val_loss / steps_per_epoch_val\n",
        "\n",
        "            print(template.format(avg_loss, avg_acc*100, avg_val_loss, avg_val_acc*100))\n",
        "            \n",
        "            time_taken = time.time() - starting_time\n",
        "            self.stats.append({\"epoch\": epoch,\n",
        "                            \"train loss\": avg_loss,\n",
        "                            \"val loss\": avg_val_loss,\n",
        "                            \"train acc\": avg_acc*100,\n",
        "                            \"val acc\": avg_val_acc*100,\n",
        "                            \"training time\": time_taken})\n",
        "            \n",
        "            if use_wandb:\n",
        "                wandb.log(self.stats[-1])\n",
        "            \n",
        "            print(f\"\\nTime taken for the epoch {time_taken:.4f}\")\n",
        "            print(\"-\"*100)\n",
        "        \n",
        "        print(\"\\nModel trained successfully !!\")\n",
        "        \n",
        "    def evaluate(self, test_dataset, batch_size=None):\n",
        "\n",
        "        if batch_size is not None:\n",
        "            self.batch_size = batch_size\n",
        "\n",
        "        steps_per_epoch_test = len(test_dataset) // batch_size\n",
        "        test_dataset = test_dataset.batch(batch_size, drop_remainder=True)\n",
        "        \n",
        "        total_test_loss = 0\n",
        "        total_test_acc = 0\n",
        "        self.metric.reset_states()\n",
        "\n",
        "        enc_state = self.encoder.initialize_hidden_state(self.batch_size)\n",
        "\n",
        "        print(\"\\nRunning test dataset through the model...\\n\")\n",
        "        for batch, (input, target) in enumerate(test_dataset.take(steps_per_epoch_test)):\n",
        "            batch_loss, acc = self.validation_step(input, target, enc_state)\n",
        "            total_test_loss += batch_loss\n",
        "            total_test_acc += acc\n",
        "\n",
        "        avg_test_acc = total_test_acc / steps_per_epoch_test\n",
        "        avg_test_loss = total_test_loss / steps_per_epoch_test\n",
        "    \n",
        "        print(f\"Test Loss: {avg_test_loss:.4f} Test Accuracy: {avg_test_acc:.4f}\")\n",
        "        wandb.log({\"Test_Loss\": avg_test_loss})\n",
        "        wandb.log({\"Test Accuracy\": avg_test_loss})\n",
        "\n",
        "        return avg_test_loss, avg_test_acc\n",
        "\n",
        "\n",
        "    def translate(self, word, get_heatmap=True):\n",
        "\n",
        "        word = \"\\t\" + word + \"\\n\"\n",
        "\n",
        "        inputs = self.input_tokenizer.texts_to_sequences([word])\n",
        "        inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
        "                                                               maxlen=self.max_input_len,\n",
        "                                                               padding=\"post\")\n",
        "\n",
        "        result = \"\"\n",
        "        att_wts = []\n",
        "\n",
        "        enc_state = self.encoder.initialize_hidden_state(1)\n",
        "        enc_out, enc_state = self.encoder(inputs, enc_state)\n",
        "\n",
        "        dec_state = enc_state\n",
        "        dec_input = tf.expand_dims([self.targ_tokenizer.word_index[\"\\t\"]]*1, 1)\n",
        "\n",
        "        for t in range(1, self.max_target_len):\n",
        "\n",
        "            preds, dec_state, attention_weights = self.decoder(dec_input, dec_state, enc_out)\n",
        "            \n",
        "            if get_heatmap:\n",
        "                att_wts.append(attention_weights)\n",
        "            \n",
        "            preds = tf.argmax(preds, 1)\n",
        "            next_char = self.targ_tokenizer.index_word[preds.numpy().item()]\n",
        "            result += next_char\n",
        "\n",
        "            dec_input = tf.expand_dims(preds, 1)\n",
        "\n",
        "            if next_char == \"\\n\":\n",
        "                return result[:-1], att_wts[:-1]\n",
        "\n",
        "        return result[:-1], att_wts[:-1]\n",
        "\n",
        "    def plot_attention_heatmap(self, word):\n",
        "\n",
        "        translated_word, attn_wts = self.translate(word, get_heatmap=True)\n",
        "        attn_heatmap = tf.squeeze(tf.concat(attn_wts, 0), -1).numpy()\n",
        "\n",
        "        input_word_len = len(word)\n",
        "        output_word_len = len(translated_word)\n",
        "        list(word).sort()\n",
        "        list(translated_word).sort()\n",
        "        wandb.log({'heatmap_with_attn': wandb.plots.HeatMap(list(word), list(translated_word), attn_heatmap[:, :input_word_len], show_text=False)})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSZFHEmw9KRw"
      },
      "source": [
        "# Visualizing Model Outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPPCBrHukCMZ"
      },
      "source": [
        "def get_colors(inputs, targets, preds):\n",
        "\n",
        "    n = len(targets)\n",
        "    smoother = SmoothingFunction().method2\n",
        "    def get_scores(target, output, smoother):\n",
        "        return sentence_bleu(list(list(target)), list(output), smoothing_function=smoother)\n",
        "\n",
        "    red = Color(\"red\")\n",
        "    colors = list(red.range_to(Color(\"violet\"),n))\n",
        "    colors = list(map(lambda c: c.hex, colors))\n",
        "\n",
        "    scores = []\n",
        "    for i in range(n):\n",
        "        scores.append(get_scores(targets[i], preds[i], smoother))\n",
        "\n",
        "    d = dict(zip(sorted(scores), list(range(n))))\n",
        "    ordered_colors = list(map(lambda x: colors[d[x]], scores))\n",
        "    \n",
        "    input_colors = dict(zip(inputs, ordered_colors))\n",
        "    target_colors = dict(zip(targets, ordered_colors))\n",
        "    pred_colors = dict(zip(preds, ordered_colors))\n",
        "\n",
        "    return input_colors, target_colors, pred_colors\n",
        "\n",
        "\n",
        "class Colorizer():\n",
        "    def __init__(self, word_to_color, default_color):\n",
        "       \n",
        "        self.word_to_color = word_to_color\n",
        "        self.default_color = default_color\n",
        "\n",
        "    def __call__(self, word, **kwargs):\n",
        "        return self.word_to_color.get(word, self.default_color)\n",
        "\n",
        "def randomly_evaluate(model, test_file=get_data_files(\"kn\")[2], n=10):\n",
        "\n",
        "    df = pd.read_csv(test_file, sep=\"\\t\", header=None)\n",
        "    df = df.sample(n=n).reset_index(drop=True)\n",
        "\n",
        "    print(f\"Randomly evaluating the model on {n} words\\n\")\n",
        "    my_data=[]\n",
        "    for i in range(n):\n",
        "        word = str(df[1][i])\n",
        "\n",
        "        print(f\"Input word: {word}\")\n",
        "        print(f\"Actual translation: {str(df[0][i])}\")\n",
        "        print(f\"Model translation: {model.translate(word)[0]}\\n\")\n",
        "        my_data.append([i,word,str(df[0][i]),model.translate(word)[0]])\n",
        "    columns=[\"id\",\"Input word\", \"Actual translation\",\"Model translation\"]\n",
        "    my_table = wandb.Table(data=my_data, columns=columns)\n",
        "    wandb.log({\"table_key\": my_table})\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "def test_on_dataset(language, embedding_dim, encoder_layers, decoder_layers, layer_type, units, dropout, attention, teacher_forcing_ratio=1.0, save_outputs=None):\n",
        "    \n",
        "    TRAIN_TSV, VAL_TSV, TEST_TSV = get_data_files(language)\n",
        "\n",
        "    model = Seq2SeqModel(embedding_dim, \n",
        "                         encoder_layers, \n",
        "                         decoder_layers, \n",
        "                         layer_type, \n",
        "                         units,\n",
        "                         dropout,\n",
        "                         attention)\n",
        "\n",
        "    dataset, input_tokenizer, targ_tokenizer = preprocess_data(TRAIN_TSV)\n",
        "    val_dataset, _, _ = preprocess_data(VAL_TSV, input_tokenizer, targ_tokenizer)\n",
        "\n",
        "    model.set_vocabulary(input_tokenizer, targ_tokenizer)\n",
        "    model.build(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metric = tf.keras.metrics.SparseCategoricalAccuracy())\n",
        "    \n",
        "    model.fit(dataset, val_dataset, epochs=30, use_wandb=True, teacher_forcing_ratio=teacher_forcing_ratio)\n",
        "\n",
        "    ## Character level accuracy ##\n",
        "    test_dataset, _, _ = preprocess_data(TEST_TSV, model.input_tokenizer, model.targ_tokenizer)\n",
        "    test_loss, test_acc = model.evaluate(test_dataset, batch_size=100)\n",
        "\n",
        "    ##  Word level accuracy ##\n",
        "    test_tsv = pd.read_csv(TEST_TSV, sep=\"\\t\", header=None)\n",
        "    inputs = test_tsv[1].astype(str).tolist()\n",
        "    targets = test_tsv[0].astype(str).tolist()\n",
        "    \n",
        "    outputs = []\n",
        "\n",
        "    for word in inputs:\n",
        "        outputs.append(model.translate(word)[0])\n",
        "\n",
        "    def word_level_acc(outputs, targets):\n",
        "        return np.sum(np.asarray(outputs) == np.array(targets)) / len(outputs)\n",
        "\n",
        "    print(f\"Word level accuracy: {word_level_acc(outputs, targets)}\")\n",
        "\n",
        "    if save_outputs is not None:\n",
        "        df = pd.DataFrame()\n",
        "        df[\"inputs\"] = inputs\n",
        "        df[\"targets\"] = targets\n",
        "        df[\"outputs\"] = outputs\n",
        "        df.to_csv('predictions_attention.csv', encoding = 'utf-8-sig') \n",
        "        files.download('predictions_attention.csv')\n",
        "\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvVSaWfGYvvn"
      },
      "source": [
        "# Visualizing Model Connectivity (Q6)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeWT7Yno7LXd"
      },
      "source": [
        "# Tools for getting model connectivity between input and output characters\n",
        "def get_lstm_output(decoder, x, hidden, enc_out=None):\n",
        "    \n",
        "    x = decoder.embedding_layer(x)\n",
        "\n",
        "    if decoder.attention:\n",
        "        context_vector, attention_weights = decoder.attention_layer(hidden, enc_out)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], -1)\n",
        "    else:\n",
        "        attention_weights = None\n",
        "\n",
        "    x = decoder.rnn_layers[0](x, initial_state=hidden)\n",
        "\n",
        "    for layer in decoder.rnn_layers[1:]:\n",
        "        x = layer(x)\n",
        "\n",
        "    output, state = x[0], x[1:]\n",
        "\n",
        "    #output = decoder.dense(decoder.flatten(output))\n",
        "    \n",
        "    return output, state, attention_weights\n",
        "\n",
        "def get_output_from_embedding(encoder, x, hidden):\n",
        "\n",
        "    x = encoder.rnn_layers[0](x, initial_state=hidden)\n",
        "\n",
        "    for layer in encoder.rnn_layers[1:]:\n",
        "        x = layer(x)\n",
        "\n",
        "    output, state = x[0], x[1:]\n",
        "\n",
        "    return output, state\n",
        "\n",
        "\n",
        "def get_connectivity(model, word):\n",
        "\n",
        "    word = \"\\t\" + word + \"\\n\"\n",
        "\n",
        "    inputs = model.input_tokenizer.texts_to_sequences([word])\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
        "                                                            maxlen=model.max_input_len,\n",
        "                                                            padding=\"post\")\n",
        "\n",
        "    result = \"\"\n",
        "\n",
        "    gradient_list = []\n",
        "\n",
        "    enc_state = model.encoder.initialize_hidden_state(1)\n",
        "    embedded_in = model.encoder.embedding(inputs)\n",
        "\n",
        "\n",
        "    with tf.GradientTape(persistent=True, watch_accessed_variables=False) as tape:\n",
        "        tape.watch(embedded_in)\n",
        "\n",
        "        enc_out, enc_state = get_output_from_embedding(model.encoder, embedded_in, enc_state)\n",
        "\n",
        "        dec_state = enc_state\n",
        "        dec_input = tf.expand_dims([model.targ_tokenizer.word_index[\"\\t\"]]*1, 1)\n",
        "\n",
        "        for t in range(1, model.max_target_len):\n",
        "\n",
        "            lstm_out, dec_state, _ = get_lstm_output(model.decoder, dec_input, dec_state, enc_out)\n",
        "\n",
        "            preds = model.decoder.dense(model.decoder.flatten(lstm_out))\n",
        "            gradient_list.append(tape.gradient(lstm_out, embedded_in)[0])\n",
        "            \n",
        "            preds = tf.argmax(preds, 1)\n",
        "            next_char = model.targ_tokenizer.index_word[preds.numpy().item()]\n",
        "            result += next_char\n",
        "\n",
        "            dec_input = tf.expand_dims(preds, 1)\n",
        "\n",
        "            if next_char == \"\\n\":\n",
        "                return result[:-1], gradient_list[:-1]\n",
        "\n",
        "        return result[:-1], gradient_list[:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22kfP4uvp63B"
      },
      "source": [
        "# Imports for visualising the model connectivity\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from IPython.display import HTML as html_print\n",
        "from IPython.display import display\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# get html element\n",
        "def cstr(s, color='black'):\n",
        "    if s == ' ':\n",
        "      return \"<text style=color:#000;padding-left:10px;background-color:{}> </text>\".format(color, s)\n",
        "    else:\n",
        "      return \"<text style=color:#000;background-color:{}>{} </text>\".format(color, s)\n",
        "\t\n",
        "# print html\n",
        "def print_color(t):\n",
        "\t  display(html_print(''.join([cstr(ti, color=ci) for ti,ci in t])))\n",
        "\n",
        "# get appropriate color for value\n",
        "def get_clr(value):\n",
        "    colors = ['#85c2e1', '#89c4e2', '#95cae5', '#99cce6', '#a1d0e8'\n",
        "      '#b2d9ec', '#baddee', '#c2e1f0', '#eff7fb', '#f9e8e8',\n",
        "      '#f9e8e8', '#f9d4d4', '#f9bdbd', '#f8a8a8', '#f68f8f',\n",
        "      '#f47676', '#f45f5f', '#f34343', '#f33b3b', '#f42e2e']\n",
        "    value = int(value * 19)\n",
        "    if value == 19:\n",
        "        value -= 1\n",
        "    return colors[value]\n",
        "\n",
        "# sigmoid function\n",
        "def sigmoid(x):\n",
        "    z = 1/(1 + np.exp(-x)) \n",
        "    return z\n",
        "\n",
        "def softmax(x):\n",
        "    v = np.exp(x)\n",
        "    v = v / np.sum(v)\n",
        "    return v\n",
        "\n",
        "def get_gradient_norms(grad_list, word, activation=\"sigmoid\"):\n",
        "    grad_norms = []\n",
        "    for grad_tensor in grad_list:\n",
        "        grad_mags = tf.norm(grad_tensor, axis=1)\n",
        "        grad_mags = grad_mags[:len(word)]\n",
        "        if activation == \"softmax\":\n",
        "            grad_mags_scaled = softmax(grad_mags)\n",
        "        elif activation == \"scaler\":\n",
        "            scaler = MinMaxScaler()\n",
        "            grad_mags = tf.reshape(grad_mags, (-1,1))\n",
        "            grad_mags_scaled = scaler.fit_transform(grad_mags)\n",
        "        else:\n",
        "            grad_mags_scaled = sigmoid(grad_mags)\n",
        "        grad_norms.append(grad_mags_scaled)\n",
        "    return grad_norms\n",
        "\n",
        "def visualize(grad_norms, word, translated_word):\n",
        "    print(\"Original Word:\", word)\n",
        "    print(\"Transliterated Word:\", translated_word)\n",
        "    for i in range(len(translated_word)):\n",
        "        print(\"Connectivity Visualization for\", translated_word[i],\":\")\n",
        "        text_colours = []\n",
        "        for j in range(len(grad_norms[i])):\n",
        "            text = (word[j], get_clr(grad_norms[i][j]))\n",
        "            text_colours.append(text)\n",
        "        print_color(text_colours)\n",
        "        data_table = wandb.Table(data=text_colours, columns=[\"s_ind\", \"t_ind\"])\n",
        "        fields = {\n",
        "                     \"s_index\": \"s_ind\",\n",
        "                     \"t_index\": \"t_ind\",\n",
        "\n",
        "                }\n",
        "        wandb.log({\"heatmap\": wandb.plot_table(\n",
        "                       vega_spec_name=\"spec-visualization\",\n",
        "                       data_table=data_table,\n",
        "                       fields=fields\n",
        "                       )\n",
        "                   })\n",
        "\n",
        "def visualise_connectivity(model, word, activation=\"sigmoid\"):\n",
        "    translated_word, grad_list = get_connectivity(model, word)\n",
        "    grad_norms = get_gradient_norms(grad_list, word, activation)\n",
        "    visualize(grad_norms, word, translated_word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzkdsWRlZzTf",
        "outputId": "e62b3993-4641-4bc3-e811-f00ce193204b"
      },
      "source": [
        "model = test_on_dataset(language=\"kn\",\n",
        "                        embedding_dim=64,\n",
        "                        encoder_layers=2,\n",
        "                        decoder_layers=2,\n",
        "                        layer_type=\"lstm\",\n",
        "                        units=256,\n",
        "                        dropout=0.2,\n",
        "                        attention=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "EPOCH 1\n",
            "\n",
            "Training ...\n",
            "\n",
            "Batch 1 Loss 3.9973\n",
            "Batch 100 Loss 1.1411\n",
            "Batch 200 Loss 1.0578\n",
            "Batch 300 Loss 0.9281\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 1.0969 Train Accuracy: 65.7635 Validation Loss: 2.0199 Validation Accuracy: 58.5038\n",
            "\n",
            "Time taken for the epoch 269.4127\n",
            "----------------------------------------------------------------------------------------------------\n",
            "EPOCH 2\n",
            "\n",
            "Training ...\n",
            "\n",
            "Batch 1 Loss 0.8903\n",
            "Batch 100 Loss 0.7841\n",
            "Batch 200 Loss 0.7484\n",
            "Batch 300 Loss 0.7364\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.7727 Train Accuracy: 75.7360 Validation Loss: 2.2248 Validation Accuracy: 59.8363\n",
            "\n",
            "Time taken for the epoch 134.2739\n",
            "----------------------------------------------------------------------------------------------------\n",
            "EPOCH 3\n",
            "\n",
            "Training ...\n",
            "\n",
            "Batch 1 Loss 0.6885\n",
            "Batch 100 Loss 0.6176\n",
            "Batch 200 Loss 0.5523\n",
            "Batch 300 Loss 0.5060\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.5533 Train Accuracy: 81.5650 Validation Loss: 1.9822 Validation Accuracy: 66.1561\n",
            "\n",
            "Time taken for the epoch 127.5469\n",
            "----------------------------------------------------------------------------------------------------\n",
            "EPOCH 4\n",
            "\n",
            "Training ...\n",
            "\n",
            "Batch 1 Loss 0.4092\n",
            "Batch 100 Loss 0.3740\n",
            "Batch 200 Loss 0.3321\n",
            "Batch 300 Loss 0.2546\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.3306 Train Accuracy: 88.2574 Validation Loss: 1.6790 Validation Accuracy: 74.3459\n",
            "\n",
            "Time taken for the epoch 118.3222\n",
            "----------------------------------------------------------------------------------------------------\n",
            "EPOCH 5\n",
            "\n",
            "Training ...\n",
            "\n",
            "Batch 1 Loss 0.2411\n",
            "Batch 100 Loss 0.2130\n",
            "Batch 200 Loss 0.2108\n",
            "Batch 300 Loss 0.1747\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.1918 Train Accuracy: 93.3380 Validation Loss: 1.2064 Validation Accuracy: 83.2581\n",
            "\n",
            "Time taken for the epoch 105.2637\n",
            "----------------------------------------------------------------------------------------------------\n",
            "EPOCH 6\n",
            "\n",
            "Training ...\n",
            "\n",
            "Batch 1 Loss 0.1321\n",
            "Batch 100 Loss 0.1390\n",
            "Batch 200 Loss 0.1190\n",
            "Batch 300 Loss 0.1137\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.1200 Train Accuracy: 96.0549 Validation Loss: 1.0746 Validation Accuracy: 86.1869\n",
            "\n",
            "Time taken for the epoch 112.5609\n",
            "----------------------------------------------------------------------------------------------------\n",
            "EPOCH 7\n",
            "\n",
            "Training ...\n",
            "\n",
            "Batch 1 Loss 0.0898\n",
            "Batch 100 Loss 0.0872\n",
            "Batch 200 Loss 0.0767\n",
            "Batch 300 Loss 0.0706\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0859 Train Accuracy: 97.2098 Validation Loss: 0.9395 Validation Accuracy: 88.0696\n",
            "\n",
            "Time taken for the epoch 109.6456\n",
            "----------------------------------------------------------------------------------------------------\n",
            "EPOCH 8\n",
            "\n",
            "Training ...\n",
            "\n",
            "Batch 1 Loss 0.0858\n",
            "Batch 100 Loss 0.0732\n",
            "Batch 200 Loss 0.0809\n",
            "Batch 300 Loss 0.0709\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0668 Train Accuracy: 97.9308 Validation Loss: 0.8944 Validation Accuracy: 89.0941\n",
            "\n",
            "Time taken for the epoch 113.2500\n",
            "----------------------------------------------------------------------------------------------------\n",
            "EPOCH 9\n",
            "\n",
            "Training ...\n",
            "\n",
            "Batch 1 Loss 0.0630\n",
            "Batch 100 Loss 0.0484\n",
            "Batch 200 Loss 0.0637\n",
            "Batch 300 Loss 0.0504\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0544 Train Accuracy: 98.3284 Validation Loss: 0.9350 Validation Accuracy: 89.5158\n",
            "\n",
            "Time taken for the epoch 147.1004\n",
            "----------------------------------------------------------------------------------------------------\n",
            "EPOCH 10\n",
            "\n",
            "Training ...\n",
            "\n",
            "Batch 1 Loss 0.0415\n",
            "Batch 100 Loss 0.0452\n",
            "Batch 200 Loss 0.0406\n",
            "Batch 300 Loss 0.0493\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0454 Train Accuracy: 98.6336 Validation Loss: 0.9057 Validation Accuracy: 90.3277\n",
            "\n",
            "Time taken for the epoch 135.0642\n",
            "----------------------------------------------------------------------------------------------------\n",
            "EPOCH 11\n",
            "\n",
            "Training ...\n",
            "\n",
            "Batch 1 Loss 0.0388\n",
            "Batch 100 Loss 0.0336\n",
            "Batch 200 Loss 0.0384\n",
            "Batch 300 Loss 0.0514\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0379 Train Accuracy: 98.8407 Validation Loss: 0.9332 Validation Accuracy: 89.8178\n",
            "\n",
            "Time taken for the epoch 139.5507\n",
            "----------------------------------------------------------------------------------------------------\n",
            "EPOCH 12\n",
            "\n",
            "Training ...\n",
            "\n",
            "Batch 1 Loss 0.0375\n",
            "Batch 100 Loss 0.0289\n",
            "Batch 200 Loss 0.0273\n",
            "Batch 300 Loss 0.0386\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0330 Train Accuracy: 99.0123 Validation Loss: 0.9752 Validation Accuracy: 89.6485\n",
            "\n",
            "Time taken for the epoch 138.2859\n",
            "----------------------------------------------------------------------------------------------------\n",
            "EPOCH 13\n",
            "\n",
            "Training ...\n",
            "\n",
            "Batch 1 Loss 0.0313\n",
            "Batch 100 Loss 0.0294\n",
            "Batch 200 Loss 0.0340\n",
            "Batch 300 Loss 0.0261\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0285 Train Accuracy: 99.1326 Validation Loss: 0.9620 Validation Accuracy: 90.0384\n",
            "\n",
            "Time taken for the epoch 134.3556\n",
            "----------------------------------------------------------------------------------------------------\n",
            "EPOCH 14\n",
            "\n",
            "Training ...\n",
            "\n",
            "Batch 1 Loss 0.0251\n",
            "Batch 100 Loss 0.0330\n",
            "Batch 200 Loss 0.0254\n",
            "Batch 300 Loss 0.0234\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0251 Train Accuracy: 99.2576 Validation Loss: 0.9456 Validation Accuracy: 90.0314\n",
            "\n",
            "Time taken for the epoch 137.6755\n",
            "----------------------------------------------------------------------------------------------------\n",
            "EPOCH 15\n",
            "\n",
            "Training ...\n",
            "\n",
            "Batch 1 Loss 0.0145\n",
            "Batch 100 Loss 0.0185\n",
            "Batch 200 Loss 0.0214\n",
            "Batch 300 Loss 0.0200\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0227 Train Accuracy: 99.3372 Validation Loss: 0.9684 Validation Accuracy: 90.4471\n",
            "\n",
            "Time taken for the epoch 141.3942\n",
            "----------------------------------------------------------------------------------------------------\n",
            "EPOCH 16\n",
            "\n",
            "Training ...\n",
            "\n",
            "Batch 1 Loss 0.0160\n",
            "Batch 100 Loss 0.0153\n",
            "Batch 200 Loss 0.0231\n",
            "Batch 300 Loss 0.0144\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0196 Train Accuracy: 99.4152 Validation Loss: 1.0210 Validation Accuracy: 90.3121\n",
            "\n",
            "Time taken for the epoch 147.1429\n",
            "----------------------------------------------------------------------------------------------------\n",
            "EPOCH 17\n",
            "\n",
            "Training ...\n",
            "\n",
            "Batch 1 Loss 0.0143\n",
            "Batch 100 Loss 0.0137\n",
            "Batch 200 Loss 0.0203\n",
            "Batch 300 Loss 0.0180\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0169 Train Accuracy: 99.5049 Validation Loss: 1.0414 Validation Accuracy: 90.2139\n",
            "\n",
            "Time taken for the epoch 140.1581\n",
            "----------------------------------------------------------------------------------------------------\n",
            "EPOCH 18\n",
            "\n",
            "Training ...\n",
            "\n",
            "Batch 1 Loss 0.0146\n",
            "Batch 100 Loss 0.0173\n",
            "Batch 200 Loss 0.0168\n",
            "Batch 300 Loss 0.0183\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0172 Train Accuracy: 99.4643 Validation Loss: 1.0055 Validation Accuracy: 90.7992\n",
            "\n",
            "Time taken for the epoch 140.8687\n",
            "----------------------------------------------------------------------------------------------------\n",
            "EPOCH 19\n",
            "\n",
            "Training ...\n",
            "\n",
            "Batch 1 Loss 0.0131\n",
            "Batch 100 Loss 0.0134\n",
            "Batch 200 Loss 0.0224\n",
            "Batch 300 Loss 0.0136\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0146 Train Accuracy: 99.5637 Validation Loss: 1.0346 Validation Accuracy: 90.4300\n",
            "\n",
            "Time taken for the epoch 138.8377\n",
            "----------------------------------------------------------------------------------------------------\n",
            "EPOCH 20\n",
            "\n",
            "Training ...\n",
            "\n",
            "Batch 1 Loss 0.0090\n",
            "Batch 100 Loss 0.0093\n",
            "Batch 200 Loss 0.0113\n",
            "Batch 300 Loss 0.0190\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0143 Train Accuracy: 99.6020 Validation Loss: 1.1234 Validation Accuracy: 89.5846\n",
            "\n",
            "Time taken for the epoch 140.0578\n",
            "----------------------------------------------------------------------------------------------------\n",
            "EPOCH 21\n",
            "\n",
            "Training ...\n",
            "\n",
            "Batch 1 Loss 0.0146\n",
            "Batch 100 Loss 0.0068\n",
            "Batch 200 Loss 0.0138\n",
            "Batch 300 Loss 0.0126\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0133 Train Accuracy: 99.5858 Validation Loss: 1.0727 Validation Accuracy: 90.5857\n",
            "\n",
            "Time taken for the epoch 135.9136\n",
            "----------------------------------------------------------------------------------------------------\n",
            "EPOCH 22\n",
            "\n",
            "Training ...\n",
            "\n",
            "Batch 1 Loss 0.0131\n",
            "Batch 100 Loss 0.0147\n",
            "Batch 200 Loss 0.0152\n",
            "Batch 300 Loss 0.0155\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0132 Train Accuracy: 99.5741 Validation Loss: 1.1459 Validation Accuracy: 90.3800\n",
            "\n",
            "Time taken for the epoch 147.1359\n",
            "----------------------------------------------------------------------------------------------------\n",
            "EPOCH 23\n",
            "\n",
            "Training ...\n",
            "\n",
            "Batch 1 Loss 0.0061\n",
            "Batch 100 Loss 0.0094\n",
            "Batch 200 Loss 0.0121\n",
            "Batch 300 Loss 0.0160\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0116 Train Accuracy: 99.6660 Validation Loss: 1.1005 Validation Accuracy: 90.4827\n",
            "\n",
            "Time taken for the epoch 137.8847\n",
            "----------------------------------------------------------------------------------------------------\n",
            "EPOCH 24\n",
            "\n",
            "Training ...\n",
            "\n",
            "Batch 1 Loss 0.0121\n",
            "Batch 100 Loss 0.0089\n",
            "Batch 200 Loss 0.0106\n",
            "Batch 300 Loss 0.0125\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0110 Train Accuracy: 99.6552 Validation Loss: 1.0802 Validation Accuracy: 91.0502\n",
            "\n",
            "Time taken for the epoch 141.0183\n",
            "----------------------------------------------------------------------------------------------------\n",
            "EPOCH 25\n",
            "\n",
            "Training ...\n",
            "\n",
            "Batch 1 Loss 0.0085\n",
            "Batch 100 Loss 0.0109\n",
            "Batch 200 Loss 0.0062\n",
            "Batch 300 Loss 0.0099\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0102 Train Accuracy: 99.7064 Validation Loss: 1.0880 Validation Accuracy: 91.0807\n",
            "\n",
            "Time taken for the epoch 136.5043\n",
            "----------------------------------------------------------------------------------------------------\n",
            "EPOCH 26\n",
            "\n",
            "Training ...\n",
            "\n",
            "Batch 1 Loss 0.0086\n",
            "Batch 100 Loss 0.0095\n",
            "Batch 200 Loss 0.0100\n",
            "Batch 300 Loss 0.0124\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0098 Train Accuracy: 99.7102 Validation Loss: 1.1478 Validation Accuracy: 90.3739\n",
            "\n",
            "Time taken for the epoch 138.0120\n",
            "----------------------------------------------------------------------------------------------------\n",
            "EPOCH 27\n",
            "\n",
            "Training ...\n",
            "\n",
            "Batch 1 Loss 0.0120\n",
            "Batch 100 Loss 0.0071\n",
            "Batch 200 Loss 0.0114\n",
            "Batch 300 Loss 0.0192\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0108 Train Accuracy: 99.6751 Validation Loss: 1.1374 Validation Accuracy: 90.5049\n",
            "\n",
            "Time taken for the epoch 137.6936\n",
            "----------------------------------------------------------------------------------------------------\n",
            "EPOCH 28\n",
            "\n",
            "Training ...\n",
            "\n",
            "Batch 1 Loss 0.0086\n",
            "Batch 100 Loss 0.0084\n",
            "Batch 200 Loss 0.0105\n",
            "Batch 300 Loss 0.0157\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0105 Train Accuracy: 99.6910 Validation Loss: 1.1683 Validation Accuracy: 90.8572\n",
            "\n",
            "Time taken for the epoch 141.2177\n",
            "----------------------------------------------------------------------------------------------------\n",
            "EPOCH 29\n",
            "\n",
            "Training ...\n",
            "\n",
            "Batch 1 Loss 0.0086\n",
            "Batch 100 Loss 0.0120\n",
            "Batch 200 Loss 0.0085\n",
            "Batch 300 Loss 0.0094\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0112 Train Accuracy: 99.6240 Validation Loss: 1.1064 Validation Accuracy: 91.2523\n",
            "\n",
            "Time taken for the epoch 138.6390\n",
            "----------------------------------------------------------------------------------------------------\n",
            "EPOCH 30\n",
            "\n",
            "Training ...\n",
            "\n",
            "Batch 1 Loss 0.0122\n",
            "Batch 100 Loss 0.0058\n",
            "Batch 200 Loss 0.0041\n",
            "Batch 300 Loss 0.0093\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0081 Train Accuracy: 99.7484 Validation Loss: 1.1175 Validation Accuracy: 91.0222\n",
            "\n",
            "Time taken for the epoch 147.0966\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Model trained successfully !!\n",
            "\n",
            "Running test dataset through the model...\n",
            "\n",
            "Test Loss: 1.1360 Test Accuracy: 0.9083\n",
            "Word level accuracy: 0.5072320190212007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_tsv = pd.read_csv(get_data_files(\"kn\")[2], sep=\"\\t\", header=None)\n",
        "inputs = test_tsv[1].astype(str).tolist()\n",
        "targets = test_tsv[0].astype(str).tolist()\n",
        "outputs = []\n",
        "for word in inputs:\n",
        "    outputs.append(model.translate(word)[0])\n",
        "df = pd.DataFrame()\n",
        "df[\"inputs\"] = inputs\n",
        "df[\"targets\"] = targets\n",
        "df[\"outputs\"] = outputs\n",
        "df.to_csv('predictions_attention.csv', encoding = 'utf-8-sig') \n",
        "files.download('predictions_attention.csv')"
      ],
      "metadata": {
        "id": "_kHT2SdxDv5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgY9jxQo2I1Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a364776f-5a8a-470f-dd70-81fbf557729d"
      },
      "source": [
        "def get_test_words(n):\n",
        "    test_df = pd.read_csv(get_data_files(\"kn\")[2])\n",
        "    test_sample = test_df.sample(n)\n",
        "    test_sample.reset_index(inplace=True, drop=True)\n",
        "    test_words = []\n",
        "    for i in test_sample.index:\n",
        "        entry = test_sample[\"ಅಂಗಡಿ\\tangadi\\t3\"].loc[i]\n",
        "        parts = entry.split(\"\\t\")\n",
        "        word = parts[1]\n",
        "        test_words.append(word)\n",
        "    return test_words\n",
        "\n",
        "test_words = get_test_words(5)\n",
        "print(test_words)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['pariganisuvante', 'banada', 'sariyutiruva', 'anivarya', 'samitigalannu']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgDA-bWL1ueE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cc89e429-5e6f-422f-dd95-c7570a0982f6"
      },
      "source": [
        "for word in test_words:\n",
        "    visualise_connectivity(model, word, activation=\"scaler\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "Original Word: pariganisuvante\n",
            "Transliterated Word: ಪರಿಗಣಿಸುವಂತೆ\n",
            "Connectivity Visualization for ಪ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#f68f8f>p </text><text style=color:#000;background-color:#f42e2e>a </text><text style=color:#000;background-color:#baddee>r </text><text style=color:#000;background-color:#eff7fb>i </text><text style=color:#000;background-color:#eff7fb>g </text><text style=color:#000;background-color:#c2e1f0>a </text><text style=color:#000;background-color:#95cae5>n </text><text style=color:#000;background-color:#95cae5>i </text><text style=color:#000;background-color:#89c4e2>s </text><text style=color:#000;background-color:#c2e1f0>u </text><text style=color:#000;background-color:#95cae5>v </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#89c4e2>t </text><text style=color:#000;background-color:#89c4e2>e </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ರ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>p </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#c2e1f0>i </text><text style=color:#000;background-color:#f42e2e>g </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>e </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ಿ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>p </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#f42e2e>g </text><text style=color:#000;background-color:#95cae5>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>e </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ಗ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>p </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#f42e2e>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>e </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ಣ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>p </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>e </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ಿ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>p </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>e </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ಸ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>p </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>e </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ು :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>p </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>e </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ವ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>p </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>e </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ಂ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>p </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>e </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ತ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>p </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>e </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ೆ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>p </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>e </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Word: banada\n",
            "Transliterated Word: ಬಾಣದ\n",
            "Connectivity Visualization for ಬ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#f42e2e>b </text><text style=color:#000;background-color:#f8a8a8>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#f9e8e8>a </text><text style=color:#000;background-color:#95cae5>d </text><text style=color:#000;background-color:#95cae5>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ಾ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>b </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#99cce6>a </text><text style=color:#000;background-color:#f42e2e>d </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ಣ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>b </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#f42e2e>d </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ದ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>b </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#f42e2e>d </text><text style=color:#000;background-color:#f8a8a8>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Word: sariyutiruva\n",
            "Transliterated Word: ಸರಿಯುತಿರುವ\n",
            "Connectivity Visualization for ಸ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#f34343>s </text><text style=color:#000;background-color:#f42e2e>a </text><text style=color:#000;background-color:#a1d0e8#b2d9ec>r </text><text style=color:#000;background-color:#a1d0e8#b2d9ec>i </text><text style=color:#000;background-color:#c2e1f0>y </text><text style=color:#000;background-color:#89c4e2>u </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#89c4e2>i </text><text style=color:#000;background-color:#95cae5>r </text><text style=color:#000;background-color:#95cae5>u </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#a1d0e8#b2d9ec>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ರ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#a1d0e8#b2d9ec>i </text><text style=color:#000;background-color:#f42e2e>y </text><text style=color:#000;background-color:#89c4e2>u </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ಿ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#f42e2e>y </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ಯ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#f42e2e>y </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ು :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>y </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ತ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>y </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ಿ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>y </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ರ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>y </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ು :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>y </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ವ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>y </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Word: anivarya\n",
            "Transliterated Word: ಅನಿವಾರ್ಯ\n",
            "Connectivity Visualization for ಅ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#f42e2e>a </text><text style=color:#000;background-color:#c2e1f0>n </text><text style=color:#000;background-color:#f9d4d4>i </text><text style=color:#000;background-color:#c2e1f0>v </text><text style=color:#000;background-color:#99cce6>a </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#95cae5>y </text><text style=color:#000;background-color:#baddee>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ನ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#89c4e2>v </text><text style=color:#000;background-color:#f42e2e>a </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>y </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ಿ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#f42e2e>a </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>y </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ವ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#f42e2e>a </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>y </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ಾ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>y </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ರ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>y </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ್ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>y </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ಯ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>y </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Word: samitigalannu\n",
            "Transliterated Word: ಸಾಮಿತಿಗಳನ್ನು\n",
            "Connectivity Visualization for ಸ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#f42e2e>s </text><text style=color:#000;background-color:#f42e2e>a </text><text style=color:#000;background-color:#c2e1f0>m </text><text style=color:#000;background-color:#f8a8a8>i </text><text style=color:#000;background-color:#eff7fb>t </text><text style=color:#000;background-color:#a1d0e8#b2d9ec>i </text><text style=color:#000;background-color:#a1d0e8#b2d9ec>g </text><text style=color:#000;background-color:#a1d0e8#b2d9ec>a </text><text style=color:#000;background-color:#89c4e2>l </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#89c4e2>n </text><text style=color:#000;background-color:#99cce6>u </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ಾ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>m </text><text style=color:#000;background-color:#baddee>i </text><text style=color:#000;background-color:#f42e2e>t </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>u </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ಮ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>m </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#f42e2e>t </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>u </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ಿ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>m </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#f42e2e>t </text><text style=color:#000;background-color:#c2e1f0>i </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>u </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ತ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>m </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>u </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ಿ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>m </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>u </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ಗ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>m </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>u </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ಳ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>m </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>u </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ನ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>m </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>u </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ್ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>m </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>u </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ನ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>m </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>u </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ು :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>m </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>u </text>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E9pUPNGndTS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24308a20-a9e3-4c35-8c1f-472738f99e82"
      },
      "source": [
        "randomly_evaluate(model, n=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Randomly evaluating the model on 5 words\n",
            "\n",
            "Input word: hecchuttiruva\n",
            "Actual translation: ಹೆಚ್ಚುತ್ತಿರುವ\n",
            "Model translation: ಹೆಚ್ಚುತ್ತಿರುವ\n",
            "\n",
            "Input word: vyatirikthavaagi\n",
            "Actual translation: ವ್ಯತಿರಿಕ್ತವಾಗಿ\n",
            "Model translation: ವ್ಯತಿರಿಕ್ತವಾಗಿ\n",
            "\n",
            "Input word: averadoo\n",
            "Actual translation: ಅವೆರಡೂ\n",
            "Model translation: ಅವೆರದೂ\n",
            "\n",
            "Input word: jotejotheyagi\n",
            "Actual translation: ಜೊತೆಜೊತೆಯಾಗಿ\n",
            "Model translation: ಜೊತೆಜೊತೆಯಾಗಿ\n",
            "\n",
            "Input word: upakhandada\n",
            "Actual translation: ಉಪಖಂಡದ\n",
            "Model translation: ಉಪಘಂಡದ\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVjQ4r9f1Xoz"
      },
      "source": [
        "# WandB Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_FiH40wgm0i"
      },
      "source": [
        "def train_with_wandb(language, test_beam_search=False):\n",
        "\n",
        "    config_defaults = {\"embedding_dim\": 64, \n",
        "                       \"enc_dec_layers\": 1,\n",
        "                       \"layer_type\": \"lstm\",\n",
        "                       \"units\": 128,\n",
        "                       \"dropout\": 0,\n",
        "                       \"attention\": False,\n",
        "                       \"beam_width\": 3,\n",
        "                       \"teacher_forcing_ratio\": 1.0\n",
        "                       }\n",
        "\n",
        "    wandb.init(config=config_defaults, project='Assignment3-partB_attn', entity='cs21s002-ee21s113-dlassignment-1')\n",
        "    # Below is an example of a custom run name for sweep 4\n",
        "    # This line was different for all sweeps\n",
        "    #wandb.run.name = f\"beam_width_{wandb.config.beam_width}\"\n",
        "\n",
        "    ## 1. SELECT LANGUAGE ##\n",
        "    TRAIN_TSV, VAL_TSV, TEST_TSV = get_data_files(language)\n",
        "\n",
        "    ## 2. DATA PREPROCESSING ##\n",
        "    dataset, input_tokenizer, targ_tokenizer = preprocess_data(TRAIN_TSV)\n",
        "    val_dataset, _, _ = preprocess_data(VAL_TSV, input_tokenizer, targ_tokenizer)\n",
        "\n",
        "    ## 3. CREATING THE MODEL ##\n",
        "    model = Seq2SeqModel(embedding_dim=wandb.config.embedding_dim,\n",
        "                         encoder_layers=wandb.config.enc_dec_layers,\n",
        "                         decoder_layers=wandb.config.enc_dec_layers,\n",
        "                         layer_type=wandb.config.layer_type,\n",
        "                         units=wandb.config.units,\n",
        "                         dropout=wandb.config.dropout,\n",
        "                         attention=wandb.config.attention)\n",
        "    \n",
        "    ## 4. COMPILING THE MODEL \n",
        "    model.set_vocabulary(input_tokenizer, targ_tokenizer)\n",
        "    model.build(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metric = tf.keras.metrics.SparseCategoricalAccuracy())\n",
        "    \n",
        "    ## 5. FITTING AND VALIDATING THE MODEL\n",
        "    model.fit(dataset, val_dataset, epochs=30, use_wandb=True, teacher_forcing_ratio=wandb.config.teacher_forcing_ratio)\n",
        "\n",
        "    if test_beam_search:\n",
        "        ## OPTIONAL :- Evaluate the dataset using beam search and without beam search\n",
        "        val_dataset, _, _ = preprocess_data(VAL_TSV, model.input_tokenizer, model.targ_tokenizer)\n",
        "        subset = val_dataset.take(500)\n",
        "\n",
        "        # a) Without beam search\n",
        "        _, test_acc_without = model.evaluate(subset, batch_size=100) \n",
        "        wandb.log({\"test acc\": test_acc_without})\n",
        "        \n",
        "        # b) With beam search\n",
        "        beam_search = BeamSearch(model=model, k=wandb.config.beam_width)\n",
        "        beam_search.evaluate(subset, batch_size=100, use_wandb=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Kx44JYk6uXr"
      },
      "source": [
        "# Sweeps with Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6ZvJVNy6mxE"
      },
      "source": [
        "sweep_config5 = {\n",
        "  \"name\": \"Attention Sweep - Assignment3\",\n",
        "  \"description\": \"Hyperparameter sweep for Seq2Seq Model with Attention\",\n",
        "  \"method\": \"grid\",\n",
        "  \"parameters\": {\n",
        "       \"layer_type\": {\n",
        "            \"values\": [\"gru\", \"rnn\", \"lstm\"]\n",
        "        },\n",
        "        \"enc_dec_layers\": {\n",
        "           \"values\": [2]\n",
        "        },\n",
        "        \"units\": {\n",
        "            \"values\": [256]\n",
        "        },\n",
        "        \"dropout\": {\n",
        "            \"values\": [0.2]\n",
        "        },\n",
        "        \"attention\": {\n",
        "            \"values\": [True]\n",
        "        },\n",
        "         \"teacher_forcing_ratio\": {\n",
        "             \"values\":[0.3,0.5,0.7,1.0]}\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AntGSlwU7RDm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7c6b6ca-658c-4b62-8c2b-a3dbd2667853"
      },
      "source": [
        "sweep_id5 = wandb.sweep(sweep_config5, project='Assignment3-partB_attn', entity='cs21s002-ee21s113-dlassignment-1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: pvvkr8c1\n",
            "Sweep URL: https://wandb.ai/cs21s002-ee21s113-dlassignment-1/Assignment3-partB_attn/sweeps/pvvkr8c1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZtXMBc47h2Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "2f62528b-945f-450e-fc4a-44259ec1e2cf"
      },
      "source": [
        "#wandb.agent(sweep_id5, function=lambda: train_with_wandb(\"kn\"), project='Assignment3-partB_attn', entity='cs21s002-ee21s113-dlassignment-1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1w6ursf6 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_dec_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_type: gru\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220504_214833-1w6ursf6</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/Assignment3-partB_attn/runs/1w6ursf6\" target=\"_blank\">summer-sweep-1</a></strong> to <a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/Assignment3-partB_attn\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/Assignment3-partB_attn/sweeps/pvvkr8c1\" target=\"_blank\">https://wandb.ai/cs21s002-ee21s113-dlassignment-1/Assignment3-partB_attn/sweeps/pvvkr8c1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "EPOCH 1\n",
            "\n",
            "Training ...\n",
            "\n",
            "Batch 1 Loss 4.0005\n",
            "Batch 100 Loss 1.1581\n",
            "Batch 200 Loss 0.9918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#wandb.init(config=config_defaults, project='Assignment3-partB_attn', entity='cs21s002-ee21s113-dlassignment-1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "oZ9nW2hoMqzM",
        "outputId": "1048dbf6-a5cd-405d-ab08-755520800083"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:1w6ursf6) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:1w6ursf6). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220504_223102-1w6ursf6</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/Assignment3-partB_attn/runs/1w6ursf6\" target=\"_blank\">summer-sweep-1</a></strong> to <a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/Assignment3-partB_attn\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/Assignment3-partB_attn/sweeps/pvvkr8c1\" target=\"_blank\">https://wandb.ai/cs21s002-ee21s113-dlassignment-1/Assignment3-partB_attn/sweeps/pvvkr8c1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/Assignment3-partB_attn/runs/1w6ursf6?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f99ba314690>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    }
  ]
}