{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_3_part_B_with_attn_and_Question6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshaygrao77/DeepLearning-Assignment3/blob/main/Assignment_3_part_B_with_attn_and_Question6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2vkvje2XA3r"
      },
      "source": [
        "# CS6910 Assignment 3 -part-B-with attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0qCvgqBxzLo",
        "outputId": "f7981ecb-1eb8-44f1-ab2b-23d1e73a1fec"
      },
      "source": [
        "!pip install wandb\n",
        "!pip install wordcloud\n",
        "!pip install colour"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.16)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb) (1.2.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.8)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.5.11)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.27)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.2.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from wordcloud) (1.21.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from wordcloud) (7.1.2)\n",
            "Requirement already satisfied: colour in /usr/local/lib/python3.7/dist-packages (0.1.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6xB0KDuy95e"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "import wandb\n",
        "import re, string\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.font_manager import FontProperties\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from collections import Counter\n",
        "from colour import Color\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from google.colab import files\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()\n",
        "defaults = {\"embedding_dim\": 512, \n",
        "                       \"enc_dec_layers\": 2,\n",
        "                       \"define_layer\": \"LSTM\",\n",
        "                       \"units\": 512,\n",
        "                       \"dropout\": 0,\n",
        "                       \"attention\": False,\n",
        "                       \"beam_width\": 3,\n",
        "                       \"teacher_forcing_ratio\":0.5\n",
        "                       }\n",
        "wandb.init(config=defaults, project='Assignment3-new_outputs', entity='cs21s002-ee21s113-dlassignment-1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "6iHIdF5HdgmC",
        "outputId": "eba7ec0a-9746-4f11-b2e1-fba72f2fcc8b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmanu_data_analyst\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmanu_data_analyst\u001b[0m (\u001b[33mcs21s002-ee21s113-dlassignment-1\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220507_220142-3ow58krv</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/Assignment3-new_outputs/runs/3ow58krv\" target=\"_blank\">radiant-river-2</a></strong> to <a href=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/Assignment3-new_outputs\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/cs21s002-ee21s113-dlassignment-1/Assignment3-new_outputs/runs/3ow58krv?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f5edd30e350>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVMyzAmMzE1a",
        "outputId": "61b30349-bb10-44a8-c0e6-1941edfba147"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9t1O6AgVjPYm"
      },
      "source": [
        "# Loading the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w96THw2KjYFJ"
      },
      "source": [
        "## Download the dataset ##\n",
        "import requests\n",
        "import tarfile\n",
        "\n",
        "def download_data(save_path):\n",
        "\n",
        "    data_url = r\"https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\"\n",
        "\n",
        "    r = requests.get(data_url, allow_redirects=True)\n",
        "    tar_path = \"data_assignment3.tar\"\n",
        "\n",
        "    if r.status_code == 200:\n",
        "        with open(tar_path, 'wb') as f:\n",
        "            f.write(r.content)\n",
        "\n",
        "    tar_file = tarfile.open(tar_path)\n",
        "    tar_file.extractall(save_path)\n",
        "    tar_file.close()\n",
        "\n",
        "\n",
        "# downloading and extracting the data to drive \n",
        "# uncomment the line below if downloading data for the 1st time\n",
        "#download_data(\"/content/drive/MyDrive/DakshinaDataset\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC_zHEatTLsT"
      },
      "source": [
        "# Files with English to kannada \n",
        "def get_data(language):\n",
        "    \"\"\" Function fo read data \n",
        "    \"\"\"\n",
        "\n",
        "    ## REPLACE THIS PATH UPTO dakshina_dataset_v1.0 with your own dataset path ##\n",
        "    template = \"/content/drive/MyDrive/DakshinaDataset/dakshina_dataset_v1.0/{}/lexicons/{}.translit.sampled.{}.tsv\"\n",
        "\n",
        "    train_input = template.format(language, language, \"train\")\n",
        "    val_input = template.format(language, language, \"dev\")\n",
        "    test_input = template.format(language, language, \"test\")\n",
        "\n",
        "    return train_input, val_input, test_input\n",
        "\n",
        "## Utility functions for preprocessing data ##\n",
        "\n",
        "def add_Tokens(data_Frame, cols, sos=\"\\t\", eos=\"\\n\"):\n",
        "    \"\"\" Adds EOS and SOS tokens \n",
        "    \"\"\"\n",
        "    def add(s):  \n",
        "        # \\t = starting token\n",
        "        # \\n = ending token\n",
        "        return sos + str(s) + eos\n",
        "\n",
        "    for i in cols:\n",
        "        data_Frame[i] = data_Frame[i].apply(add) \n",
        "    \n",
        "def tokenize(lang, tokenizer=None):\n",
        "    \"\"\" Uses keras tokenizer to tokenize \n",
        "    \"\"\"\n",
        "\n",
        "    if tokenizer is None:\n",
        "        tokenizer = Tokenizer(char_level=True)\n",
        "        tokenizer.fit_on_texts(lang)\n",
        "\n",
        "        tensor_token = tokenizer.texts_to_sequences(lang)\n",
        "        tensor_token = tf.keras.preprocessing.sequence.pad_sequences(tensor_token,\n",
        "                                                            padding='post')\n",
        "\n",
        "    else: \n",
        "        tensor_token = tokenizer.texts_to_sequences(lang)\n",
        "        tensor_token = tf.keras.preprocessing.sequence.pad_sequences(tensor_token,\n",
        "                                                            padding='post')\n",
        "\n",
        "    return tensor_token, tokenizer\n",
        "\n",
        "def data_Preprocess(fpath, input_lang_tokenizer=None, targ_lang_tokenizer=None):\n",
        "    \"\"\" Reads, tokenizes and adds SOS/EOS tokens to data \n",
        "    \"\"\"\n",
        "\n",
        "    data_Frame = pd.read_csv(fpath, sep=\"\\t\", header=None)\n",
        "\n",
        "    # adding start and end tokens to know when to stop predicting \n",
        "    add_Tokens(data_Frame, [0,1])\n",
        "    \n",
        "    input_token, input_tokenizer = tokenize(data_Frame[1].astype(str).tolist(), \n",
        "                                                    tokenizer=input_lang_tokenizer)\n",
        "    \n",
        "    targ_tensor, targ_tokenizer = tokenize(data_Frame[0].astype(str).tolist(),\n",
        "                                                    tokenizer=targ_lang_tokenizer) \n",
        "    \n",
        "    dataset = tf.data.Dataset.from_tensor_slices((input_token, targ_tensor))\n",
        "    dataset = dataset.shuffle(len(dataset))\n",
        "    \n",
        "    return dataset, input_tokenizer, targ_tokenizer"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjGJ1sFE-eon"
      },
      "source": [
        "# Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLLikr1QN4kE"
      },
      "source": [
        "## functions ##\n",
        "def define_Layers(name, units, dropout, return_state=False, return_sequences=False):\n",
        "\n",
        "    if name==\"RNN\":\n",
        "        return layers.SimpleRNN(units=units, dropout=dropout, \n",
        "                                return_state=return_state,\n",
        "                                return_sequences=return_sequences)\n",
        "\n",
        "    if name==\"GRU\":\n",
        "        return layers.GRU(units=units, dropout=dropout, \n",
        "                          return_state=return_state,\n",
        "                          return_sequences=return_sequences)\n",
        "\n",
        "    if name==\"LSTM\":\n",
        "        return layers.LSTM(units=units, dropout=dropout, \n",
        "                           return_state=return_state,\n",
        "                           return_sequences=return_sequences)\n",
        "\n",
        "class attention_Layer_RNN(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(attention_Layer_RNN, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, encoder_state, encoder_output):\n",
        "    \n",
        "    encoder_state = tf.concat(encoder_state, 1)\n",
        "    encoder_state = tf.expand_dims(encoder_state, 1)\n",
        "\n",
        "    score = self.V(tf.nn.tanh(self.W1(encoder_state) + self.W2(encoder_output)))\n",
        "\n",
        "    attn_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    attn_vector = attn_weights * encoder_output\n",
        "    attn_vector = tf.reduce_sum(attn_vector, axis=1)\n",
        "\n",
        "    return attn_vector, attn_weights\n",
        "\n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, define_layer, number_layers, units, encoder_vocab_size, embedding_dim, dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.define_layer = define_layer\n",
        "        self.number_layers = number_layers\n",
        "        self.units = units\n",
        "        self.dropout = dropout\n",
        "        self.embedding = tf.keras.layers.Embedding(encoder_vocab_size, embedding_dim)\n",
        "        self.final_RNN_layers()\n",
        "\n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        x = self.RNN_layers[0](x, initial_state=hidden)\n",
        "\n",
        "        for layer in self.RNN_layers[1:]:\n",
        "            x = layer(x)\n",
        "\n",
        "        out,state = x[0], x[1:]\n",
        "\n",
        "        return out,state\n",
        "    \n",
        "    def final_RNN_layers(self):\n",
        "        self.RNN_layers = []\n",
        "\n",
        "        for i in range(self.number_layers):\n",
        "            self.RNN_layers.append(define_Layers(self.define_layer, self.units, self.dropout,\n",
        "                                                return_sequences=True,\n",
        "                                                return_state=True))\n",
        "\n",
        "\n",
        "    def hidden_states(self, batch_size):\n",
        "\n",
        "        if self.define_layer != \"LSTM\":\n",
        "            return [tf.zeros((batch_size, self.units))]\n",
        "        else:\n",
        "            return [tf.zeros((batch_size, self.units))]*2\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, define_layer, number_layers, units, dec_size, embedding_dim, dropout, attention=False):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.define_layer = define_layer\n",
        "        self.number_layers = number_layers\n",
        "        self.units = units\n",
        "        self.dropout = dropout\n",
        "        self.attention = attention\n",
        "        self.embedding_layer = layers.Embedding(input_dim=dec_size, \n",
        "                                                output_dim=embedding_dim)\n",
        "        \n",
        "        self.dense = layers.Dense(dec_size, activation=\"softmax\")\n",
        "        self.flatten = layers.Flatten()\n",
        "        if self.attention:\n",
        "            self.attention_layer = attention_Layer_RNN(self.units)\n",
        "        self.final_RNN_layers()\n",
        "\n",
        "    def call(self, x, hidden, encoder_output=None):\n",
        "        \n",
        "        x = self.embedding_layer(x)\n",
        "\n",
        "        if self.attention:\n",
        "            attn_vector, attn_weights = self.attention_layer(hidden, encoder_output)\n",
        "            x = tf.concat([tf.expand_dims(attn_vector, 1), x], -1)\n",
        "        else:\n",
        "            attn_weights = None\n",
        "\n",
        "        x = self.RNN_layers[0](x, initial_state=hidden)\n",
        "\n",
        "        for layer in self.RNN_layers[1:]:\n",
        "            x = layer(x)\n",
        "\n",
        "        out,state = x[0], x[1:]\n",
        "\n",
        "        out= self.dense(self.flatten(out))\n",
        "        \n",
        "        return out,state, attn_weights\n",
        "\n",
        "    def final_RNN_layers(self):\n",
        "        self.RNN_layers = []    \n",
        "\n",
        "        for i in range(self.number_layers - 1):\n",
        "            self.RNN_layers.append(define_Layers(self.define_layer, self.units, self.dropout,\n",
        "                                                return_sequences=True,\n",
        "                                                return_state=True))\n",
        "        \n",
        "        self.RNN_layers.append(define_Layers(self.define_layer, self.units, self.dropout,\n",
        "                                            return_sequences=False,\n",
        "                                            return_state=True))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwR1miyeRrIG"
      },
      "source": [
        "class Seq2Seq_RNN_Model():\n",
        "    def __init__(self, embedding_dim, encoder_layers, dec_layers, define_layer, units, dropout, attention=False):\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.encoder_layers = encoder_layers\n",
        "        self.dec_layers = dec_layers\n",
        "        self.define_layer = define_layer\n",
        "        self.units = units\n",
        "        self.dropout = dropout\n",
        "        self.attention = attention\n",
        "        self.stats = []\n",
        "        self.batch_size = 128\n",
        "        self.use_beam_search = False\n",
        "\n",
        "    def build(self, loss, optimizer, metric):\n",
        "        self.loss = loss\n",
        "        self.optimizer = optimizer\n",
        "        self.metric = metric\n",
        "\n",
        "    def set_vocabulary(self, input_tokenizer, targ_tokenizer):\n",
        "        self.input_tokenizer = input_tokenizer\n",
        "        self.targ_tokenizer = targ_tokenizer\n",
        "        self.model_create()\n",
        "    \n",
        "    def model_create(self):\n",
        "\n",
        "        encoder_vocab_size = len(self.input_tokenizer.word_index) + 1\n",
        "        dec_size = len(self.targ_tokenizer.word_index) + 1\n",
        "\n",
        "        self.encoder = Encoder(self.define_layer, self.encoder_layers, self.units, encoder_vocab_size,\n",
        "                               self.embedding_dim, self.dropout)\n",
        "\n",
        "        self.dec = Decoder(self.define_layer, self.dec_layers, self.units, dec_size,\n",
        "                               self.embedding_dim,  self.dropout, self.attention)\n",
        "\n",
        "    @tf.function\n",
        "    def Training(self, input, target, encoder_state):\n",
        "\n",
        "        loss = 0 \n",
        "\n",
        "        with tf.GradientTape() as tape: \n",
        "\n",
        "            encoder_output, encoder_state = self.encoder(input, encoder_state)\n",
        "\n",
        "            dec_state = encoder_state\n",
        "            dec_input = tf.expand_dims([self.targ_tokenizer.word_index[\"\\t\"]]*self.batch_size ,1)\n",
        "\n",
        "            ##  Teacher forcing to train \n",
        "            ## Each target at timestep t is passed as input nest timestamp\n",
        "\n",
        "            if random.random() < self.teacher_forcing_ratio:\n",
        "\n",
        "                for t in range(1, target.shape[1]):\n",
        "\n",
        "                    preds, dec_state, _ = self.dec(dec_input, dec_state, encoder_output)\n",
        "                    loss += self.loss(target[:,t], preds)\n",
        "                    self.metric.update_state(target[:,t], preds)\n",
        "                    \n",
        "                    dec_input = tf.expand_dims(target[:,t], 1)\n",
        "            \n",
        "            else:\n",
        "\n",
        "                for i in range(1, target.shape[1]):\n",
        "\n",
        "                    preds, dec_state, _ = self.dec(dec_input, dec_state, encoder_output)\n",
        "                    loss += self.loss(target[:,i], preds)\n",
        "                    self.metric.update_state(target[:,i], preds)\n",
        "\n",
        "                    preds = tf.argmax(preds, 1)\n",
        "                    dec_input = tf.expand_dims(preds, 1)\n",
        "\n",
        "\n",
        "            batch_loss = loss / target.shape[1]\n",
        "\n",
        "            variables = self.encoder.variables + self.dec.variables\n",
        "            gradients = tape.gradient(loss, variables)\n",
        "\n",
        "            self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "        return batch_loss, self.metric.result()\n",
        "\n",
        "    @tf.function\n",
        "    def validation_step(self, input, target, encoder_state):\n",
        "\n",
        "        loss = 0\n",
        "        \n",
        "        encoder_output, encoder_state = self.encoder(input, encoder_state)\n",
        "\n",
        "        dec_state = encoder_state\n",
        "        dec_input = tf.expand_dims([self.targ_tokenizer.word_index[\"\\t\"]]*self.batch_size ,1)\n",
        "\n",
        "        for t in range(1, target.shape[1]):\n",
        "\n",
        "            preds, dec_state, _ = self.dec(dec_input, dec_state, encoder_output)\n",
        "            loss += self.loss(target[:,t], preds)\n",
        "            self.metric.update_state(target[:,t], preds)\n",
        "\n",
        "            preds = tf.argmax(preds, 1)\n",
        "            dec_input = tf.expand_dims(preds, 1)\n",
        "\n",
        "        batch_loss = loss / target.shape[1]\n",
        "        \n",
        "        return batch_loss, self.metric.result()\n",
        "\n",
        "\n",
        "    def fit(self, dataset, val_dataset, batch_size=128, epochs=10, use_wandb=False, teacher_forcing_ratio=1.0):\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
        "\n",
        "        steps_per_epoch = len(dataset) // self.batch_size\n",
        "        steps_per_epoch_val = len(val_dataset) // self.batch_size\n",
        "        \n",
        "        dataset = dataset.batch(self.batch_size, drop_remainder=True)\n",
        "        val_dataset = val_dataset.batch(self.batch_size, drop_remainder=True)\n",
        "\n",
        "        # useful when we need to translate the sentence\n",
        "        sample_inp, sample_targ = next(iter(dataset))\n",
        "        self.max_target_len = sample_targ.shape[1]\n",
        "        self.max_input_len = sample_inp.shape[1]\n",
        "\n",
        "        template = \"\\nTrain Loss: {0:.4f} Train Accuracy: {1:.4f} Validation Loss: {2:.4f} Validation Accuracy: {3:.4f}\"\n",
        "\n",
        "        print(\"-\"*100)\n",
        "        for epoch in range(1, epochs+1):\n",
        "            print(f\"EPOCH {epoch}\\n\")\n",
        "\n",
        "            ## Training loop ##\n",
        "            total_loss = 0\n",
        "            total_acc = 0\n",
        "            self.metric.reset_states()\n",
        "\n",
        "            starting_time = time.time()\n",
        "            encoder_state = self.encoder.hidden_states(self.batch_size)\n",
        "\n",
        "            print(\"validating_model....\")\n",
        "            for batch, (input, target) in enumerate(dataset.take(steps_per_epoch)):\n",
        "                batch_loss, acc = self.Training(input, target, encoder_state)\n",
        "                total_loss += batch_loss\n",
        "                total_acc += acc\n",
        "\n",
        "\n",
        "                if batch==0 or ((batch + 1) % 100 == 0):\n",
        "                    print(f\"Batch {batch+1} Loss {batch_loss:.4f}\")\n",
        "\n",
        "            avg_acc = total_acc / steps_per_epoch\n",
        "            avg_loss = total_loss / steps_per_epoch\n",
        "\n",
        "            # Validation loop ##\n",
        "            total_val_loss = 0\n",
        "            total_val_acc = 0\n",
        "            self.metric.reset_states()\n",
        "\n",
        "            encoder_state = self.encoder.hidden_states(self.batch_size)\n",
        "\n",
        "            print(\"\\nValidating ...\")\n",
        "            for batch, (input, target) in enumerate(val_dataset.take(steps_per_epoch_val)):\n",
        "                batch_loss, acc = self.validation_step(input, target, encoder_state)\n",
        "                total_val_loss += batch_loss\n",
        "                total_val_acc += acc\n",
        "\n",
        "            validation_accuracy = total_val_acc / steps_per_epoch_val\n",
        "            validation_loss = total_val_loss / steps_per_epoch_val\n",
        "\n",
        "            print(template.format(avg_loss, avg_acc*100, validation_loss, validation_accuracy*100))\n",
        "            \n",
        "            time_taken = time.time() - starting_time\n",
        "            self.stats.append({\"epoch\": epoch,\n",
        "                            \"train loss\": avg_loss,\n",
        "                            \"val loss\": validation_loss,\n",
        "                            \"train acc\": avg_acc*100,\n",
        "                            \"val acc\": validation_accuracy*100,\n",
        "                            \"training time\": time_taken})\n",
        "            \n",
        "\n",
        "          \n",
        "       \n",
        "        \n",
        "    def evaluate(self, test_dataset, batch_size=None):\n",
        "\n",
        "        if batch_size is not None:\n",
        "            self.batch_size = batch_size\n",
        "\n",
        "        steps_per_epoch_test = len(test_dataset) // batch_size\n",
        "        test_dataset = test_dataset.batch(batch_size, drop_remainder=True)\n",
        "        \n",
        "        total_test_loss = 0\n",
        "        total_test_acc = 0\n",
        "        self.metric.reset_states()\n",
        "\n",
        "        encoder_state = self.encoder.hidden_states(self.batch_size)\n",
        "\n",
        "        print(\"\\nRunning test dataset through the model...\\n\")\n",
        "        for batch, (input, target) in enumerate(test_dataset.take(steps_per_epoch_test)):\n",
        "            batch_loss, acc = self.validation_step(input, target, encoder_state)\n",
        "            total_test_loss += batch_loss\n",
        "            total_test_acc += acc\n",
        "\n",
        "        test_Accuracy = total_test_acc / steps_per_epoch_test\n",
        "        test_Loss = total_test_loss / steps_per_epoch_test\n",
        "    \n",
        "        print(f\"Test Loss: {test_Loss:.4f} Test Accuracy: {test_Accuracy:.4f}\")\n",
        "        wandb.log({\"Test_Loss\": test_Loss})\n",
        "        wandb.log({\"Test Accuracy\": test_Loss})\n",
        "\n",
        "        return test_Loss, test_Accuracy\n",
        "\n",
        "\n",
        "    def translate(self, word, get_heatmap=True):\n",
        "\n",
        "        word = \"\\t\" + word + \"\\n\"\n",
        "\n",
        "        inputs = self.input_tokenizer.texts_to_sequences([word])\n",
        "        inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
        "                                                               maxlen=self.max_input_len,\n",
        "                                                               padding=\"post\")\n",
        "\n",
        "        result = \"\"\n",
        "        att_wts = []\n",
        "\n",
        "        encoder_state = self.encoder.hidden_states(1)\n",
        "        encoder_output, encoder_state = self.encoder(inputs, encoder_state)\n",
        "\n",
        "        dec_state = encoder_state\n",
        "        dec_input = tf.expand_dims([self.targ_tokenizer.word_index[\"\\t\"]]*1, 1)\n",
        "\n",
        "        for t in range(1, self.max_target_len):\n",
        "\n",
        "            preds, dec_state, attn_weights = self.dec(dec_input, dec_state, encoder_output)\n",
        "            \n",
        "            if get_heatmap:\n",
        "                att_wts.append(attn_weights)\n",
        "            \n",
        "            preds = tf.argmax(preds, 1)\n",
        "            next_char = self.targ_tokenizer.index_word[preds.numpy().item()]\n",
        "            result += next_char\n",
        "\n",
        "            dec_input = tf.expand_dims(preds, 1)\n",
        "\n",
        "            if next_char == \"\\n\":\n",
        "                return result[:-1], att_wts[:-1]\n",
        "\n",
        "        return result[:-1], att_wts[:-1]\n",
        "\n",
        "    def plot_attention_heatmap(self, word):\n",
        "\n",
        "        translated_word, attn_wts = self.translate(word, get_heatmap=True)\n",
        "        attn_heatmap = tf.squeeze(tf.concat(attn_wts, 0), -1).numpy()\n",
        "\n",
        "        input_word_len = len(word)\n",
        "        output_word_len = len(translated_word)\n",
        "        list(word).sort()\n",
        "        list(translated_word).sort()\n",
        "        wandb.log({'heatmap_with_attn': wandb.plots.HeatMap(list(word), list(translated_word), attn_heatmap[:, :input_word_len], show_text=False)})\n",
        "       "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSZFHEmw9KRw"
      },
      "source": [
        "# Visualizing Model Outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPPCBrHukCMZ"
      },
      "source": [
        "def randomly_evaluate(model, test_file=get_data(\"kn\")[2], n=10):\n",
        "\n",
        "    data_Frame = pd.read_csv(test_file, sep=\"\\t\", header=None)\n",
        "    data_Frame = data_Frame.sample(n=n).reset_index(drop=True)\n",
        "\n",
        "    print(f\"Randomly evaluating the model on {n} words\\n\")\n",
        "    my_data=[]\n",
        "    for i in range(n):\n",
        "        word = str(data_Frame[1][i])\n",
        "\n",
        "        print(f\"Input word: {word}\")\n",
        "        print(f\"Actual translation: {str(data_Frame[0][i])}\")\n",
        "        print(f\"Model translation: {model.translate(word)[0]}\\n\")\n",
        "        my_data.append([i,word,str(data_Frame[0][i]),model.translate(word)[0]])\n",
        "    columns=[\"id\",\"Input word\", \"Actual translation\",\"Model translation\"]\n",
        "    my_table = wandb.Table(data=my_data, columns=columns)\n",
        "    wandb.log({\"table_key\": my_table})\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "def train_best_model(language, embedding_dim, encoder_layers, dec_layers, define_layer, units, dropout, attention, teacher_forcing_ratio=1.0, save_outputs=None):\n",
        "    \n",
        "    TRAIN_INPUT, val_input, test_input = get_data(language)\n",
        "\n",
        "    model = Seq2Seq_RNN_Model(embedding_dim, \n",
        "                         encoder_layers, \n",
        "                         dec_layers, \n",
        "                         define_layer, \n",
        "                         units,\n",
        "                         dropout,\n",
        "                         attention)\n",
        "\n",
        "    dataset, input_tokenizer, targ_tokenizer = data_Preprocess(TRAIN_INPUT)\n",
        "    val_dataset, _, _ = data_Preprocess(val_input, input_tokenizer, targ_tokenizer)\n",
        "\n",
        "    model.set_vocabulary(input_tokenizer, targ_tokenizer)\n",
        "    model.build(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metric = tf.keras.metrics.SparseCategoricalAccuracy())\n",
        "    \n",
        "    model.fit(dataset, val_dataset, epochs=30, use_wandb=True, teacher_forcing_ratio=teacher_forcing_ratio)\n",
        "\n",
        "    ## Character level accuracy ##\n",
        "    test_dataset, _, _ = data_Preprocess(test_input, model.input_tokenizer, model.targ_tokenizer)\n",
        "    test_loss, test_acc = model.evaluate(test_dataset, batch_size=100)\n",
        "\n",
        "    ##  Word level accuracy ##\n",
        "    test_input = pd.read_csv(test_input, sep=\"\\t\", header=None)\n",
        "    inputs = test_input[1].astype(str).tolist()\n",
        "    targets = test_input[0].astype(str).tolist()\n",
        "    \n",
        "    outputs = []\n",
        "\n",
        "    for word in inputs:\n",
        "        outputs.append(model.translate(word)[0])\n",
        "\n",
        "    def word_level_acc(outputs, targets):\n",
        "        return np.sum(np.asarray(outputs) == np.array(targets)) / len(outputs)\n",
        "\n",
        "    print(f\"Word level accuracy: {word_level_acc(outputs, targets)}\")\n",
        "\n",
        "    \n",
        "    data_Frame = pd.DataFrame()\n",
        "    data_Frame[\"inputs\"] = inputs\n",
        "    data_Frame[\"targets\"] = targets\n",
        "    data_Frame[\"outputs\"] = outputs\n",
        "    data_Frame.to_csv('predictions_attention.csv', encoding = 'utf-8-sig') \n",
        "    files.download('predictions_attention.csv')\n",
        "\n",
        "\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RUN BEST MODEL _ FUNCTION"
      ],
      "metadata": {
        "id": "7GKJBr8M32Op"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kzkdsWRlZzTf",
        "outputId": "e656a114-5105-43b6-f5e8-dc5f12d4c859"
      },
      "source": [
        "model = train_best_model(language=\"kn\",\n",
        "                        embedding_dim=64,\n",
        "                        encoder_layers=2,\n",
        "                        dec_layers=2,\n",
        "                        define_layer=\"LSTM\",\n",
        "                        units=256,\n",
        "                        dropout=0.2,\n",
        "                        attention=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "EPOCH 1\n",
            "\n",
            "validating_model....\n",
            "Batch 1 Loss 3.9938\n",
            "Batch 100 Loss 1.1259\n",
            "Batch 200 Loss 0.9969\n",
            "Batch 300 Loss 0.9122\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 1.1046 Train Accuracy: 65.6259 Validation Loss: 2.1946 Validation Accuracy: 57.3341\n",
            "EPOCH 2\n",
            "\n",
            "validating_model....\n",
            "Batch 1 Loss 0.8512\n",
            "Batch 100 Loss 0.8133\n",
            "Batch 200 Loss 0.8009\n",
            "Batch 300 Loss 0.6969\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.7622 Train Accuracy: 75.9704 Validation Loss: 2.0829 Validation Accuracy: 61.5177\n",
            "EPOCH 3\n",
            "\n",
            "validating_model....\n",
            "Batch 1 Loss 0.6679\n",
            "Batch 100 Loss 0.6277\n",
            "Batch 200 Loss 0.5608\n",
            "Batch 300 Loss 0.4710\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.5386 Train Accuracy: 81.8841 Validation Loss: 1.8261 Validation Accuracy: 68.6165\n",
            "EPOCH 4\n",
            "\n",
            "validating_model....\n",
            "Batch 1 Loss 0.4151\n",
            "Batch 100 Loss 0.3075\n",
            "Batch 200 Loss 0.2985\n",
            "Batch 300 Loss 0.2474\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.3050 Train Accuracy: 89.0632 Validation Loss: 1.5367 Validation Accuracy: 76.6223\n",
            "EPOCH 5\n",
            "\n",
            "validating_model....\n",
            "Batch 1 Loss 0.2216\n",
            "Batch 100 Loss 0.2022\n",
            "Batch 200 Loss 0.1438\n",
            "Batch 300 Loss 0.1306\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.1654 Train Accuracy: 94.2024 Validation Loss: 1.1331 Validation Accuracy: 84.3814\n",
            "EPOCH 6\n",
            "\n",
            "validating_model....\n",
            "Batch 1 Loss 0.1505\n",
            "Batch 100 Loss 0.1114\n",
            "Batch 200 Loss 0.0930\n",
            "Batch 300 Loss 0.0929\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.1042 Train Accuracy: 96.5418 Validation Loss: 0.9359 Validation Accuracy: 88.2706\n",
            "EPOCH 7\n",
            "\n",
            "validating_model....\n",
            "Batch 1 Loss 0.0727\n",
            "Batch 100 Loss 0.0866\n",
            "Batch 200 Loss 0.0771\n",
            "Batch 300 Loss 0.0637\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0766 Train Accuracy: 97.5584 Validation Loss: 0.8864 Validation Accuracy: 89.3552\n",
            "EPOCH 8\n",
            "\n",
            "validating_model....\n",
            "Batch 1 Loss 0.0499\n",
            "Batch 100 Loss 0.0430\n",
            "Batch 200 Loss 0.0438\n",
            "Batch 300 Loss 0.0576\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0611 Train Accuracy: 98.0870 Validation Loss: 0.8767 Validation Accuracy: 89.6308\n",
            "EPOCH 9\n",
            "\n",
            "validating_model....\n",
            "Batch 1 Loss 0.0394\n",
            "Batch 100 Loss 0.0534\n",
            "Batch 200 Loss 0.0660\n",
            "Batch 300 Loss 0.0432\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0500 Train Accuracy: 98.4690 Validation Loss: 0.8946 Validation Accuracy: 89.9583\n",
            "EPOCH 10\n",
            "\n",
            "validating_model....\n",
            "Batch 1 Loss 0.0442\n",
            "Batch 100 Loss 0.0425\n",
            "Batch 200 Loss 0.0420\n",
            "Batch 300 Loss 0.0426\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0426 Train Accuracy: 98.6685 Validation Loss: 0.9112 Validation Accuracy: 90.2682\n",
            "EPOCH 11\n",
            "\n",
            "validating_model....\n",
            "Batch 1 Loss 0.0351\n",
            "Batch 100 Loss 0.0350\n",
            "Batch 200 Loss 0.0362\n",
            "Batch 300 Loss 0.0453\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0365 Train Accuracy: 98.8718 Validation Loss: 0.9336 Validation Accuracy: 89.9952\n",
            "EPOCH 12\n",
            "\n",
            "validating_model....\n",
            "Batch 1 Loss 0.0278\n",
            "Batch 100 Loss 0.0263\n",
            "Batch 200 Loss 0.0305\n",
            "Batch 300 Loss 0.0361\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0309 Train Accuracy: 99.0731 Validation Loss: 0.9018 Validation Accuracy: 90.6708\n",
            "EPOCH 13\n",
            "\n",
            "validating_model....\n",
            "Batch 1 Loss 0.0221\n",
            "Batch 100 Loss 0.0238\n",
            "Batch 200 Loss 0.0272\n",
            "Batch 300 Loss 0.0281\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0267 Train Accuracy: 99.1875 Validation Loss: 0.9540 Validation Accuracy: 90.6533\n",
            "EPOCH 14\n",
            "\n",
            "validating_model....\n",
            "Batch 1 Loss 0.0207\n",
            "Batch 100 Loss 0.0265\n",
            "Batch 200 Loss 0.0291\n",
            "Batch 300 Loss 0.0320\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0246 Train Accuracy: 99.2476 Validation Loss: 0.9466 Validation Accuracy: 90.6424\n",
            "EPOCH 15\n",
            "\n",
            "validating_model....\n",
            "Batch 1 Loss 0.0191\n",
            "Batch 100 Loss 0.0193\n",
            "Batch 200 Loss 0.0246\n",
            "Batch 300 Loss 0.0246\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0214 Train Accuracy: 99.3607 Validation Loss: 1.0068 Validation Accuracy: 90.4445\n",
            "EPOCH 16\n",
            "\n",
            "validating_model....\n",
            "Batch 1 Loss 0.0217\n",
            "Batch 100 Loss 0.0168\n",
            "Batch 200 Loss 0.0208\n",
            "Batch 300 Loss 0.0211\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0186 Train Accuracy: 99.4444 Validation Loss: 0.9995 Validation Accuracy: 90.8148\n",
            "EPOCH 17\n",
            "\n",
            "validating_model....\n",
            "Batch 1 Loss 0.0178\n",
            "Batch 100 Loss 0.0121\n",
            "Batch 200 Loss 0.0190\n",
            "Batch 300 Loss 0.0168\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0181 Train Accuracy: 99.4640 Validation Loss: 1.0194 Validation Accuracy: 90.5009\n",
            "EPOCH 18\n",
            "\n",
            "validating_model....\n",
            "Batch 1 Loss 0.0103\n",
            "Batch 100 Loss 0.0104\n",
            "Batch 200 Loss 0.0168\n",
            "Batch 300 Loss 0.0263\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0173 Train Accuracy: 99.4698 Validation Loss: 1.0504 Validation Accuracy: 90.1638\n",
            "EPOCH 19\n",
            "\n",
            "validating_model....\n",
            "Batch 1 Loss 0.0210\n",
            "Batch 100 Loss 0.0124\n",
            "Batch 200 Loss 0.0132\n",
            "Batch 300 Loss 0.0156\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0146 Train Accuracy: 99.5433 Validation Loss: 1.0326 Validation Accuracy: 90.4181\n",
            "EPOCH 20\n",
            "\n",
            "validating_model....\n",
            "Batch 1 Loss 0.0108\n",
            "Batch 100 Loss 0.0095\n",
            "Batch 200 Loss 0.0139\n",
            "Batch 300 Loss 0.0132\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0127 Train Accuracy: 99.6177 Validation Loss: 1.0096 Validation Accuracy: 90.7722\n",
            "EPOCH 21\n",
            "\n",
            "validating_model....\n",
            "Batch 1 Loss 0.0085\n",
            "Batch 100 Loss 0.0115\n",
            "Batch 200 Loss 0.0118\n",
            "Batch 300 Loss 0.0168\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0140 Train Accuracy: 99.5700 Validation Loss: 1.0102 Validation Accuracy: 90.9632\n",
            "EPOCH 22\n",
            "\n",
            "validating_model....\n",
            "Batch 1 Loss 0.0108\n",
            "Batch 100 Loss 0.0134\n",
            "Batch 200 Loss 0.0107\n",
            "Batch 300 Loss 0.0108\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0128 Train Accuracy: 99.5967 Validation Loss: 1.0905 Validation Accuracy: 90.7471\n",
            "EPOCH 23\n",
            "\n",
            "validating_model....\n",
            "Batch 1 Loss 0.0118\n",
            "Batch 100 Loss 0.0129\n",
            "Batch 200 Loss 0.0189\n",
            "Batch 300 Loss 0.0154\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0115 Train Accuracy: 99.6557 Validation Loss: 1.1127 Validation Accuracy: 90.5018\n",
            "EPOCH 24\n",
            "\n",
            "validating_model....\n",
            "Batch 1 Loss 0.0096\n",
            "Batch 100 Loss 0.0111\n",
            "Batch 200 Loss 0.0110\n",
            "Batch 300 Loss 0.0098\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0111 Train Accuracy: 99.6697 Validation Loss: 1.0361 Validation Accuracy: 90.8687\n",
            "EPOCH 25\n",
            "\n",
            "validating_model....\n",
            "Batch 1 Loss 0.0105\n",
            "Batch 100 Loss 0.0067\n",
            "Batch 200 Loss 0.0130\n",
            "Batch 300 Loss 0.0122\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0102 Train Accuracy: 99.6731 Validation Loss: 1.1734 Validation Accuracy: 90.5058\n",
            "EPOCH 26\n",
            "\n",
            "validating_model....\n",
            "Batch 1 Loss 0.0065\n",
            "Batch 100 Loss 0.0062\n",
            "Batch 200 Loss 0.0077\n",
            "Batch 300 Loss 0.0082\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0093 Train Accuracy: 99.7182 Validation Loss: 1.1054 Validation Accuracy: 90.8767\n",
            "EPOCH 27\n",
            "\n",
            "validating_model....\n",
            "Batch 1 Loss 0.0106\n",
            "Batch 100 Loss 0.0090\n",
            "Batch 200 Loss 0.0087\n",
            "Batch 300 Loss 0.0140\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0109 Train Accuracy: 99.6769 Validation Loss: 1.0994 Validation Accuracy: 90.6341\n",
            "EPOCH 28\n",
            "\n",
            "validating_model....\n",
            "Batch 1 Loss 0.0088\n",
            "Batch 100 Loss 0.0101\n",
            "Batch 200 Loss 0.0083\n",
            "Batch 300 Loss 0.0145\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0114 Train Accuracy: 99.6461 Validation Loss: 1.1567 Validation Accuracy: 90.7780\n",
            "EPOCH 29\n",
            "\n",
            "validating_model....\n",
            "Batch 1 Loss 0.0120\n",
            "Batch 100 Loss 0.0069\n",
            "Batch 200 Loss 0.0075\n",
            "Batch 300 Loss 0.0095\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0090 Train Accuracy: 99.7087 Validation Loss: 1.2042 Validation Accuracy: 90.6935\n",
            "EPOCH 30\n",
            "\n",
            "validating_model....\n",
            "Batch 1 Loss 0.0088\n",
            "Batch 100 Loss 0.0081\n",
            "Batch 200 Loss 0.0129\n",
            "Batch 300 Loss 0.0069\n",
            "\n",
            "Validating ...\n",
            "\n",
            "Train Loss: 0.0086 Train Accuracy: 99.7261 Validation Loss: 1.0904 Validation Accuracy: 91.2702\n",
            "\n",
            "Running test dataset through the model...\n",
            "\n",
            "Test Loss: 1.0915 Test Accuracy: 0.9118\n",
            "Word level accuracy: 0.5191202694670101\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9cff7072-f23c-4467-ab38-bd5ac503c874\", \"predictions_attention.csv\", 337735)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvVSaWfGYvvn"
      },
      "source": [
        "# Visualizing Model Connectivity (Q6)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeWT7Yno7LXd"
      },
      "source": [
        "# model connectivity between input and output characters\n",
        "def LSTM_estimate(dec, x, hidden, encoder_output=None):\n",
        "    \n",
        "    x = dec.embedding_layer(x)\n",
        "\n",
        "    if dec.attention:\n",
        "        attn_vector, attn_weights = dec.attention_layer(hidden, encoder_output)\n",
        "        x = tf.concat([tf.expand_dims(attn_vector, 1), x], -1)\n",
        "    else:\n",
        "        attn_weights = None\n",
        "\n",
        "    x = dec.RNN_layers[0](x, initial_state=hidden)\n",
        "\n",
        "    for layer in dec.RNN_layers[1:]:\n",
        "        x = layer(x)\n",
        "\n",
        "    out,state = x[0], x[1:]\n",
        "\n",
        "    #output = dec.dense(dec.flatten(output))\n",
        "    \n",
        "    return out,state, attn_weights\n",
        "\n",
        "def output_embeded(encoder, x, hidden):\n",
        "\n",
        "    x = encoder.RNN_layers[0](x, initial_state=hidden)\n",
        "\n",
        "    for layer in encoder.RNN_layers[1:]:\n",
        "        x = layer(x)\n",
        "\n",
        "    out,state = x[0], x[1:]\n",
        "\n",
        "    return out,state\n",
        "\n",
        "\n",
        "def get_connectivity(model, word):\n",
        "\n",
        "    word = \"\\t\" + word + \"\\n\"\n",
        "\n",
        "    inputs = model.input_tokenizer.texts_to_sequences([word])\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
        "                                                            maxlen=model.max_input_len,\n",
        "                                                            padding=\"post\")\n",
        "\n",
        "    result = \"\"\n",
        "\n",
        "    gradient_list = []\n",
        "\n",
        "    encoder_state = model.encoder.hidden_states(1)\n",
        "    embedded_in = model.encoder.embedding(inputs)\n",
        "\n",
        "\n",
        "    with tf.GradientTape(persistent=True, watch_accessed_variables=False) as tape:\n",
        "        tape.watch(embedded_in)\n",
        "\n",
        "        encoder_output, encoder_state = output_embeded(model.encoder, embedded_in, encoder_state)\n",
        "\n",
        "        dec_state = encoder_state\n",
        "        dec_input = tf.expand_dims([model.targ_tokenizer.word_index[\"\\t\"]]*1, 1)\n",
        "\n",
        "        for t in range(1, model.max_target_len):\n",
        "\n",
        "            LSTM_output, dec_state, _ = LSTM_estimate(model.dec, dec_input, dec_state, encoder_output)\n",
        "\n",
        "            preds = model.dec.dense(model.dec.flatten(LSTM_output))\n",
        "            gradient_list.append(tape.gradient(LSTM_output, embedded_in)[0])\n",
        "            \n",
        "            preds = tf.argmax(preds, 1)\n",
        "            next_char = model.targ_tokenizer.index_word[preds.numpy().item()]\n",
        "            result += next_char\n",
        "\n",
        "            dec_input = tf.expand_dims(preds, 1)\n",
        "\n",
        "            if next_char == \"\\n\":\n",
        "                return result[:-1], gradient_list[:-1]\n",
        "\n",
        "        return result[:-1], gradient_list[:-1]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22kfP4uvp63B"
      },
      "source": [
        "# Imports for visualising the model connectivity\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from IPython.display import HTML as html_print\n",
        "from IPython.display import display\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# get html element\n",
        "def cstr(s, color='black'):\n",
        "    if s == ' ':\n",
        "      return \"<text style=color:#000;padding-left:10px;background-color:{}> </text>\".format(color, s)\n",
        "    else:\n",
        "      return \"<text style=color:#000;background-color:{}>{} </text>\".format(color, s)\n",
        "\t\n",
        "# print html\n",
        "def print_color(t):\n",
        "\t  display(html_print(''.join([cstr(ti, color=ci) for ti,ci in t])))\n",
        "\n",
        "# get appropriate color for value\n",
        "def get_clr(value):\n",
        "    colors = ['#85c2e1', '#89c4e2', '#95cae5', '#99cce6', '#a1d0e8'\n",
        "      '#b2d9ec', '#baddee', '#c2e1f0', '#eff7fb', '#f9e8e8',\n",
        "      '#f9e8e8', '#f9d4d4', '#f9bdbd', '#f8a8a8', '#f68f8f',\n",
        "      '#f47676', '#f45f5f', '#f34343', '#f33b3b', '#f42e2e']\n",
        "    value = int(value * 19)\n",
        "    if value == 19:\n",
        "        value -= 1\n",
        "    return colors[value]\n",
        "\n",
        "# sigmoid function\n",
        "def sigmoid(x):\n",
        "    z = 1/(1 + np.exp(-x)) \n",
        "    return z\n",
        "\n",
        "def softmax(x):\n",
        "    v = np.exp(x)\n",
        "    v = v / np.sum(v)\n",
        "    return v\n",
        "\n",
        "def get_gradient_norms(grad_list, word, activation=\"sigmoid\"):\n",
        "    grad_norms = []\n",
        "    for grad_tensor in grad_list:\n",
        "        grad_mags = tf.norm(grad_tensor, axis=1)\n",
        "        grad_mags = grad_mags[:len(word)]\n",
        "        if activation == \"softmax\":\n",
        "            grad_mags_scaled = softmax(grad_mags)\n",
        "        elif activation == \"scaler\":\n",
        "            scaler = MinMaxScaler()\n",
        "            grad_mags = tf.reshape(grad_mags, (-1,1))\n",
        "            grad_mags_scaled = scaler.fit_transform(grad_mags)\n",
        "        else:\n",
        "            grad_mags_scaled = sigmoid(grad_mags)\n",
        "        grad_norms.append(grad_mags_scaled)\n",
        "    return grad_norms\n",
        "\n",
        "def visualize(grad_norms, word, translated_word):\n",
        "    print(\"Original Word:\", word)\n",
        "    print(\"Transliterated Word:\", translated_word)\n",
        "    for i in range(len(translated_word)):\n",
        "        print(\"Connectivity Visualization for\", translated_word[i],\":\")\n",
        "        text_colours = []\n",
        "        for j in range(len(grad_norms[i])):\n",
        "            text = (word[j], get_clr(grad_norms[i][j]))\n",
        "            text_colours.append(text)\n",
        "        print_color(text_colours)\n",
        "        data_table = wandb.Table(data=text_colours, columns=[\"s_ind\", \"t_ind\"])\n",
        "        fields = {\n",
        "                     \"s_index\": \"s_ind\",\n",
        "                     \"t_index\": \"t_ind\"\n",
        "\n",
        "                }\n",
        "        wandb.log({\"heatmap\": wandb.plot_table(\n",
        "                       vega_spec_name=\"spec-visualization\",\n",
        "                       data_table=data_table,\n",
        "                       fields=fields\n",
        "                       )\n",
        "                   })\n",
        "\n",
        "def visualise_connectivity(model, word, activation=\"sigmoid\"):\n",
        "    translated_word, grad_list = get_connectivity(model, word)\n",
        "    grad_norms = get_gradient_norms(grad_list, word, activation)\n",
        "    visualize(grad_norms, word, translated_word)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_words_sample(n):\n",
        "    test_df = pd.read_csv(get_data(\"kn\")[2])\n",
        "    test_sample = test_df.sample(n)\n",
        "    test_sample.reset_index(inplace=True, drop=True)\n",
        "    test_words = []\n",
        "    for i in test_sample.index:\n",
        "        entry = test_sample[\"ಅಂಗಡಿ\\tangadi\\t3\"].loc[i]\n",
        "        parts = entry.split(\"\\t\")\n",
        "        word = parts[1]\n",
        "        test_words.append(word)\n",
        "    return test_words\n",
        "\n",
        "test_words = test_words_sample(5)\n",
        "print(test_words)\n",
        "for word in test_words:\n",
        "    visualise_connectivity(model, word, activation=\"scaler\")"
      ],
      "metadata": {
        "id": "q2i9g6SHCIvs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8bba6c4c-a6d9-4a87-b489-e8f6785b4b7e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['anumatiyillade', 'bhinnavaagiruva', 'ranarangada', 'hanuma', 'kedet']\n",
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
            "Original Word: anumatiyillade\n",
            "Transliterated Word: ಅನುಮತಿಯಿಲ್ಲದೆ\n",
            "Connectivity Visualization for ಅ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#f42e2e>a </text><text style=color:#000;background-color:#f9e8e8>n </text><text style=color:#000;background-color:#f9e8e8>u </text><text style=color:#000;background-color:#f8a8a8>m </text><text style=color:#000;background-color:#f9bdbd>a </text><text style=color:#000;background-color:#a1d0e8#b2d9ec>t </text><text style=color:#000;background-color:#baddee>i </text><text style=color:#000;background-color:#f9d4d4>y </text><text style=color:#000;background-color:#f9bdbd>i </text><text style=color:#000;background-color:#a1d0e8#b2d9ec>l </text><text style=color:#000;background-color:#99cce6>l </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>d </text><text style=color:#000;background-color:#89c4e2>e </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ನ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#89c4e2>m </text><text style=color:#000;background-color:#f42e2e>a </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>y </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>d </text><text style=color:#000;background-color:#85c2e1>e </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ು :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>m </text><text style=color:#000;background-color:#f42e2e>a </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>y </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>d </text><text style=color:#000;background-color:#85c2e1>e </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ಮ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>m </text><text style=color:#000;background-color:#f42e2e>a </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>y </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>d </text><text style=color:#000;background-color:#85c2e1>e </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ತ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>m </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>y </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>d </text><text style=color:#000;background-color:#85c2e1>e </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ಿ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>m </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>y </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>d </text><text style=color:#000;background-color:#85c2e1>e </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ಯ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>m </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>y </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>d </text><text style=color:#000;background-color:#85c2e1>e </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ಿ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>m </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>y </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>d </text><text style=color:#000;background-color:#85c2e1>e </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ಲ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>m </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>y </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>d </text><text style=color:#000;background-color:#85c2e1>e </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ್ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>m </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>y </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>d </text><text style=color:#000;background-color:#85c2e1>e </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ಲ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>m </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>y </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>d </text><text style=color:#000;background-color:#85c2e1>e </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ದ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>m </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>y </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>d </text><text style=color:#000;background-color:#85c2e1>e </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ೆ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>m </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>y </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>l </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>d </text><text style=color:#000;background-color:#85c2e1>e </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Word: bhinnavaagiruva\n",
            "Transliterated Word: ಭಿನ್ನವಾಗಿರುವ\n",
            "Connectivity Visualization for ಭ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#f42e2e>b </text><text style=color:#000;background-color:#f45f5f>h </text><text style=color:#000;background-color:#f34343>i </text><text style=color:#000;background-color:#f9e8e8>n </text><text style=color:#000;background-color:#f9d4d4>n </text><text style=color:#000;background-color:#a1d0e8#b2d9ec>a </text><text style=color:#000;background-color:#95cae5>v </text><text style=color:#000;background-color:#f33b3b>a </text><text style=color:#000;background-color:#95cae5>a </text><text style=color:#000;background-color:#89c4e2>g </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#a1d0e8#b2d9ec>r </text><text style=color:#000;background-color:#f68f8f>u </text><text style=color:#000;background-color:#99cce6>v </text><text style=color:#000;background-color:#95cae5>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ಿ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>b </text><text style=color:#000;background-color:#85c2e1>h </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#89c4e2>n </text><text style=color:#000;background-color:#f33b3b>n </text><text style=color:#000;background-color:#f42e2e>a </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ನ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>b </text><text style=color:#000;background-color:#85c2e1>h </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#f42e2e>a </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ್ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>b </text><text style=color:#000;background-color:#85c2e1>h </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#f42e2e>a </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ನ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>b </text><text style=color:#000;background-color:#85c2e1>h </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ವ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>b </text><text style=color:#000;background-color:#85c2e1>h </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ಾ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>b </text><text style=color:#000;background-color:#85c2e1>h </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ಗ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>b </text><text style=color:#000;background-color:#85c2e1>h </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ಿ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>b </text><text style=color:#000;background-color:#85c2e1>h </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ರ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>b </text><text style=color:#000;background-color:#85c2e1>h </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ು :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>b </text><text style=color:#000;background-color:#85c2e1>h </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ವ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>b </text><text style=color:#000;background-color:#85c2e1>h </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Word: ranarangada\n",
            "Transliterated Word: ರಣರಂಗದ\n",
            "Connectivity Visualization for ರ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#f42e2e>r </text><text style=color:#000;background-color:#f34343>a </text><text style=color:#000;background-color:#f9e8e8>n </text><text style=color:#000;background-color:#f9e8e8>a </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#a1d0e8#b2d9ec>a </text><text style=color:#000;background-color:#89c4e2>d </text><text style=color:#000;background-color:#99cce6>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ಣ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#eff7fb>a </text><text style=color:#000;background-color:#f42e2e>r </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>d </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ರ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#f42e2e>r </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>d </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ಂ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#f42e2e>r </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>d </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ಗ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>d </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ದ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>d </text><text style=color:#000;background-color:#85c2e1>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Word: hanuma\n",
            "Transliterated Word: ಹನುಮ\n",
            "Connectivity Visualization for ಹ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#f42e2e>h </text><text style=color:#000;background-color:#c2e1f0>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#f34343>u </text><text style=color:#000;background-color:#eff7fb>m </text><text style=color:#000;background-color:#95cae5>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ನ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>h </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#f42e2e>m </text><text style=color:#000;background-color:#f47676>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ು :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>h </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>m </text><text style=color:#000;background-color:#f42e2e>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ಮ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>h </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>u </text><text style=color:#000;background-color:#85c2e1>m </text><text style=color:#000;background-color:#f42e2e>a </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Word: kedet\n",
            "Transliterated Word: ಕೆದೆತ್\n",
            "Connectivity Visualization for ಕ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#f9e8e8>k </text><text style=color:#000;background-color:#f8a8a8>e </text><text style=color:#000;background-color:#f9bdbd>d </text><text style=color:#000;background-color:#f42e2e>e </text><text style=color:#000;background-color:#85c2e1>t </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ೆ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>k </text><text style=color:#000;background-color:#85c2e1>e </text><text style=color:#000;background-color:#85c2e1>d </text><text style=color:#000;background-color:#f42e2e>e </text><text style=color:#000;background-color:#eff7fb>t </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ದ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>k </text><text style=color:#000;background-color:#85c2e1>e </text><text style=color:#000;background-color:#85c2e1>d </text><text style=color:#000;background-color:#89c4e2>e </text><text style=color:#000;background-color:#f42e2e>t </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ೆ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>k </text><text style=color:#000;background-color:#85c2e1>e </text><text style=color:#000;background-color:#85c2e1>d </text><text style=color:#000;background-color:#85c2e1>e </text><text style=color:#000;background-color:#f42e2e>t </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ತ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>k </text><text style=color:#000;background-color:#85c2e1>e </text><text style=color:#000;background-color:#85c2e1>d </text><text style=color:#000;background-color:#85c2e1>e </text><text style=color:#000;background-color:#85c2e1>t </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connectivity Visualization for ್ :\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>k </text><text style=color:#000;background-color:#85c2e1>e </text><text style=color:#000;background-color:#85c2e1>d </text><text style=color:#000;background-color:#85c2e1>e </text><text style=color:#000;background-color:#85c2e1>t </text>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## To get prediction CSV file (execute only after getting best model test accuracy)"
      ],
      "metadata": {
        "id": "PmlIaEgNBcYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_input = pd.read_csv(get_data(\"kn\")[2], sep=\"\\t\", header=None)\n",
        "inputs = test_input[1].astype(str).tolist()\n",
        "targets = test_input[0].astype(str).tolist()\n",
        "outputs = []\n",
        "for word in inputs:\n",
        "    outputs.append(model.translate(word)[0])\n",
        "data_Frame = pd.DataFrame()\n",
        "data_Frame[\"inputs\"] = inputs\n",
        "data_Frame[\"targets\"] = targets\n",
        "data_Frame[\"outputs\"] = outputs\n",
        "data_Frame.to_csv('predictions_attention.csv', encoding = 'utf-8-sig') \n",
        "files.download('predictions_attention.csv')"
      ],
      "metadata": {
        "id": "_kHT2SdxDv5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E9pUPNGndTS"
      },
      "source": [
        "randomly_evaluate(model, n=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVjQ4r9f1Xoz"
      },
      "source": [
        "# Hyper_Parameter_tuning_with_attention"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_with_wandb(language):\n",
        "\n",
        "    config_defaults = {\"embedding_dim\": 64, \n",
        "                   \"enc_dec_layers\": 1,\n",
        "                   \"define_layer\": \"LSTM\",\n",
        "                   \"latent_dim\": 128,\n",
        "                   \"dropout\": 0,\n",
        "                   \"attention\": False,\n",
        "                   \"beam_width\": 3,\n",
        "                   \"teacher_forcing_ratio\": 1.0\n",
        "                   }\n",
        "\n",
        "    #wandb.init(config=config_defaults, project='Assignment3-partB_attn', entity='cs21s002-ee21s113-dlassignment-1')\n",
        "\n",
        "## 1. SELECT LANGUAGE ##\n",
        "    TRAIN_INPUT, val_input, test_input = get_data(language)\n",
        "\n",
        "## 2. DATA PREPROCESSING ##\n",
        "    dataset, input_tokenizer, targ_tokenizer = data_Preprocess(TRAIN_INPUT)\n",
        "    val_dataset, _, _ = data_Preprocess(val_input, input_tokenizer, targ_tokenizer)\n",
        "\n",
        "## 3. CREATING THE MODEL ##\n",
        "    model = Seq2Seq_RNN_Model(embedding_dim=wandb.config.embedding_dim,\n",
        "                     encoder_layers=wandb.config.enc_dec_layers,\n",
        "                     dec_layers=wandb.config.enc_dec_layers,\n",
        "                     define_layer=wandb.config.define_layer,\n",
        "                     latent_dim=wandb.config.latent_dim,\n",
        "                     dropout=wandb.config.dropout,\n",
        "                     attention=wandb.config.attention)\n",
        "\n",
        "## 4. COMPILING THE MODEL \n",
        "    model.set_vocabulary(input_tokenizer, targ_tokenizer)\n",
        "    model.build(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "            optimizer = tf.keras.optimizers.Adam(),\n",
        "            metric = tf.keras.metrics.SparseCategoricalAccuracy())\n",
        "\n",
        "## 5. FITTING AND VALIDATING THE MODEL\n",
        "    model.fit(dataset, val_dataset, epochs=30, use_wandb=True, teacher_forcing_ratio=wandb.config.teacher_forcing_ratio)\n"
      ],
      "metadata": {
        "id": "vZlNdVtS2uTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Kx44JYk6uXr"
      },
      "source": [
        "# Sweeps with Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6ZvJVNy6mxE"
      },
      "source": [
        "sweep_config5 = {\n",
        "                 \"name\": \"Attention Sweep - Assignment3\",\n",
        "                 \"description\": \"Hyperparameter sweep for Seq2Seq Model with Attention\",\n",
        "                 \"method\": \"grid\",\n",
        "                 \"parameters\": {\n",
        "                 \"define_layer\": {\n",
        "                 \"values\": [\"GRU\", \"RNN\", \"LSTM\"]\n",
        "                                 },\n",
        "                 \"enc_dec_layers\": {\n",
        "                            \"values\": [2]\n",
        "                                   },\n",
        "                 \"units\": {\n",
        "                            \"values\": [256]\n",
        "                           },\n",
        "                 \"dropout\": {\n",
        "                            \"values\": [0.2]\n",
        "                            },\n",
        "                 \"attention\": {\n",
        "                            \"values\": [True]\n",
        "                            },\n",
        "                 \"teacher_forcing_ratio\": {\n",
        "                            \"values\":[0.3,0.5,0.7,1.0]}\n",
        "                            }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AntGSlwU7RDm"
      },
      "source": [
        "sweep_id5 = wandb.sweep(sweep_config5, project='Assignment3-partB_attn', entity='cs21s002-ee21s113-dlassignment-1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZtXMBc47h2Z"
      },
      "source": [
        "#wandb.agent(sweep_id5, function=lambda: train_with_wandb(\"kn\"), project='Assignment3-partB_attn', entity='cs21s002-ee21s113-dlassignment-1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#wandb.init(config=config_defaults, project='Assignment3-partB_attn', entity='cs21s002-ee21s113-dlassignment-1')"
      ],
      "metadata": {
        "id": "oZ9nW2hoMqzM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}